# Awesome HCI-LLM-Agent Papers

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated collection of research papers on **HCI**, **LLM**, **MLLM**, **Agent**, **RAG**, **Agentic-RL**, and **Embodied AI** (2021–present).

> **[Jan 2025]** Added new sections: **Agentic-RL** and **MLLM**. Regular updates resumed.

## Quick Start

```bash
pip install -e .                          # Install CLI
paper add 2312.00752 LLM -t "llm, mamba"  # Add paper
paper search transformer -t IMU           # Search
paper stats                               # Statistics
```

## Documentation

- [USAGE.md](USAGE.md) - CLI reference
- [FIELDS_GUIDE.md](FIELDS_GUIDE.md) - Field guide
- [FORMAT_EXAMPLES.md](FORMAT_EXAMPLES.md) - Format examples

---

# HCI
<!-- TABLE_START: HCI -->
| Source | Title (Link) | Authors | Tag | Subjects | Additional info | Date |
|---|---|---|---|---|---|---|
| Ubicomp25 (IMWUT Vol 9 Issue 4) | [Ads that Talk Back: Implications and Perceptions of Injecting Personalized Advertising into LLM Chatbots](https://doi.org/10.1145/3770640) | Brian Jay Tang, et al. | LLM, personalization, advertising, chatbot |  |  | 2025.12 |
| Ubicomp25 (IMWUT Vol 9 Issue 4) | [CHEF-VL: Detecting Cognitive Sequencing Errors in Cooking with Vision-language Models](https://doi.org/10.1145/3770714) | Ruiqi Wang, et al. | VLM, cooking, error detection |  |  | 2025.12 |
| Ubicomp25 (IMWUT Vol 9 Issue 4) | [Design and Evaluation of Generative Agent-based Platform for Human-Assistant Interaction Research: A Tale of 10 User Studies](https://doi.org/10.1145/3770661) | Ziyi Xuan, et al. | LLM, generative agent, platform, human-assistant interaction, user study |  |  | 2025.12 |
| Ubicomp25 (IMWUT Vol 9 Issue 4) | [Gestura: A LVLM-Powered System Bridging Motion and Semantics for Real-Time Free-Form Gesture Understanding](https://doi.org/10.1145/3770709) | Zhuoming Li, et al. | LVLM, gesture, motion, semantics |  |  | 2025.12 |
| Ubicomp25 (IMWUT Vol 9 Issue 4) | [IMUZero: Zero-Shot Human Activity Recognition by Language-Based Cross Modality Fusion](https://doi.org/10.1145/3770669) | Jie Su, et al. | LLM, HAR, zero-shot, cross-modality, language |  |  | 2025.12 |
| arXiv(v2) 2026 | [LLM-Guided Exemplar Selection for Few-Shot Wearable-Sensor Human Activity Recognition](http://arxiv.org/abs/2512.22385v2) | Elsen Ronando, et al. | LLM, HAR, wearable, few-shot, exemplar selection | cs.CL, cs.AI, cs.CV | 88.78% F1 on UCI-HAR | 2025.12 |
| Ubicomp25 (IMWUT Vol 9 Issue 4) | [Large Language Model-guided Semantic Alignment for Human Activity Recognition](https://doi.org/10.1145/3770652) | Hua Yan, et al. | LLM, HAR, semantic alignment |  |  | 2025.12 |
| Ubicomp25 (IMWUT Vol 9 Issue 4) | [TourismMinds: A Geo-augmented LLM Framework for Semantic-aware Trajectory Analytics and Generation](https://doi.org/10.1145/3770697) | Zhuohan Ye, et al. | LLM, trajectory, geo-augmented |  |  | 2025.12 |
| CSCW25 | [An Emergent Understanding of Human-AI Collaboration in Deliberation](https://doi.org/10.1145/3715070.3749265) | Authors TBD, et al. | LLM, human-AI collaboration, deliberation, citizen assembly |  |  | 2025.11 |
| SenSys25 | [Demo: An LLM-Powered Multimodal Mobile Sensing System for Personalized Health Behavior Analysis](https://doi.org/10.1145/3715014.3724376) | Authors TBD, et al. | LLM, mobile sensing, multimodal, health, personalized |  | Demo paper | 2025.11 |
| CSCW25 | [Exploring Collaboration Patterns and Strategies in Human-AI Co-creation through the Lens of Agency: A Scoping Review](https://doi.org/10.1145/3757594) | Authors TBD, et al. | human-AI co-creation, agency, collaboration, scoping review |  | PACM HCI | 2025.11 |
| HAI25 | [Human-Like Remembering and Forgetting in LLM Agents: An ACT-R-Inspired Memory Architecture](https://doi.org/10.1145/3765766.3765803) | Yudai Honda, et al. | LLM, agent, memory, ACT-R, forgetting |  |  | 2025.11 |
| HAI25 | [Robots with Attitudes: Influence of LLM-Driven Robot Personalities on Motivation and Performance](https://doi.org/10.1145/3765766.3765780) | Dennis Becker, et al. | LLM, robot, personality, motivation, performance |  |  | 2025.11 |
| HAI25 | [The Double-Edged Sword: Exploring Older Adults' Interaction and Imagination with an LLM-Enhanced Health Agent](https://doi.org/10.1145/3765766.3765779) | Leon Paul Mondrian Munz, et al. | LLM, health agent, older adults, interaction |  |  | 2025.11 |
| SenSys25 | [Toward Sensor-In-the-Loop LLM Agent: Benchmarks and Implications](https://doi.org/10.1145/3715014.3722082) | Zechen Li, et al. | LLM, agent, sensor, wearable, benchmark |  |  | 2025.11 |
| UIST25 | [ImaginationVellum: Generative-AI Ideation Canvas with Spatial Prompts](https://doi.org/10.1145/3746059.3747631) | Authors TBD, et al. | generative AI, ideation, canvas, spatial prompts, co-creation |  |  | 2025.10 |
| Ubicomp25 | [LLM Powered Memory Consolidation for Ubiquitous Computing](https://doi.org/10.1145/3714394.3750599) | Parampuneet Kaur Thind, et al. | LLM, memory consolidation, ubiquitous computing |  | UbiComp 2025 Companion | 2025.10 |
| UIST25 | [SketchGPT: A Sketch-based Multimodal Interface for Application-Agnostic LLM Interaction](https://doi.org/10.1145/3746059.3747598) | Authors TBD, et al. | LLM, sketch, multimodal, interface |  |  | 2025.10 |
| UIST25 | ["This is My Fault", Really? Understanding Blind and Low-Vision People’s Perception of Hallucination in Large Vision Language Models](https://doi.org/10.1145/3746059.3747597) | Yilin Tang, et al. | VLM |  |  | 2025.09 |
| UIST25 | [BloomIntent: Automating Search Evaluation with LLM-Generated Fine-Grained User Intents](https://doi.org/10.1145/3746059.3747677) | Yoonseo Choi, et al. | LLM |  |  | 2025.09 |
| UIST25 | [Can You Move These Over There? Exploring an LLM-based VR Mover to Support Natural Multi-object Manipulation](https://doi.org/10.1145/3746059.3747673) | Xiangzhi Eric Wang, et al. | LLM |  |  | 2025.09 |
| UIST25 | [CoGrader: Transforming Instructors' Assessment of Project Reports through Collaborative LLM Integration](https://doi.org/10.1145/3746059.3747670) | Zixin Chen, et al. | LLM |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [Contact-free Vital Signs Monitoring and Separating Distinct Vital Signs](https://doi.org/10.1145/3749496) | Authors TBD, et al. | vital signs, contactless, respiration, monitoring |  |  | 2025.09 |
| UIST25 | [DxHF: Providing High-Quality Human Feedback for LLM Alignment with Interactive Decomposition](https://doi.org/10.1145/3746059.3747600) | Danqing Shi, et al. | LLM, alignment |  |  | 2025.09 |
| UIST25 | [GestureCoach: Rehearsing for Engaging Talks with LLM-Driven Gesture Recommendations](https://doi.org/10.1145/3746059.3747705) | Ashwin Ram, et al. | LLM |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [Hapt-Aids: Self-Powered, On-Body Haptics for Activity Monitoring](https://doi.org/10.1145/3749468) | Authors TBD, et al. | haptic, self-powered, activity monitoring, wearable |  |  | 2025.09 |
| UIST25 | [InReAcTable: LLM-powered Interactive Visual Data Story Construction from Tabular Data](https://doi.org/10.1145/3746059.3747719) | Gerile Aodeng, et al. | LLM |  |  | 2025.09 |
| arXiv(v4) 2025 | [LLaSA: A Sensor-Aware LLM for Natural Language Reasoning of Human Activity from IMU Data](http://arxiv.org/abs/2406.14498v4) | Sheikh Asif Imran, et al. | IMU, LLM, wearable, sensor, HAR | cs.CL |  | 2025.09 |
| UIST25 | [LegisFlow: Enhancing Korean Legal Research with Temporal-Aware LLM Interfaces](https://doi.org/10.1145/3746059.3747752) | Junghwan Kim, et al. | LLM |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [MASTER: A Multi-modal Foundation Model for Human Activity Recognition](https://doi.org/10.1145/3749511) | Guanzhou Zhu, et al. | foundation model, HAR, multimodal |  |  | 2025.09 |
| UIST25 | [MapStory: Prototyping Editable Map Animations with LLM Agents](https://doi.org/10.1145/3746059.3747664) | Aditya Gunturu, et al. | LLM, agent |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [Mindfulness Meditation and Respiration: Accelerometer-based Respiration Rate Estimation](https://doi.org/10.1145/3749498) | Authors TBD, et al. | mindfulness, respiration, accelerometer, meditation |  |  | 2025.09 |
| UIST25 | [NarraGuide: an LLM-based Narrative Mobile Robot for Remote Place Exploration](https://doi.org/10.1145/3746059.3747697) | Yaxin Hu, et al. | LLM |  |  | 2025.09 |
| UIST25 | [NeuroSync: Intent-Aware Code-Based Problem Solving via Direct LLM Understanding Modification](https://doi.org/10.1145/3746059.3747668) | Wenshuo Zhang, et al. | LLM |  |  | 2025.09 |
| UIST25 | [Oak Story: Improving Learner Outcomes with LLM-Mediated Interactive Narratives](https://doi.org/10.1145/3746059.3747698) | Alan Y. Cheng, et al. | LLM |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [One Model to Fit Them All: Universal IMU-based Human Activity Recognition with LLM-assisted Cross-dataset Representation](https://doi.org/10.1145/3749509) | Wei Wei, et al. | IMU, LLM, HAR, universal model, cross-dataset |  |  | 2025.09 |
| UIST25 | [Policy Maps: Tools for Guiding the Unbounded Space of LLM Behaviors](https://doi.org/10.1145/3746059.3747680) | Michelle S. Lam, et al. | LLM |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications across Lab and Field Settings](https://doi.org/10.1145/3749494) | Mithun Saha, et al. | foundation model, wearable, PPG |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [RouteLLM: A Large Language Model with Native Route Context Understanding to Enable Context-Aware Reasoning](https://doi.org/10.1145/3749552) | Philipp Hallgarten, et al. | LLM, navigation, route, context-aware |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [SELA: Smart Edge LLM Agent to Optimize Response Trade-offs of AI Assistants](https://doi.org/10.1145/3749483) | Shreshth Tuli, et al. | LLM agent, edge, assistant, optimization |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [Sleep Monitoring with Continuous Posture, Heart Rate, Respiratory Rate Tracking](https://doi.org/10.1145/3749461) | Authors TBD, et al. | sleep, posture, heart rate, respiration, monitoring |  |  | 2025.09 |
| UIST25 | [Streaming, Fast and Slow: Cognitive Load-Aware Streaming for Efficient LLM Serving](https://doi.org/10.1145/3746059.3747721) | Chang Xiao, et al. | LLM |  |  | 2025.09 |
| arXiv(v1) 2025 | [Through the Lens of Human-Human Collaboration: A Configurable Research Platform for Exploring Human-Agent Collaboration](http://arxiv.org/abs/2509.18008v1) | Bingsheng Yao, et al. | LLM, agent, human-agent collaboration, CSCW, platform | cs.HC, cs.AI, cs.CL |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [Towards Customizable Foundation Models for Human Activity Recognition with Wearable Devices](https://doi.org/10.1145/3749479) | Minghui Qiu, et al. | foundation model, HAR, customizable |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [Vinci: A Real-time Smart Assistant Based on Egocentric Vision-language Model for Portable Devices](https://doi.org/10.1145/3749513) | Yifei Huang, et al. | VLM, egocentric, assistant, wearable |  |  | 2025.09 |
| UIST25 | [ViseGPT: Towards Better Alignment of LLM-generated Data Wrangling Scripts and User Prompts](https://doi.org/10.1145/3746059.3747689) | Jiajun Zhu, et al. | LLM, alignment |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [Vital Insight: Assisting Experts' Context-Driven Sensemaking of Multi-modal Personal Tracking Data Using Visualization and Human-in-the-Loop LLM](https://doi.org/10.1145/3749508) | Jiachen Li, et al. | LLM, sensemaking, visualization, personal data |  |  | 2025.09 |
| UIST25 | [agentAR: Creating Augmented Reality Applications with Tool-Augmented LLM-based Autonomous Agents](https://doi.org/10.1145/3746059.3747676) | Chenfei Zhu, et al. | LLM, agent |  |  | 2025.09 |
| Ubicomp25 (IMWUT Vol 9 Issue 3) | [mmPencil: Toward Writing-Style-Independent In-Air Handwriting Recognition via mmWave Radar and Large Vision-Language Model](https://doi.org/10.1145/3749504) | Yifan Guo, et al. | mmWave, radar, handwriting, VLM |  |  | 2025.09 |
| arXiv(v1) 2025 | [BaroPoser: Real-time Human Motion Tracking from IMUs and Barometers in Everyday Devices](http://arxiv.org/abs/2508.03313v1) | Riku Arakawa, et al. | IMU, barometer, pose estimation, motion tracking | cs.CV, cs.HC |  | 2025.08 |
| arXiv(v1) 2025 | [DiffCap: Diffusion-based Real-time Human Motion Capture using Sparse IMUs and a Monocular Camera](http://arxiv.org/abs/2508.06139v1) | Zongmian Li, et al. | IMU, diffusion, motion capture, real-time, camera | cs.CV |  | 2025.08 |
| arXiv(v4) 2025 | [SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition](http://arxiv.org/abs/2410.10624v4) | Zechen Li, et al. | IMU, LLM, motion sensor, HAR | cs.CL | Accepted by EMNLP 2025 Main Conference | 2025.08 |
| Ubicomp25 (IMWUT Vol 9 Issue 2) | [CataractBot: An LLM-powered Expert-in-the-Loop Chatbot for Cataract Patients](https://doi.org/10.1145/3729479) | Pragnya Ramjee, et al. | LLM, chatbot, healthcare, expert-in-the-loop |  |  | 2025.06 |
| arXiv(v1) 2025 | [Garment Inertial Poser: Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models](http://arxiv.org/abs/2506.15290v1) | Tao Wang, et al. | IMU, pose estimation, loose sensor, diffusion, garment | cs.CV |  | 2025.06 |
| Ubicomp25 (IMWUT Vol 9 Issue 2) | [LEGO: Synthesizing IoT Device Components Based on Static Analysis and Large Language Models](https://doi.org/10.1145/3729482) | Liwei Liu, et al. | LLM, IoT, static analysis |  |  | 2025.06 |
| arXiv(v1) 2025 | [SensorLM: Learning the Language of Wearable Sensors](http://arxiv.org/abs/2506.09108v1) | Tong Xia, et al. | wearable, sensor, LLM, activity recognition, foundation model | cs.LG, cs.HC |  | 2025.06 |
| arXiv(v2) 2025 (PRX Quantum 6, 020311 (April 2025)) | [Device-Independent Quantum Key Distribution Based on Routed Bell Tests](http://arxiv.org/abs/2404.01202v2) | Tristan Le Roy-Deloison, et al. | IMU, RGB, human object interaction, dataset, 3D tracking | quant-ph | Version2: Slight improvements in the text. Close to published version | 2025.05 |
| arXiv(v4) 2025 | [LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey](http://arxiv.org/abs/2505.00753v4) | Hengyi Peng, et al. | LLM, agent, human-agent collaboration, HCI, survey | cs.HC, cs.AI, cs.CL |  | 2025.05 |
| CHI25 | ["A Great Start, But...": Evaluating LLM-Generated Mind Maps for Information Mapping in Video-Based Design](https://doi.org/10.1145/3706599.3719940) | Tianhao He, et al. | LLM |  |  | 2025.04 |
| CHI25 | ["Ask Sir Oliver Ingham": LLM-based Social Simulations for History Education](https://doi.org/10.1145/3706599.3719728) | Kieun Park, et al. | LLM |  |  | 2025.04 |
| CHI25 | ["Create a Fear of Missing Out" - ChatGPT Implements Unsolicited Deceptive Designs in Generated Websites Without Warning](https://doi.org/10.1145/3706598.3713083) | Veronika Krauß, et al. | LLM |  |  | 2025.04 |
| CHI25 | ["It Warned Me Just at the Right Moment": Exploring LLM-based Real-time Detection of Phone Scams](https://doi.org/10.1145/3706599.3720263) | Zitong Shen, et al. | LLM |  |  | 2025.04 |
| CHI25 | ["Kya family planning after marriage hoti hai?": Integrating Cultural Sensitivity in an LLM Chatbot for Reproductive Health](https://doi.org/10.1145/3706598.3713362) | Roshini Deva, et al. | LLM, chatbot |  |  | 2025.04 |
| CHI25 | ["We do use it, but not how hearing people think": How the Deaf and Hard of Hearing Community Uses Large Language Model Tools](https://doi.org/10.1145/3706599.3719785) | Shuxu Huffman, et al. | LLM |  |  | 2025.04 |
| CHI25 | ["When AI Writes Personas": Analyzing Lexical Diversity in LLM-Generated Persona Descriptions](https://doi.org/10.1145/3706599.3719712) | Sankalp Sethi, et al. | LLM, persona |  |  | 2025.04 |
| CHI25 | ["You Don't Need a University Degree to Comprehend Data Protection This Way": LLM-Powered Interactive Privacy Policy Assessment](https://doi.org/10.1145/3706599.3719816) | Vincent Freiberger, et al. | LLM, privacy |  |  | 2025.04 |
| CHI25 | [A Matter of Perspective(s): Contrasting Human and LLM Argumentation in Subjective Decision-Making on Subtle Sexism](https://doi.org/10.1145/3706598.3713248) | Paula Akemi Aoyagui, et al. | LLM |  |  | 2025.04 |
| CHI25 | [AI on My Shoulder: Supporting Emotional Labor in Front-Office Roles with an LLM-based Empathetic Coworker](https://doi.org/10.1145/3706598.3713705) | Vedant Das Swain, et al. | LLM |  |  | 2025.04 |
| CHI25 | [AI-Instruments: Embodying Prompts as Instruments](https://doi.org/10.1145/3706598.3714259) | Authors TBD, et al. | LLM, prompt, instruments, direct manipulation |  |  | 2025.04 |
| CHI25 | [ASHABot: An LLM-Powered Chatbot to Support the Informational Needs of Community Health Workers](https://doi.org/10.1145/3706598.3713680) | Pragnya Ramjee, et al. | LLM, chatbot |  |  | 2025.04 |
| CHI25 | [Adaptive Human-LLMs Interaction Collaboration: Reinforcement Learning driven Vision-Language Models for Medical Report Generation](https://doi.org/10.1145/3706599.3719852) | Yiming Cao, et al. | VLM |  |  | 2025.04 |
| CHI25 | [Align with Me, Not TO Me: How People Perceive Concept Alignment with LLM-Powered Conversational Agents](https://doi.org/10.1145/3706599.3720126) | Shengchen Zhang, et al. | LLM, agent, alignment |  |  | 2025.04 |
| CHI25 | [Applying the Gricean Maxims to a Human-LLM Interaction Cycle: Design Insights from a Participatory Approach](https://doi.org/10.1145/3706599.3719759) | Yoonsu Kim, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Artificial Intimacy: Exploring Normativity and Personalization Through Fine-tuning LLM Chatbots](https://doi.org/10.1145/3706598.3713728) | Mirabelle Jones, et al. | LLM, chatbot, personalization, fine-tuning, normativity |  |  | 2025.04 |
| CHI25 | [Assessing Critical Thinking through a Multi-Agent LLM-Based Debate Chatbot](https://doi.org/10.1145/3706599.3721207) | Bogyeom Park, et al. | LLM, agent, chatbot |  |  | 2025.04 |
| CHI25 | [AutoPBL: An LLM-powered Platform to Guide and Support Individual Learners Through Self Project-based Learning](https://doi.org/10.1145/3706598.3714261) | Yihao Zhu, et al. | LLM |  |  | 2025.04 |
| CHI25 | [BallistoBud: Heart Rate Variability Monitoring using Earbud Accelerometry for Stress Assessment](https://doi.org/10.1145/3706598.3714029) | Authors TBD, et al. | earbuds, accelerometer, BCG, heart rate, stress |  |  | 2025.04 |
| CHI25 | [Beyond Adaptation: an LLM-Supported Self-Presentation Ideation Tool for Cross-Cultural Mingling](https://doi.org/10.1145/3706599.3719929) | Chien-Yin Wu, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Beyond Code Generation: LLM-supported Exploration of the Program Design Space](https://doi.org/10.1145/3706598.3714154) | J.D. Zamfirescu-Pereira, et al. | LLM |  |  | 2025.04 |
| CHI25 | [BioSpark: Beyond Analogical Inspiration to LLM-augmented Transfer](https://doi.org/10.1145/3706598.3714053) | Hyeonsu B Kang, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Boosting Diary Study Outcomes with a Fine-Tuned Large Language Model](https://doi.org/10.1145/3706599.3719287) | Sunggyeol Oh, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Breaking Barriers or Building Dependency? Exploring Team-LLM Collaboration in AI-infused Classroom Debate](https://doi.org/10.1145/3706598.3713853) | Zihan Zhang, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Bridging the Treatment Gap: A Novel LLM-Driven System for Scalable Initial Patient Assessments in Mental Healthcare](https://doi.org/10.1145/3706599.3720043) | Niclas Rosteck, et al. | LLM |  |  | 2025.04 |
| CHI25 | [BudsID: Mobile-Ready and Expressive Finger Identification Input for Earbuds](https://doi.org/10.1145/3706598.3714133) | Authors TBD, et al. | earbuds, finger identification, magnetometer, wearable |  | 96.9% accuracy | 2025.04 |
| CHI25 | [COMETIC: Enhancing Smartphone Eye Tracking with Cursor-Based Implicit Calibration](https://doi.org/10.1145/3706598.3713936) | Authors TBD, et al. | eye tracking, smartphone, calibration, cursor |  | 27.2% improvement | 2025.04 |
| CHI25 | [Canvil: Designerly Adaptation for LLM-Powered User Experiences](https://doi.org/10.1145/3706598.3713139) | Kenneth Li, et al. | LLM, design, UX, user experience, adaptation |  |  | 2025.04 |
| CHI25 | [CaseMaster: Designing a Probe for Oral Case Presentation Training with LLM Assistance](https://doi.org/10.1145/3706599.3720206) | Yang Ouyang, et al. | LLM |  |  | 2025.04 |
| CHI25 | [ChainBuddy: An AI-assisted Agent System for Generating LLM Pipelines](https://doi.org/10.1145/3706598.3714085) | Xinyue Chen, et al. | LLM, agent, pipeline, AI-assisted, prompt engineering |  |  | 2025.04 |
| CHI25 | [Characterizing LLM-Empowered Personalized Story Reading and Interaction for Children: Insights From Multi-Stakeholder Perspectives](https://doi.org/10.1145/3706598.3713275) | Jiaju Chen, et al. | LLM, persona, personalization |  |  | 2025.04 |
| CHI25 | [Closing the Loop between User Stories and GUI Prototypes: An LLM-Based Assistant for Cross-Functional Integration in Software Development](https://doi.org/10.1145/3706598.3713932) | Felix Kretzer, et al. | LLM, assistant |  |  | 2025.04 |
| CHI25 | [Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators](https://doi.org/10.1145/3706598.3713971) | Prerna Ravi, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Context over Categories: Implementing the Theory of Constructed Emotion with LLM-Guided User Analysis](https://doi.org/10.1145/3706599.3721205) | Nils Klüwer, et al. | LLM |  |  | 2025.04 |
| CHI25 | [ConversAR: Exploring Embodied LLM-Powered Group Conversations in Augmented Reality for Second Language Learners](https://doi.org/10.1145/3706599.3720162) | Jad Bendarkawi, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Cross, Dwell, or Pinch: Around-Device Selection Methods for Unmodified Smartwatches](https://doi.org/10.1145/3706598.3714308) | Authors TBD, et al. | smartwatch, sonar, around-device, input |  | First sonar-based around-device input on consumer smartwatch | 2025.04 |
| CHI25 | [Customizing Emotional Support: How Do Individuals Construct and Interact With LLM-Powered Chatbots](https://doi.org/10.1145/3706598.3713453) | Xi Zheng, et al. | LLM, chatbot, personalization |  |  | 2025.04 |
| CHI25 | [DBox: Scaffolding Algorithmic Programming Learning through Learner-LLM Co-Decomposition](https://doi.org/10.1145/3706598.3713748) | Shuai Ma, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Dango: A Mixed-Initiative Data Wrangling System using Large Language Model](https://doi.org/10.1145/3706598.3714135) | Wei-Hao Chen, et al. | LLM |  |  | 2025.04 |
| CHI25 | [DanmuA11y: Making Time-Synced Video Comments Accessible to BLV Users](https://doi.org/10.1145/3706598.3713496) | Authors TBD, et al. | accessibility, BLV, video, Danmu, audio |  |  | 2025.04 |
| CHI25 | [Demonstration of GazeNoter: Enhancing AR Note-Taking Through Gaze-Based Selection of LLM Suggestions](https://doi.org/10.1145/3706599.3721274) | Shih-Kang Chiu, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Demystifying Mental Health Reports Through an LLM-based Approach](https://doi.org/10.1145/3706599.3720208) | Shyama Sastha Krishnamoorthy Srinivasan, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Design Principles and Guidelines for LLM Observability: Insights from Developers](https://doi.org/10.1145/3706599.3719914) | Xin Chen, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Designing Accessible Audio Nudges for Voice Interfaces](https://doi.org/10.1145/3706598.3713563) | Hira Jamshed, et al. | voice interface, audio, nudging, older adults, accessibility |  |  | 2025.04 |
| CHI25 | [Designing LLM-Powered Multimodal Instructions to Support Rich Hands-on Skills Remote Learning: A Case Study with Massage Instructors and Learners](https://doi.org/10.1145/3706598.3713677) | Chutian Jiang, et al. | LLM, multimodal |  |  | 2025.04 |
| CHI25 | [Development of an LLM-Based Chatbot to Support Learnability in Stardew Valley: A Diary Study Approach](https://doi.org/10.1145/3706598.3713310) | Jungmin Lee, et al. | LLM, chatbot |  |  | 2025.04 |
| CHI25 | [Effects of Acoustic Transparency of Wearable Audio Devices on Audio AR](https://doi.org/10.1145/3706598.3713907) | Yuki Watanabe, et al. | audio AR, wearable, acoustic transparency, hearables |  |  | 2025.04 |
| CHI25 | [Effects of LLM-based Search on Decision Making: Speed, Accuracy, and Overreliance](https://doi.org/10.1145/3706598.3714082) | Sofia Eleni Spatharioti, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Efficient Management of LLM-Based Coaching Agents' Reasoning While Maintaining Interaction Quality and Speed](https://doi.org/10.1145/3706598.3713606) | Andreas Göldi, et al. | LLM, agent |  |  | 2025.04 |
| arXiv(v1) 2025 | [Ego4o: Egocentric Human Motion Capture and Understanding from Multi-Modal Input](http://arxiv.org/abs/2504.08449v1) | Jian Wang, et al. | egocentric, IMU, pose estimation, multimodal, VR | cs.CV, cs.HC |  | 2025.04 |
| CHI25 | [End User Authoring of Personalized Content Classifiers: Comparing Example Labeling, Rule Writing, and LLM Prompting](https://doi.org/10.1145/3706598.3713691) | Leijie Wang, et al. | LLM, personalization, content classifier, end-user, prompting |  |  | 2025.04 |
| CHI25 | [Enhancing AI Explainability for Non-technical Users with LLM-Driven Narrative Gamification](https://doi.org/10.1145/3706599.3719795) | Yuzhe You, et al. | LLM |  |  | 2025.04 |
| CHI25 | [EvAlignUX: Advancing UX Evaluation through LLM-Supported Metrics Exploration](https://doi.org/10.1145/3706598.3714045) | Qingxiao Zheng, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Explaining Complex ML Models to Domain Experts Using LLM & Visualization: An Exploration in the French Breadmaking Industry](https://doi.org/10.1145/3706599.3706685) | Briggs Twitchell, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Exploring Culturally Informed AI Assistants: A Comparative Study of ChatBlackGPT and ChatGPT](https://doi.org/10.1145/3706599.3720136) | Lisa Egede, et al. | LLM, assistant |  |  | 2025.04 |
| CHI25 | [Exploring Gender Biases in LLM-based Voice Chatbots for Job Interviews](https://doi.org/10.1145/3706599.3719281) | Sumin Heo, et al. | LLM, chatbot |  |  | 2025.04 |
| CHI25 | [Exploring LLM-Powered Role and Action-Switching Pedagogical Agents for History Education in Virtual Reality](https://doi.org/10.1145/3706598.3713109) | Zihao Zhu, et al. | LLM, agent |  |  | 2025.04 |
| CHI25 | [Exploring Mobile Touch Interaction with Large Language Models](https://doi.org/10.1145/3706598.3713554) | Authors TBD, et al. | LLM, touch, mobile, gesture, interaction |  |  | 2025.04 |
| CHI25 | [Exploring Older Adults Personality Preferences for LLM-powered Conversational Companions](https://doi.org/10.1145/3706599.3719976) | Ajwa Shahid, et al. | LLM, persona, personalization |  |  | 2025.04 |
| CHI25 | [Exploring Personalized Health Support through Data-Driven, Theory-Guided LLMs: A Case Study in Sleep Health](https://doi.org/10.1145/3706598.3713852) | Xin Tong, et al. | LLM, wearable, health, sleep, personalized, chatbot |  | HealthGuru multi-agent framework | 2025.04 |
| CHI25 | [Exploring the Design Space of Real-time LLM Knowledge Support Systems: A Case Study of Jargon Explanations](https://doi.org/10.1145/3706598.3714262) | Yuhan Liu, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Exploring the Design of LLM-based Agent in Enhancing Self-disclosure Among the Older Adults](https://doi.org/10.1145/3706598.3713639) | Yijie Guo, et al. | LLM, agent |  |  | 2025.04 |
| CHI25 | [Exploring the Impact of Explainability in Large Language Model (LLM) Applications on User Experience](https://doi.org/10.1145/3706599.3719941) | Yanyun Wang, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Exploring the Impact of Intervention Methods on Developers’ Security Behavior in a Manipulated ChatGPT Study](https://doi.org/10.1145/3706598.3713989) | Raphael Serafini, et al. | LLM |  |  | 2025.04 |
| CHI25 | [FIP: Endowing Robust Motion Capture on Daily Garment by Fusing Flex and Inertial Sensors](https://doi.org/10.1145/3706598.3714140) | Yiwei Zhao, et al. | IMU, flex sensor, motion capture, pose estimation, garment |  | 19.5% improvement over SOTA | 2025.04 |
| CHI25 | [Fact or Fiction? Exploring Explanations to Identify Factual Confabulations in RAG-Based LLM Systems](https://doi.org/10.1145/3706599.3720249) | Philipp Reinhard, et al. | LLM |  |  | 2025.04 |
| CHI25 | [FineType: Fine-grained Tapping Gesture Recognition for Text Entry](https://doi.org/10.1145/3706598.3714278) | Authors TBD, et al. | tapping, gesture, text entry, IMU, wristband |  |  | 2025.04 |
| CHI25 | [FingerGlass: Enhancing Smart Glasses Interaction via Fingerprint Sensing](https://doi.org/10.1145/3706598.3713929) | Authors TBD, et al. | smart glasses, fingerprint, gesture recognition, CNN, LSTM |  |  | 2025.04 |
| CHI25 | [Friction: Deciphering Writing Feedback into Writing Revisions through LLM-Assisted Reflection](https://doi.org/10.1145/3706598.3714316) | Chao Zhang, et al. | LLM |  |  | 2025.04 |
| CHI25 | [From Text to Trust: Empowering AI-assisted Decision Making with Adaptive LLM-powered Analysis](https://doi.org/10.1145/3706598.3713133) | Zhuoyan Li, et al. | LLM |  |  | 2025.04 |
| CHI25 | [FusAIn: Composing Generative AI Visual Prompts Using Pen-based Interaction](https://doi.org/10.1145/3706598.3714027) | Xiaohan Peng, et al. | generative AI, pen-based, prompt, visual design |  |  | 2025.04 |
| CHI25 | [GPTCoach: Towards LLM-Based Physical Activity Coaching](https://doi.org/10.1145/3706598.3713819) | Matthew Jörke, et al. | LLM |  |  | 2025.04 |
| CHI25 | [GazeNoter: Co-Piloted AR Note-Taking via Gaze Selection of LLM Suggestions to Match Users' Intentions](https://doi.org/10.1145/3706598.3714294) | Zhiyi Rong, et al. | LLM, AR, gaze, note-taking, eye tracking |  |  | 2025.04 |
| CHI25 | [Gesture and Audio-Haptic Guidance Techniques to Direct Conversations with Intelligent Voice Interfaces](https://doi.org/10.1145/3706598.3714310) | Xiyuan Shen, et al. | LLM, wearable, voice interface, gesture, haptic, smart glasses |  | Ray-Ban Meta Glasses, GPT-4o | 2025.04 |
| CHI25 | [HaptiCoil: Soft Programmable Buttons with Hydraulically Coupled Haptic Feedback and Sensing](https://doi.org/10.1145/3706598.3713175) | Authors TBD, et al. | haptic, soft button, sensing, feedback |  | 1-500Hz bandwidth | 2025.04 |
| CHI25 | [Human Robot Interaction for Blind and Low Vision People: A Systematic Literature Review](https://doi.org/10.1145/3706598.3713438) | Authors TBD, et al. | robot, accessibility, BLV, HRI, survey |  |  | 2025.04 |
| CHI25 | [Human Subjects Research in the Age of Generative AI: Opportunities and Challenges of Applying LLM-Simulated Data to HCI Studies](https://doi.org/10.1145/3706599.3716299) | Angel Hsing-Chi Hwang, et al. | LLM |  |  | 2025.04 |
| CHI25 | [IdeationWeb: Tracking the Evolution of Design Ideas in Human-AI Co-Creation](https://doi.org/10.1145/3706598.3713375) | Authors TBD, et al. | LLM, human-AI co-creation, ideation, design |  |  | 2025.04 |
| CHI25 | [Improving User Engagement and Learning Outcomes in LLM-Based Python Tutor: A Study of PACE](https://doi.org/10.1145/3706599.3720240) | Muhtasim Ibteda Shochcho, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching](https://doi.org/10.1145/3706598.3713397) | Authors TBD, et al. | generative AI, T2I, sketching, design exploration |  |  | 2025.04 |
| CHI25 | [Interactive Debugging and Steering of Multi-Agent AI Systems](https://doi.org/10.1145/3706598.3713581) | Will Epperson, et al. | LLM, agent, multi-agent, debugging, HCI |  |  | 2025.04 |
| CHI25 | [Investigating LLM-Driven Curiosity in Human-Robot Interaction](https://doi.org/10.1145/3706598.3713923) | Jan Leusmann, et al. | LLM |  |  | 2025.04 |
| CHI25 | [LEGOLAS: Learning & Enhancing Golf Skills through LLM-Augmented System](https://doi.org/10.1145/3706599.3720141) | Kangbeen Ko, et al. | LLM |  |  | 2025.04 |
| CHI25 | [LIGS: Developing an LLM-infused Game System for Emergent Narrative](https://doi.org/10.1145/3706599.3720212) | Jin Jeong, et al. | LLM |  |  | 2025.04 |
| CHI25 | [LLM Adoption in Data Curation Workflows: Industry Practices and Insights](https://doi.org/10.1145/3706599.3719677) | Crystal Qian, et al. | LLM |  |  | 2025.04 |
| CHI25 | [LLM Integration in Extended Reality: A Comprehensive Review of Current Trends, Challenges, and Future Perspectives](https://doi.org/10.1145/3706598.3714224) | Chengkun Wu, et al. | LLM, VR, AR, XR, survey, extended reality |  | Survey paper | 2025.04 |
| CHI25 | [LLM Powered Text Entry Decoding and Flexible Typing on Smartphones](https://doi.org/10.1145/3706598.3714314) | Authors TBD, et al. | LLM, text entry, typing, smartphone, gesture |  | 93.1% top-1 accuracy | 2025.04 |
| CHI25 | [LLM Whisperer: An Inconspicuous Attack to Bias LLM Responses](https://doi.org/10.1145/3706598.3714025) | Weiran Lin, et al. | LLM |  |  | 2025.04 |
| CHI25 | [LearnMate: Enhancing Online Education with LLM-Powered Personalized Learning Plans and Support](https://doi.org/10.1145/3706599.3719857) | Xinyu Jessica Wang, et al. | LLM, persona, personalization |  |  | 2025.04 |
| CHI25 | [Letters from Future Self: Augmenting the Letter-Exchange Exercise with LLM-based Agents to Enhance Young Adults' Career Exploration](https://doi.org/10.1145/3706598.3714206) | Hayeon Jeon, et al. | LLM, agent |  |  | 2025.04 |
| CHI25 | [Leveraging Multimodal LLM for Inspirational User Interface Search](https://doi.org/10.1145/3706598.3714213) | Seokhyeon Park, et al. | LLM, multimodal |  |  | 2025.04 |
| CHI25 | [LifeInsight: Design and Evaluation of an AI-Powered Assistive Wearable for Blind and Low Vision People](https://doi.org/10.1145/3706598.3713486) | Authors TBD, et al. | AI, wearable, accessibility, BLV, assistive |  |  | 2025.04 |
| CHI25 | [LittleToDo: Large Language Model Driven Intervention Tool for Adolescent Academic Procrastination with Affective Computing](https://doi.org/10.1145/3706599.3719890) | Xiaofan Hu, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Lookee: Gaze Tracking-based Infant Vocabulary Comprehension Assessment](https://doi.org/10.1145/3706598.3713386) | Authors TBD, et al. | gaze, infant, vocabulary, assessment, AI |  |  | 2025.04 |
| CHI25 | [M2SILENT: Enabling Multi-user Silent Speech Interactions via Multi-directional Speakers](https://doi.org/10.1145/3706598.3714174) | Authors TBD, et al. | silent speech, multi-user, speaker, shared space |  |  | 2025.04 |
| CHI25 | [MAP: Multi-user Personalization with Collaborative LLM-powered Agents](https://doi.org/10.1145/3706599.3719853) | Christine P. Lee, et al. | LLM, agent, persona, personalization |  |  | 2025.04 |
| CHI25 | [Maintaining Long-Distance Relationships with (Mediocre) LLM-based Chatbots: A Collaborative Ethnographic Study](https://doi.org/10.1145/3706599.3720221) | Bernd Ploderer, et al. | LLM, chatbot |  |  | 2025.04 |
| arXiv(v1) 2025 | [MobilePoser: Real-Time Full-Body Pose Estimation and 3D Human Translation from IMUs in Mobile Consumer Devices](http://arxiv.org/abs/2504.12492v1) | Vimal Mollyn, et al. | IMU, pose estimation, mobile, consumer device, real-time | cs.CV, cs.HC |  | 2025.04 |
| CHI25 | [MotionBlocks: Modular Geometric Motion Remapping for Accessible VR](https://doi.org/10.1145/3706598.3713837) | Authors TBD, et al. | VR, accessibility, motion, remapping, limited mobility |  |  | 2025.04 |
| CHI25 | [Objection Overruled! Lay People can Distinguish Large Language Models from Lawyers, but still Favour Advice from an LLM](https://doi.org/10.1145/3706598.3713470) | Eike Schneiders, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Online-EYE: Multimodal Implicit Eye Tracking Calibration for XR](https://doi.org/10.1145/3706598.3713461) | Authors TBD, et al. | eye tracking, XR, VR, calibration, implicit |  |  | 2025.04 |
| CHI25 | [PPG Earring: Wireless Smart Earring for Heart Health Monitoring](https://doi.org/10.1145/3706598.3713856) | Authors TBD, et al. | PPG, earring, heart rate, wearable, health monitoring |  | 14mm, 2g, 21h battery | 2025.04 |
| CHI25 | [PaperWave: Listening to Research Papers as Conversational Podcasts Scripted by LLM](https://doi.org/10.1145/3706599.3706664) | Yuchi Yahagi, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Parents, Children, and ChatGPT in Home Environments: The Conversation Content and the Interaction Mode](https://doi.org/10.1145/3706599.3719969) | Shuang Quan, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Piecing Together Teamwork: A Responsible Approach to an LLM-based Educational Jigsaw Agent](https://doi.org/10.1145/3706598.3713349) | Emily Doherty, et al. | LLM, agent |  |  | 2025.04 |
| CHI25 | [Plan-Then-Execute: An Empirical Study of User Trust and Team Performance When Using LLM Agents As A Daily Assistant](https://doi.org/10.1145/3706598.3713218) | Gaole He, et al. | LLM, agent, assistant |  |  | 2025.04 |
| CHI25 | [Playing Dumb to Get Smart: Creating and Evaluating an LLM-based Teachable Agent within University Computer Science Classes](https://doi.org/10.1145/3706598.3713644) | Naiming Liu, et al. | LLM, teachable agent, education, learning |  |  | 2025.04 |
| CHI25 | [PolicyPulse: LLM-Synthesis Tool for Policy Researchers](https://doi.org/10.1145/3706599.3720266) | Maggie Wang, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Privacy Meets Explainability: Managing Confidential Data and Transparency Policies in LLM-Empowered Science](https://doi.org/10.1145/3706599.3720099) | Yashothara Shanmugarasa, et al. | LLM, privacy |  |  | 2025.04 |
| CHI25 | [Private Yet Social: How LLM Chatbots Support and Challenge Eating Disorder Recovery](https://doi.org/10.1145/3706598.3713485) | Ryuhaerang Choi, et al. | LLM, chatbot |  |  | 2025.04 |
| CHI25 | [Promoting Cognitive Health in Elder Care with Large Language Model-Powered Socially Assistive Robots](https://doi.org/10.1145/3706598.3713582) | Maria R. Lima, et al. | LLM |  |  | 2025.04 |
| CHI25 | [PropType: Everyday Props as Typing Surfaces in Augmented Reality](https://doi.org/10.1145/3706598.3714056) | Authors TBD, et al. | AR, typing, props, text entry |  |  | 2025.04 |
| CHI25 | [Prototyping with Prompts: Emerging Approaches and Challenges in Generative AI Design](https://doi.org/10.1145/3706598.3713166) | Hari Subramonyam, et al. | generative AI, prompt engineering, design, prototyping |  |  | 2025.04 |
| CHI25 | [Proxona: Supporting Creators' Sensemaking and Ideation with LLM-Powered Audience Personas](https://doi.org/10.1145/3706598.3714034) | Yoonseo Choi, et al. | LLM, persona |  |  | 2025.04 |
| CHI25 | [RadEye: Tracking Eye Motion Using FMCW Radar](https://doi.org/10.1145/3706598.3713775) | Authors TBD, et al. | radar, eye tracking, FMCW, gaze |  |  | 2025.04 |
| CHI25 | [Rambler in the Wild: A Diary Study of LLM-Assisted Writing With Speech](https://doi.org/10.1145/3706599.3706676) | Xuyu Yang, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Redefining Research Crowdsourcing: Incorporating Human Feedback with LLM-Powered Digital Twins](https://doi.org/10.1145/3706599.3720269) | Amanda Chan, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Rescriber: Smaller-LLM-Powered User-Led Data Minimization for LLM-Based Chatbots](https://doi.org/10.1145/3706598.3713701) | Jijie Zhou, et al. | LLM, chatbot |  |  | 2025.04 |
| CHI25 | [SPECTRA: Personalizable Sound Recognition for DHH Users through Interactive ML](https://doi.org/10.1145/3706598.3713294) | Steven M. Goodman, et al. | sound recognition, DHH, accessibility, interactive ML |  |  | 2025.04 |
| CHI25 | [Scaffolded Turns and Logical Conversations: Designing Humanized LLM-Powered Conversational Agents for Hospital Admission Interviews](https://doi.org/10.1145/3706598.3714196) | Dingdong Liu, et al. | LLM, agent |  |  | 2025.04 |
| CHI25 | [Script&Shift: A Layered Interface Paradigm for Integrating Content Development and Rhetorical Strategy with LLM Writing Assistants](https://doi.org/10.1145/3706598.3714119) | Momin N Siddiqui, et al. | LLM, assistant |  |  | 2025.04 |
| CHI25 | [Seeing and Touching the Air: Eye-Hand Coordination in Mid-Air Gesture Typing for MR](https://doi.org/10.1145/3706598.3713743) | Authors TBD, et al. | gesture typing, MR, mid-air, eye-hand coordination |  |  | 2025.04 |
| CHI25 | [Seeking Inspiration through Human-LLM Interaction](https://doi.org/10.1145/3706598.3713259) | Xinrui Lin, et al. | LLM |  |  | 2025.04 |
| CHI25 | [SocialEyes: Scaling Mobile Eye-tracking to Multi-person Social Settings](https://doi.org/10.1145/3706598.3713910) | Authors TBD, et al. | eye tracking, mobile, social, multi-person |  |  | 2025.04 |
| CHI25 | [Sonora: Human-AI Co-Creation of 3D Audio Worlds](https://doi.org/10.1145/3706598.3713316) | Fernanda M De La Torre, et al. | AI, audio, 3D, soundscape, LLM, co-creation |  | Uses LLM for voice commands | 2025.04 |
| CHI25 | [Spatial Hand Actions: Hand Actions for Spatial Thinking in 3D Assembling](https://doi.org/10.1145/3706598.3713424) | Authors TBD, et al. | hand, spatial, 3D, assembling, gesture |  |  | 2025.04 |
| CHI25 | [Spatial Haptics: A Sensory Substitution Method for Distal Object Detection Using Tactile Cues](https://doi.org/10.1145/3706598.3714083) | Authors TBD, et al. | haptic, tactile, sensory substitution, localization |  |  | 2025.04 |
| CHI25 | [Spatial Speech Translation: Translating Across Space With Binaural Hearables](https://doi.org/10.1145/3706598.3713745) | Authors TBD, et al. | speech translation, binaural, hearables, spatial audio |  |  | 2025.04 |
| CHI25 | [SpellRing: Recognizing Continuous Fingerspelling in ASL using a Ring](https://doi.org/10.1145/3706598.3713721) | Authors TBD, et al. | ring, ASL, sign language, fingerspelling, wearable |  |  | 2025.04 |
| CHI25 | [TableNarrator: Making Image Tables Accessible to Blind and Low Vision People](https://doi.org/10.1145/3706598.3714329) | Authors TBD, et al. | accessibility, BLV, tables, image, data |  |  | 2025.04 |
| CHI25 | [Talk to the Hand: an LLM-powered Chatbot with Visual Pointer as Proactive Companion for On-Screen Tasks](https://doi.org/10.1145/3706598.3715579) | Zhepeng Wang, et al. | LLM, chatbot, UI, on-screen tasks, visual pointer |  |  | 2025.04 |
| CHI25 | [Tap&Say: Touch Location-Informed LLM for Multimodal Text Correction](https://doi.org/10.1145/3706598.3713376) | Authors TBD, et al. | LLM, touch, voice, multimodal, text correction |  |  | 2025.04 |
| CHI25 | [The Interaction Layer: An Exploration for Co-Designing User-LLM Interactions in Parental Wellbeing Support Systems](https://doi.org/10.1145/3706598.3714088) | Sruthi Viswanathan, et al. | LLM |  |  | 2025.04 |
| CHI25 | [The Voice of Endo: Leveraging Speech for Illness Flare-up Forecasting](https://doi.org/10.1145/3706598.3714040) | Authors TBD, et al. | speech, health, voice, endometriosis, forecasting |  |  | 2025.04 |
| CHI25 | [Through the Lens of Privacy: Exploring Privacy Protection in Vision-Language Model Interactions on Smart Glasses](https://doi.org/10.1145/3706599.3720234) | Ziyang Zhang, et al. | VLM, privacy |  |  | 2025.04 |
| CHI25 | [Too Much Information? Investigating Information Disclosure in Auction Systems with LLM Simulations](https://doi.org/10.1145/3706599.3720022) | Yue Yin, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Toward Enabling Natural Conversation with Older Adults via the Design of LLM-Powered Voice Agents that Support Interruptions and Backchannels](https://doi.org/10.1145/3706598.3714228) | Chao Liu, et al. | LLM, agent |  |  | 2025.04 |
| CHI25 | [Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making](https://doi.org/10.1145/3706598.3713423) | Shuai Ma, et al. | LLM |  |  | 2025.04 |
| CHI25 | [UXAgent: An LLM Agent-Based Usability Testing Framework for Web Design](https://doi.org/10.1145/3706599.3719729) | Yuxuan Lu, et al. | LLM, agent |  |  | 2025.04 |
| CHI25 | [Understanding the Effects of Large Language Model (LLM)-driven Adversarial Social Influences in Online Information Spread](https://doi.org/10.1145/3706599.3720019) | Zhuoran Lu, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review](https://doi.org/10.1145/3706598.3713726) | Rock Yuren Pang, et al. | LLM, HCI, CHI, survey, systematic review |  |  | 2025.04 |
| CHI25 | [Unlocking Scientific Concepts: How Effective Are LLM-Generated Analogies for Student Understanding and Classroom Practice?](https://doi.org/10.1145/3706598.3714313) | Zekai Shao, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Unpacking Trust Dynamics in the LLM Supply Chain: An Empirical Exploration to Foster Trustworthy LLM Production & Use](https://doi.org/10.1145/3706598.3713787) | Agathe Balayn, et al. | LLM |  |  | 2025.04 |
| CHI25 | [User Experience with LLM-powered Conversational Recommendation Systems: A Case of Music Recommendation](https://doi.org/10.1145/3706598.3713347) | Sojeong Yun, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Users' Expectations and Practices with Agent Memory](https://doi.org/10.1145/3706599.3720158) | Brennan Jones, et al. | LLM, agent, memory, user expectations, HCI |  |  | 2025.04 |
| CHI25 | [Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective](https://doi.org/10.1145/3706599.3720291) | Pooriya Jamie, et al. | LLM, assistant |  |  | 2025.04 |
| CHI25 | [VibWalk: Mapping Lower-limb Haptic Experiences of Everyday Walking](https://doi.org/10.1145/3706598.3714254) | Authors TBD, et al. | haptic, walking, vibration, wearable, foot |  |  | 2025.04 |
| CHI25 | [Visiobo Demo: Augmenting Static Prints with Projection-based Visual Cueing and Concept Mapping via LLM Reasoning](https://doi.org/10.1145/3706599.3721169) | Jiaqi Jiang, et al. | LLM |  |  | 2025.04 |
| CHI25 | [Wearable Meets LLM for Stress Management: A Duoethnographic Study Integrating Wearable-Triggered Stressors and LLM Chatbots for Personalized Interventions](https://doi.org/10.1145/3706599.3720197) | Sameer Neupane, et al. | LLM, wearable, stress, chatbot, personalized intervention |  |  | 2025.04 |
| CHI25 | [Weaving Sound Information to Support Real-Time Sensemaking for DHH Users](https://doi.org/10.1145/3706598.3714268) | Jeremy Zhengqi Huang, et al. | sound, DHH, accessibility, AI, sensemaking |  |  | 2025.04 |
| CHI25 | [What If Smart Homes Could See Our Homes?: Exploring DIY Smart Home Building Experiences with VLM-Based Camera Sensors](https://doi.org/10.1145/3706598.3713265) | Sojeong Yun, et al. | VLM |  |  | 2025.04 |
| CHI25 | [What Social Media Use Do People Regret? An Analysis of 34K Smartphone Screenshots with Multimodal LLM](https://doi.org/10.1145/3706598.3713724) | Longjie Guo, et al. | LLM, multimodal |  |  | 2025.04 |
| CHI25 | [WritingRing: Enabling Natural Handwriting Input with a Single IMU Ring](https://doi.org/10.1145/3706598.3714066) | Xiaoying Yang, et al. | IMU, ring, handwriting, text entry, wearable |  | Single IMU ring | 2025.04 |
| CHI25 | [Your Hands Can Tell: Detecting Redirected Hand Movements in VR](https://doi.org/10.1145/3706598.3713679) | Authors TBD, et al. | VR, hand, redirection, detection |  |  | 2025.04 |
| arXiv(v1) 2025 | [Broadband shot-to-shot transient absorption anisotropy](http://arxiv.org/abs/2503.14144v1) | Maximilian Binzer, et al. | VR, AR, egocentric, motion capture, FRAME | physics.optics | The following article has been submitted to The Journal of Physical Chemistry. After it is published, it will be found at https://pubs.aip.org/aip/jcp | 2025.03 |
| IUI25 | [CAIM: A Cognitive AI Memory Framework for Long-term Interaction with LLMs](https://doi.org/10.1145/3708557.3716342) | Rebecca Westhäußer, et al. | LLM, memory, long-term interaction, framework |  |  | 2025.03 |
| Ubicomp25 (IMWUT Vol 9 Issue 1) | [HandSAW: Wearable Hand-based Event Recognition via On-Body Surface Acoustic Waves](https://doi.org/10.1145/3712276) | Kaylee Yaxuan Li, et al. | SAW, wrist, hand, object interaction, wearable |  |  | 2025.03 |
| arXiv(v2) 2025 | [Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions](http://arxiv.org/abs/2410.13788v2) | Michael J. Q. Zhang, et al. | IMU, diffusion, pose estimation, loose sensor | cs.CL | Presented at ICLR 2025 | 2025.03 |
| IUI25 | [NoTeeline: Supporting Real-Time, Personalized Notetaking with LLM-Enhanced Micronotes](https://doi.org/10.1145/3708359.3712086) | Faria Huq, et al. | LLM, note-taking, personalization, real-time, micronotes |  |  | 2025.03 |
| Ubicomp25 (IMWUT Vol 9 Issue 1) | [Respiration Rate Estimation via Smartwatch-based PPG and Accelerometer Data](https://doi.org/10.1145/3712280) | Authors TBD, et al. | respiration, smartwatch, PPG, accelerometer, transfer learning |  |  | 2025.03 |
| Ubicomp25 (IMWUT Vol 9 Issue 1) | [SocialMind: LLM-based Proactive AR Social Assistive System with Human-like Perception for In-situ Live Interactions](https://doi.org/10.1145/3712286) | Bufang Yang, et al. | LLM, AR, social assistive, proactive |  |  | 2025.03 |
| TEI25 | [Tangible LLMs: Tangible Sense-Making For Trustworthy Large Language Models](https://doi.org/10.1145/3689050.3708338) | Authors TBD, et al. | LLM, tangible, trustworthy AI, physical interface |  |  | 2025.02 |
| CSCW24 | [Is Human-AI Interaction CSCW?](https://doi.org/10.1145/3678884.3689134) | Meredith Ringel Morris, et al. | human-AI collaboration, CSCW, LLM, panel |  | Panel discussion | 2024.11 |
| Ubicomp24 (IMWUT Vol 8 Issue 4) | [Ring-a-Pose: A Ring for Continuous Hand Pose Tracking](https://doi.org/10.1145/3699741) | Tianhong Catherine Yu, et al. | ring, hand pose, tracking, wearable |  |  | 2024.11 |
| Ubicomp24 | [Sensor2Text: Enabling Natural Language Interactions for Daily Activity Tracking Using Wearable Sensors](https://doi.org/10.1145/3699747) | Wenqiang Chen, et al. | LLM, wearable, natural language, activity tracking |  |  | 2024.11 |
| Ubicomp24 | [Leveraging LLMs to Predict Affective States via Smartphone Sensor Features](https://doi.org/10.1145/3675094.3678420) | Authors TBD, et al. | LLM, smartphone, sensing, affective state, digital phenotyping |  | First LLM work for affective state prediction | 2024.10 |
| Ubicomp24 | [Leveraging Large Language Models for Generating Mobile Sensing Strategies in Human Behavior Modeling](https://doi.org/10.1145/3675094.3678423) | Authors TBD, et al. | LLM, mobile sensing, behavior modeling, strategy generation |  |  | 2024.10 |
| UIST24 | [Patchview: LLM-powered Worldbuilding with Generative Dust and Magnet Visualization](https://doi.org/10.1145/3654777.3676352) | Jeongyeon Kim, et al. | LLM, worldbuilding, writing, creative, visualization |  |  | 2024.10 |
| UIST24 | [SHAPE-IT: Exploring Text-to-Shape-Display for Generative Shape-Changing Behaviors with LLMs](https://doi.org/10.1145/3654777.3676348) | Wanli Qian, et al. | LLM, shape display, tangible, generative, text-to-shape |  | AI-chaining approach | 2024.10 |
| UIST24 | [SituationAdapt: Contextual UI Optimization in Mixed Reality with Situation Awareness via LLM Reasoning](https://doi.org/10.1145/3654777.3676470) | Zhipeng Li, et al. | LLM, MR, UI, adaptive, context-aware, mixed reality |  |  | 2024.10 |
| UIST24 | [VizAbility: Enhancing Chart Accessibility with LLM-based Conversational Interaction](https://doi.org/10.1145/3654777.3676414) | Mandi Cai, et al. | LLM, accessibility, chart, visualization, conversational |  |  | 2024.10 |
| Ubicomp24 (IMWUT Vol 8 Issue 3) | [IMUGPT 2.0: Language-Based Cross Modality Transfer for Sensor-Based Human Activity Recognition](https://doi.org/10.1145/3678545) | Zikang Leng, et al. | IMU, LLM, HAR, cross-modality, motion synthesis |  | 20 citations | 2024.09 |
| arXiv(v1) 2024 | [WheelPoser: Sparse-IMU Based Body Pose Estimation for Wheelchair Users](http://arxiv.org/abs/2409.08494v1) | Yunzhi Li, et al. | IMU, pose estimation, wheelchair, accessibility | cs.GR, cs.CV, cs.HC | Accepted by ASSETS 2024 | 2024.09 |
| arXiv(v1) 2024 | [EMHI: A Multimodal Egocentric Human Motion Dataset with HMD and Body-Worn IMUs](http://arxiv.org/abs/2408.17168v1) | Zelin Ye, et al. | IMU, VR, HMD, dataset, egocentric, pose estimation | cs.CV, cs.HC | 885 sequences, 58 subjects, 28.5 hours | 2024.08 |
| arXiv(v1) 2024 | [Evaluating Text Classification Robustness to Part-of-Speech Adversarial Examples](http://arxiv.org/abs/2408.08374v1) | Anahita Samadi, et al. | IMU, transformer, pose estimation, calibration | cs.CL, cs.LG |  | 2024.08 |
| CHI24 | ["My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents](https://doi.org/10.1145/3613905.3650839) | Yuki Hou, et al. | LLM, agent, memory, recall, consolidation |  |  | 2024.05 |
| CHI24 | [As an AI language model I cannot: Investigating LLM Denials of User Requests](https://doi.org/10.1145/3613904.3642135) | Authors TBD, et al. | LLM, denial, user request, perception |  |  | 2024.05 |
| CHI24 | [Bridging the Gulf of Envisioning: Cognitive Challenges in Prompt Based Interactions with LLMs](https://doi.org/10.1145/3613904.3642754) | Authors TBD, et al. | LLM, prompt, cognitive challenges, user study |  |  | 2024.05 |
| CHI24 | [ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions](https://doi.org/10.1145/3613904.3642152) | Authors TBD, et al. | LLM, chatbot, children, emotion, conversation |  |  | 2024.05 |
| CHI24 | [CharacterMeet: Supporting Creative Writers' Character Construction Through LLM-Powered Chatbot Avatars](https://doi.org/10.1145/3613904.3642105) | Authors TBD, et al. | LLM, chatbot, creative writing, character design |  |  | 2024.05 |
| arXiv(v2) 2024 | [Finding Candidate TeV Halos among Very-High Energy Sources](http://arxiv.org/abs/2403.16074v2) | Dong Zheng, et al. | VR, AR, egocentric, pose estimation | astro-ph.HE | 15 pages, 7 figures, 4 tables, referee's comments incorporated, accepted for publication in ApJ | 2024.05 |
| CHI24 | [How AI Processing Delays Foster Creativity: CoQuest](https://doi.org/10.1145/3613904.3642698) | Authors TBD, et al. | LLM, agent, research question, creativity, co-creation |  |  | 2024.05 |
| CHI24 | [Learning Agent-based Modeling with LLM Companions: ChatGPT and NetLogo Chat](https://doi.org/10.1145/3613904.3642377) | Authors TBD, et al. | LLM, agent-based modeling, NetLogo, learning |  |  | 2024.05 |
| CHI24 | [The HaLLMark Effect: Supporting Provenance and Transparent Use of LLMs in Writing](https://doi.org/10.1145/3613904.3641895) | Authors TBD, et al. | LLM, writing, provenance, visualization, transparency |  |  | 2024.05 |
| CHI24 | [Towards Robotic Companions: Understanding Handler-Guide Dog Interactions for Informed Guide Dog Robot Design](https://doi.org/10.1145/3613904.3642181) | Hochul Hwang, et al. | LLM, HCI, CHI, interaction |  |  | 2024.05 |
| CHI24 | [Understanding the Impact of Long-Term Memory on Self-Disclosure with LLM-Driven Chatbots](https://doi.org/10.1145/3613904.3642420) | Authors TBD, et al. | LLM, chatbot, long-term memory, self-disclosure, health |  |  | 2024.05 |
| arXiv(v1) 2024 | [Exploring Text-to-Motion Generation with Human Preference](http://arxiv.org/abs/2404.09445v1) | Jenny Sheng, et al. | IMU, human object interaction, dataset | cs.LG, cs.AI, cs.CV | Accepted to CVPR 2024 HuMoGen Workshop | 2024.04 |
| arXiv(v2) 2024 | [Health-LLM: Large Language Models for Health Prediction via Wearable Sensor Data](http://arxiv.org/abs/2401.06866v2) | Yubin Kim, et al. | LLM, wearable, health prediction | cs.CL, cs.AI, cs.LG |  | 2024.04 |
| arXiv(v2) 2024 | [PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models](http://arxiv.org/abs/2404.15549v2) | Shashi Kant Gupta, et al. | IMU, RGB, HOI, dataset, tracking | cs.CL, cs.AI | 30 Pages, 8 Figures, Supplementary Work Attached | 2024.04 |
| arXiv(v1) 2024 | [Bayesian Learned Models Can Detect Adversarial Malware For Free](http://arxiv.org/abs/2403.18309v1) | Bao Gia Doan, et al. | VR, AR, simulated avatar, headset | cs.CR | Accepted to the 29th European Symposium on Research in Computer Security (ESORICS) 2024 Conference | 2024.03 |
| Ubicomp24 (IMWUT Vol 8 Issue 1) | [Capturing the College Experience: A Four-Year Mobile Sensing Study of Mental Health](https://doi.org/10.1145/3643501) | Authors TBD, et al. | mobile sensing, mental health, college, longitudinal |  | 19 citations | 2024.03 |
| arXiv(v1) (CVPR24) | [Dynamic Inertial Poser (DynaIP): Part-Based Motion Dynamics Learning for Enhanced Human Pose Estimation with Sparse Inertial Sensors](https://arxiv.org/abs/2312.02196) | Yu Zhang, et al. | IMU, sparse inertial sensors | cs.CV |  | 2024.03 |
| Ubicomp24 | [HyperHAR](https://doi.org/10.1145/3643511) | Nafees Ahmad, et al. | LLM, passive sensing, sensemaking |  |  | 2024.03 |
| arXiv(v1) 2024 | [LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices](http://arxiv.org/abs/2403.18173v1) | Neda Taghizadeh Serajeh, et al. | VR, AR, avatar control, pose estimation | cs.HC, cs.IR | 5 pages, CHI2024 Workshop on LLMs as Research Tools: Applications and Evaluations in HCI Data Work | 2024.03 |
| arXiv(v1) 2024 | [Modeling and optimization for arrays of water turbine OWC devices](http://arxiv.org/abs/2403.14509v1) | M. Gambarini, et al. | VR, AR, motion capture, egocentric, stereo camera | math.OC, physics.flu-dyn |  | 2024.03 |
| arXiv(v1) 2024 | [Modeling stock price dynamics on the Ghana Stock Exchange: A Geometric Brownian Motion approach](http://arxiv.org/abs/2403.13192v1) | Dennis Lartey Quayesam, et al. | VR, AR, motion capture, egocentric | math.OC, q-fin.ST |  | 2024.03 |
| arXiv(v1) 2024 | [On depth prediction for autonomous driving using self-supervised learning](http://arxiv.org/abs/2403.06194v1) | Houssem Boulahbal, et al. | VR, AR, avatar, pose estimation, headset | cs.CV | PhD thesis | 2024.03 |
| Ubicomp24 | [ViObject](https://doi.org/10.1145/3643547) | Wenqiang Chen, et al. | mental health, LLM, text data |  |  | 2024.03 |
| arXiv(v1) 2024 | [IMUGPT 2.0: Language-Based Cross Modality Transfer for Sensor-Based Human Activity Recognition](http://arxiv.org/abs/2402.01049v1) | Zikang Leng, et al. | IMU, LLM, cross-modality, HAR | cs.CV |  | 2024.02 |
| arXiv(v2) 2024 | [IMUOptimize: A Data-Driven Approach to Optimal IMU Placement for Human Pose Estimation with Transformer Architecture](https://arxiv.org/abs/2402.08923) | Varun Ramani, et al. | IMU, transformer, interpretability, data driven, time series | cs.LG |  | 2024.02 |
| arXiv(v1) 2024 | [IMUSIC: IMU-based Facial Expression Capture](https://arxiv.org/abs/2402.03944) | Youjia Wang, et al. | IMU, generation, simulate, transformer diffusion | cs.CV | code coming soon ([link](https://sites.google.com/view/projectpage-imusic)) | 2024.02 |
| Ubicomp23 | [CAvatar](https://doi.org/10.1145/3631424) | Wenqiang Chen, et al. | human activity, 3D mesh, tactile, pressure |  |  | 2023.12 |
| Ubicomp23 | [A Data-Driven Context-Aware Health Inference System for Children during School Closures](https://dl.acm.org/doi/10.1145/3580800) |  | data analysis, school closures, health inference, risk factor analysis |  |  |  |
| Ubicomp23 | [Abacus Gestures: A Large Set of Math-Based Usable Finger-Counting Gestures for Mid-Air Interactions](https://dl.acm.org/doi/10.1145/3610898) |  | vision, mid-air, gesture interaction, math, finger counting, abacus |  |  |  |
| ISWC 2023 | [C-Auth: Exploring the Feasibility of Using Egocentric View of Face Contour for User Authentication on Glasses](https://dl.acm.org/doi/10.1145/3594738.3611355) |  | smart glasses, authentication, ecocentric view |  |  |  |
| Ubicomp24 | [CAvatar: Real-time Human Activity Mesh Reconstruction via Tactile Carpets](https://dl.acm.org/doi/pdf/10.1145/3631424) |  | human activity reconstruction, 3D human mesh, pressure and vibrations, tactile sensor |  |  |  |
| Ubicomp23 | [Contact Tracing for Healthcare Workers in an Intensive Care Unit](https://dl.acm.org/doi/10.1145/3610924) |  | contact Tracing, Internet of things (IoT), bluetooth low energy, Covid-19 |  |  |  |
| Ubicomp23 | [DRG-Keyboard: Enabling Subtle Gesture Typing on the Fingertip with Dual IMU Rings](https://dl.acm.org/doi/10.1145/3569463) |  | text entry, gesture keyboard, fingertip interaction, smart ring |  |  |  |
| arXiv(v5) 2024 | [Evaluating Human-Language Model Interaction](https://arxiv.org/abs/2212.09746) | Mina Lee, et al. | LM, human-centered, evaluation | cs.CL |  |  |
| Ubicomp23 | [Exploring the Opportunities of AR for Enriching Storytelling with Family Photos between Grandparents and Grandchildren](https://dl.acm.org/doi/abs/10.1145/3610903) |  | AR, storytelling, intergenerational communication |  |  |  |
| Ubicomp23 | [Fingerprinting IoT Devices Using Latent Physical Side-Channels](https://dl.acm.org/doi/abs/10.1145/3596247) |  | physical side-channels, fingerprinting, internet-of-things |  |  |  |
| Ubicomp23 | [From 2D to 3D: Facilitating Single-Finger Mid-Air Typing on QWERTY Keyboards with Probabilistic Touch Modeling](https://dl.acm.org/doi/10.1145/3580829) |  | mid air, text entry, VR |  |  |  |
| Ubicomp23 | [GC-Loc: A Graph Attention Based Framework for Collaborative Indoor Localization Using Infrastructure-free Signals](https://dl.acm.org/doi/10.1145/3569495) |  | collaborative indoor localization, graph neural network, geomagnetism |  |  |  |
| Ubicomp23 | [GLOBEM: Cross-Dataset Generalization of Longitudinal Human Behavior Modeling](https://dl.acm.org/doi/10.1145/3569485) |  | generalizability, behavior modeling, passive sensing |  |  |  |
| Ubicomp23 | HIPPO: Pervasive Hand-Grip Estimation from Everyday Interactions |  |  |  |  |  |
| arXiv(v1) (CHI23) | [HOOV: Hand Out-Of-View Tracking for Proprioceptive Interaction using Inertial Sensing](https://arxiv.org/abs/2303.07016) | Paul Streli, et al. | IMU, VR, transformer | cs.HC, cs.CV, I.2; I.5; H.5 |  |  |
| Ubicomp23 | [Headar: Sensing Head Gestures for Confirmation Dialogs on Smartwatches with Wearable Millimeter-Wave Radar](https://dl.acm.org/doi/abs/10.1145/3610900) |  | wearable interaction, gestural input, millimeter-wave radar, head gestures, smartwatch |  |  |  |
| Ubicomp23 | [HyWay: Enabling Mingling in the Hybrid World∗](https://dl.acm.org/doi/abs/10.1145/3596235) |  | hybrid mingling, unstructured and semi-structured conversations, awareness, agency, porosity, reciprocity |  |  |  |
| Ubicomp23 | [I Know Your Intent: Graph-enhanced Intent-aware User Device Interaction Prediction via Contrastive Learning](https://dl.acm.org/doi/10.1145/3610906) |  | user device interaction, graph, attention, contrastive learning |  |  |  |
| Ubicomp22 | [IF-ConvTransformer: A Framework for Human Activity Recognition Using IMU Fusion and ConvTransformer](https://dl.acm.org/doi/10.1145/3534584) |  | IMU, fusion, multimodal, transformer, attention |  |  |  |
| arXiv(v1) (CHI23) | [IMUPoser: Full-Body Pose Estimation using IMUs in Phones, Watches, and Earbuds](https://arxiv.org/abs/2304.12518) | Vimal Mollyn, et al. | IMU, pose estimation, BiLSTM | cs.HC, cs.CV |  |  |
| Ubicomp23 | LT-Fall: The Design and Implementation of a Life-threatening Fall Detection and Alarming System |  |  |  |  |  |
| Ubicomp23 | [LapTouch: Using the Lap for Seated Touch Interaction with HMDs](https://dl.acm.org/doi/10.1145/3610878) |  | VR, seated, touch, on-body |  |  |  |
| Ubicomp23 | [MI-Poser: Human Body Pose Tracking Using Magnetic and Inertial Sensor Fusion with Metal Interference Mitigation](https://dl.acm.org/doi/10.1145/3610891) |  | EMF, body pose tracking, inverse kinematics, sensor fusion |  |  |  |
| Ubicomp24 | Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data |  |  |  |  |  |
| Ubicomp23 | [MoCaPose: Motion Capturing with Textile-integrated Capacitive Sensors in Loose-fitting Smart Garments](https://dl.acm.org/doi/abs/10.1145/3580883) |  | motion capture, wearable sensing, capacitive sensing, deep learning, motion tracking, smart textile |  |  |  |
| Ubicomp23 | [N-euro Predictor: A Neural Network Approach for Smoothing and Predicting Motion Trajectory](https://dl.acm.org/doi/10.1145/3610884) |  | vision-based interactions, motion-to-photon latency, motion prediction, neural network, perceived jitter and lag |  |  |  |
| Ubicomp23 | [NF-Heart: A Near-field Non-contact Continuous User Authentication System via Ballistocardiogram](https://dl.acm.org/doi/10.1145/3580851) |  | continuous authentication, ballistocardiogram (BCG), biometrics, non-contact sensing, smart chair |  |  |  |
| Ubicomp23 | [Naturalistic E-Scooter Maneuver Recognition with Federated Contrastive Rider Interaction Learning](https://dl.acm.org/doi/10.1145/3570345) |  | IMU, DCT, contrastive learning, asynchronous federated learning, ehavior analysis |  |  |  |
| ISWC 2023 | [On the Utility of Virtual On-body Acceleration Data for Fine-grained Human Activity Recognition](https://dl.acm.org/doi/10.1145/3594738.3611364) |  | HAR, virtual, IMU |  |  |  |
| Ubicomp23 | [PoseSonic: 3D Upper Body Pose Estimation Through Egocentric Acoustic Sensing on Smartglasses](https://dl.acm.org/doi/abs/10.1145/3610895?af=R) |  | human pose estimation, acoustic sensing, smart/AR glasses, deep learning, cross-modal supervision |  |  |  |
| Ubicomp23 | [PrintShear: Shear Input Based on Fingerprint Deformation](https://dl.acm.org/doi/10.1145/3596257) |  | touch, finger input |  |  |  |
| Ubicomp23 | [Privacy-Enhancing Technology and Everyday Augmented Reality: Understanding Bystanders’ Varying Needs for Awareness and Consent](https://dl.acm.org/doi/10.1145/3569501) |  | AR, privacy, bystanders, altered reality, extended perception, biometrics |  |  |  |
| Ubicomp23 | Radio2Text: Streaming Speech Recognition Using mmWave Radio Signals |  |  |  |  |  |
| Ubicomp23 | SkinLink: On-body Construction and Prototyping of Reconfigurable Epidermal Interfaces |  |  |  |  |  |
| Ubicomp23 | [Spectral-Loc: Indoor Localization Using Light Spectral Information](https://dl.acm.org/doi/10.1145/3580878) |  | indoor localization, spectral information, ambient light |  |  |  |
| Ubicomp23 | [StructureSense: Inferring Constructive Assembly Structures from User Behaviors](https://dl.acm.org/doi/10.1145/3570343) |  | tangible user interfaces, TUI, RFID, user modeling, bayesian inference |  |  |  |
| Ubicomp23 | [Synthetic Smartwatch IMU Data Generation from In-the-wild ASL Videos](https://dl.acm.org/doi/abs/10.1145/3596261) |  | IMU, synthetic, ASL recognition |  |  |  |
| Ubicomp23 | [TAO: Context Detection from Daily Activity Patterns Using Temporal Analysis and Ontology](https://dl.acm.org/doi/abs/10.1145/3610896) |  | behavioral context recognition, activity recognition, ontology, deep learning |  |  |  |
| Ubicomp23 | [ThumbAir: In-Air Typing for Head Mounted Displays](https://dl.acm.org/doi/10.1145/3569474) |  | mid air, text entry, VR, HMD, user study |  |  |  |
| ISWC 2023 | Towards a Haptic Taxonomy of Emotions: Exploring Vibrotactile Stimulation in the Dorsal Region |  |  |  |  |  |
| Ubicomp23 | [TwinkleTwinkle: Interacting with Your Smart Devices by Eye Blink](https://dl.acm.org/doi/abs/10.1145/3596238) |  | acoustic sensing, eye blink, signal process |  |  |  |
| Ubicomp23 | [ViSig: Automatic Interpretation of Visual Body Signals Using On-Body Sensors](https://dl.acm.org/doi/10.1145/3580797) |  | visual signalling, on-body sensors, UWB, IMU, body signals, fallback communication, sports automation, postures, gestures |  |  |  |
| Ubicomp23 | [VibPath: Two-Factor Authentication with Your Hand's Vibration Response to Unlock Your Phone](https://dl.acm.org/doi/10.1145/3610894) |  | user authentication, vibration, IMU, smartphone, wearables, smartwatch |  |  |  |
| Ubicomp23 | [Voicify Your UI: Towards Android App Control with Voice Commands](https://dl.acm.org/doi/10.1145/3581998) |  | design, smartphones, sound-based input, dl parser, UI |  |  |  |
| Ubicomp23 | [WristAcoustic: Through-Wrist Acoustic Response Based Authentication for Smartwatches](https://dl.acm.org/doi/10.1145/3569473) |  | smartwatch authentication, bone conduction, acoustic response |  |  |  |
| Ubicomp23 | [sUrban: Stable Prediction for Unseen Urban Data from Location-based Sensors](https://dl.acm.org/doi/abs/10.1145/3610877) |  | urban computing, location-based data, spatial-temporal prediction, out-of-distribution data |  |  |  |
<!-- TABLE_END: HCI -->

# LLM
<!-- TABLE_START: LLM -->
| Source | Title (Link) | Authors | Tag | Subjects | Additional info | Date |
|---|---|---|---|---|---|---|
| arXiv(v1) 2026 | [GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents](http://arxiv.org/abs/2601.09770v1) | Shuofei Qiao, et al. | GUI agent, visual grounding, tool use, perception | cs.CV, cs.AI |  | 2026.01 |
| arXiv(v1) 2025 (WACV 2026) | [AFRAgent: An Adaptive Feature Renormalization Based High Resolution Aware GUI agent](http://arxiv.org/abs/2512.00846v1) | Neeraj Anand, et al. | GUI agent, VLM, smartphone automation, multimodal | cs.CV | WACV 2026 | 2025.12 |
| arXiv(v2) 2025 | [Mobile-Agent-v3: Fundamental Agents for GUI Automation](http://arxiv.org/abs/2508.15144v2) | Junyang Wang, et al. | GUI agent, mobile, smartphone automation, VLM | cs.CV, cs.AI |  | 2025.08 |
| arXiv(v6) 2025 | [LLaVA-CoT: Let Vision Language Models Reason Step-by-Step](http://arxiv.org/abs/2411.10440v6) | Guowei Xu, et al. | LLM, GUI agent, survey, computer use | cs.CV | 17 pages, ICCV 2025 | 2025.07 |
| arXiv(v3) 2025 | [Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs](http://arxiv.org/abs/2410.16135v3) | Kang Zhao, et al. | LLM, GUI agent, interface | cs.LG, cs.AI |  | 2025.06 |
| arXiv(v3) 2025 | [Lai Loss: A Novel Loss for Gradient Control](http://arxiv.org/abs/2405.07884v3) | YuFei Lai, et al. | LLM, agent, interface, UI | cs.LG | The experiment in this article is not very rigorous and may require further testing for its effectiveness | 2025.05 |
| arXiv(v3) 2025 | [SignLLM: Sign Language Production Large Language Models](http://arxiv.org/abs/2405.10718v3) | Sen Fang, et al. | LLM, agent, user interface, HCI, interaction | cs.CV, cs.CL | website at https://signllm.github.io/ | 2025.04 |
| arXiv(v1) 2024 | [ShowUI: One Vision-Language-Action Model for GUI Visual Agent](http://arxiv.org/abs/2411.17465v1) | Kevin Qinghong Lin, et al. | LLM, UI, vision-language, GUI | cs.CV, cs.AI, cs.CL, cs.HC | Technical Report. Github: https://github.com/showlab/ShowUI | 2024.11 |
| arXiv(v1) 2024 | [A Scalable Communication Protocol for Networks of Large Language Models](http://arxiv.org/abs/2410.11905v1) | Samuele Marro, et al. | LLM, agent, GUI, computer use, interface | cs.AI, cs.LG |  | 2024.10 |
| arXiv(v1) 2024 | [In-Band Full-Duplex MIMO Systems for Simultaneous Communications and Sensing: Challenges, Methods, and Future Perspectives](http://arxiv.org/abs/2410.06512v1) | Besma Smida, et al. | LLM, GUI agent, computer use | cs.IT, cs.ET, eess.SP | 12 pages, 5 figures, White Paper to appear at IEEE SPM | 2024.10 |
| arXiv(v2) 2024 | [Massively parallel CMA-ES with increasing population](http://arxiv.org/abs/2409.11765v2) | David Redon, et al. | LLM, agent, HCI, user interface | cs.DC |  | 2024.10 |
| arXiv(v1) 2024 | [OS-ATLAS: A Foundation Action Model for Generalist GUI Agents](http://arxiv.org/abs/2410.23218v1) | Zhiyong Wu, et al. | LLM, agent, computer use, GUI, foundation model | cs.CL, cs.CV, cs.HC |  | 2024.10 |
| arXiv(v1) 2024 | [OrientedFormer: An End-to-End Transformer-Based Oriented Object Detector in Remote Sensing Images](http://arxiv.org/abs/2409.19648v1) | Jiaqi Zhao, et al. | LLM, agent, GUI, interface | cs.CV | The paper is accepted by IEEE Transactions on Geoscience and Remote Sensing (TGRS) | 2024.09 |
| arXiv(v1) 2024 | [Unlocking the Power of Environment Assumptions for Unit Proofs](http://arxiv.org/abs/2409.12269v1) | Siddharth Priya, et al. | LLM, GUI, agent, survey | cs.SE, cs.PL | SEFM 2024 | 2024.09 |
| arXiv(v2) 2024 (ACL 2025) | [GUICourse: From General Vision Language Models to Versatile GUI Agents](http://arxiv.org/abs/2406.11317v2) | Wentong Chen, et al. | GUI agent, VLM, training data, OCR, grounding | cs.CV, cs.CL, cs.HC | ACL 2025 | 2024.06 |
| arXiv(v1) 2024 | [Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs](https://arxiv.org/abs/2404.05719) | Keen You, et al. | ui, mllm, benchmark, any-resolution | cs.CV, cs.CL, cs.HC |  | 2024.04 |
| arXiv(v1) 2024 | [Are You Being Tracked? Discover the Power of Zero-Shot Trajectory Tracing with LLMs!](https://arxiv.org/abs/2403.06201) | Huanqi Yang, et al. | iot, imu, cot, prompt | cs.CL, cs.AI, cs.HC, cs.LG |  | 2024.03 |
| arXiv(v1) 2024 | [Design2Code: How Far Are We From Automating Front-End Engineering?](https://arxiv.org/abs/2403.03163) | Chenglei Si, et al. | llm, auto, google | cs.CL, cs.CV, cs.CY |  | 2024.03 |
| arXiv(v2) 2023 | [The Good, The Bad, and Why: Unveiling Emotions in Generative AI](https://arxiv.org/abs/2312.11111) | Cheng Li, et al. | emotion, prompt, attack, decode | cs.AI, cs.CL, cs.HC | extension of Large language models understand and can be enhanced by emotional stimuli | 2023.12 |
| arXiv(v1) (NIPS23) | [Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias](https://arxiv.org/abs/2306.15895) | Yue Yu, et al. | synthetic data generation | cs.CL, cs.AI, cs.LG |  | arXiv(v2) 2023.10 |
| arXiv(v1) 2023 | [Multimodal Foundation Models: From Specialists to General-Purpose Assistants](https://arxiv.org/abs/2309.10020) | Chunyuan Li, et al. | survey | cs.CV, cs.CL |  | 2023.09 |
| arXiv(v7) 2023 | [Attention Is All You Need](http://arxiv.org/abs/1706.03762v7) | Ashish Vaswani, et al. | arxiv | cs.CL, cs.LG | 15 pages, 5 figures | 2023.08 |
<!-- TABLE_END: LLM -->

# RAG
<!-- TABLE_START: RAG -->
| Source | Title (Link) | Authors | Tag | Subjects | Additional info | Date |
|---|---|---|---|---|---|---|
| arXiv(v1) 2026 | [L-RAG: Balancing Context and Retrieval with Entropy-Based Lazy Loading](http://arxiv.org/abs/2601.06551v1) | Authors TBD, et al. | RAG, lazy loading, entropy, context | cs.CL, cs.IR |  | 2026.01 |
| arXiv(v1) 2025 | [RAGLens: Toward Faithful RAG with Sparse Autoencoders](http://arxiv.org/abs/2512.08892v1) | Authors TBD, et al. | RAG, hallucination, faithfulness, detection | cs.CL |  | 2025.12 |
| arXiv(v1) 2025 | [CDTA: Cross-Document Topic-Aligned Chunking for RAG](http://arxiv.org/abs/2601.05265v1) | Authors TBD, et al. | RAG, chunking, cross-document, topic alignment | cs.CL, cs.IR | 0.93 faithfulness on HotpotQA | 2025.11 |
| arXiv(v1) 2025 | [Agentic RAG for Fintech: Design and Evaluation](http://arxiv.org/abs/2510.25518v1) | Authors TBD, et al. | RAG, agentic, fintech, query reformulation | cs.CL, cs.IR |  | 2025.10 |
| arXiv(v1) 2025 | [Practical Code RAG at Scale: Task-Aware Retrieval Design](http://arxiv.org/abs/2510.20609v1) | Authors TBD, et al. | RAG, code, retrieval, hybrid, dense | cs.CL, cs.IR | BM25 + dense hybrid | 2025.10 |
| arXiv(v1) 2025 | [A Systematic Review of Key RAG Systems: Progress, Gaps, and Future Directions](http://arxiv.org/abs/2507.18910v1) | Authors TBD, et al. | RAG, survey, systematic review, knowledge base | cs.CL, cs.IR |  | 2025.07 |
| arXiv(v1) 2025 | [Late Chunking: Contextual Chunk Embeddings for RAG](http://arxiv.org/abs/2409.04701v3) | Authors TBD, et al. | RAG, chunking, embedding, contextual | cs.CL, cs.IR | Updated July 2025 | 2025.07 |
| arXiv(v1) 2025 | [GraphRAG-Bench: When to Use Graphs in RAG](http://arxiv.org/abs/2506.05690v1) | Authors TBD, et al. | RAG, graph, benchmark, evaluation | cs.CL, cs.IR |  | 2025.06 |
| arXiv(v1) 2025 | [RAG Survey: Architectures, Enhancements, and Robustness Frontiers](http://arxiv.org/abs/2506.00054v1) | Authors TBD, et al. | RAG, survey, architecture, robustness | cs.CL, cs.IR |  | 2025.06 |
| arXiv(v1) 2025 | [Rethinking Chunk Size for Long-Document Retrieval: Multi-Dataset Analysis](http://arxiv.org/abs/2505.21700v2) | Authors TBD, et al. | RAG, chunking, chunk size, retrieval | cs.CL, cs.IR | 64-1024 tokens optimal | 2025.05 |
| arXiv(v1) 2025 | [A Survey of Multimodal Retrieval-Augmented Generation](http://arxiv.org/abs/2504.08748v1) | Zihan Zhao, et al. | multimodal, RAG, retrieval, survey, vision-language | cs.CV, cs.CL |  | 2025.04 |
| arXiv(v1) 2025 | [RAG Evaluation in the Era of LLMs: A Comprehensive Survey](http://arxiv.org/abs/2504.14891v1) | Authors TBD, et al. | RAG, evaluation, benchmark, LLM | cs.CL, cs.IR |  | 2025.04 |
| arXiv(v1) 2025 | [HiRAG: Retrieval-Augmented Generation with Hierarchical Knowledge](http://arxiv.org/abs/2503.10150v1) | Authors TBD, et al. | RAG, hierarchical, knowledge, indexing | cs.CL, cs.IR |  | 2025.03 |
| arXiv(v1) 2025 | [Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation](http://arxiv.org/abs/2502.08826v1) | Zihan Wang, et al. | multimodal, RAG, retrieval, survey, LLM | cs.CL, cs.IR |  | 2025.02 |
| arXiv(v1) 2025 | [GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation](http://arxiv.org/abs/2502.01113v1) | Authors TBD, et al. | RAG, graph, foundation model, knowledge graph | cs.CL, cs.IR | 8M params, 60 KGs, 14M triples | 2025.02 |
| arXiv(v1) 2025 | [KG2RAG: Knowledge Graph-Guided Retrieval Augmented Generation](http://arxiv.org/abs/2502.06864v1) | Authors TBD, et al. | RAG, knowledge graph, retrieval, fact-level | cs.CL, cs.IR |  | 2025.02 |
| arXiv(v1) 2025 | [RAG-Fusion: Query Expansion and Multi-Source Retrieval](http://arxiv.org/abs/2502.08541v1) | Authors TBD, et al. | RAG, query expansion, multi-source, fusion | cs.CL, cs.IR |  | 2025.02 |
| arXiv(v1) 2025 | [Vendi-RAG: Adaptively Trading Off Diversity and Quality in RAG](http://arxiv.org/abs/2502.11228v1) | Authors TBD, et al. | RAG, diversity, quality, adaptive | cs.CL, cs.IR |  | 2025.02 |
| arXiv(v1) 2025 | [Agentic RAG: A Survey](http://arxiv.org/abs/2501.09136v1) | Authors TBD, et al. | RAG, agentic, survey, LLM agent | cs.CL, cs.IR |  | 2025.01 |
| arXiv(v1) 2025 | [CG-RAG: Citation Graph RAG for Research Question Answering](http://arxiv.org/abs/2501.15067v1) | Authors TBD, et al. | RAG, citation graph, research QA | cs.CL, cs.IR |  | 2025.01 |
| arXiv(v1) 2025 | [ChunkRAG: Novel Context-Aware Chunking for RAG Systems](http://arxiv.org/abs/2501.00045v1) | Authors TBD, et al. | RAG, chunking, context-aware, retrieval | cs.CL, cs.IR |  | 2025.01 |
| arXiv(v1) 2024 | LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language Models and Doc-Level Embedding |  | relevant query, doc-Level embedding, embedding-based retrieval, dense retrieval |  |  | 2024.04 |
| arXiv(v6) 2024 | [Health-LLM: Personalized Retrieval-Augmented Disease Prediction System](https://arxiv.org/abs/2402.00746) | Qinkai Yu, et al. | RAG, XGBoost, AutoML | cs.CL |  | 2024.03 |
| arXiv(v1) 2024 | CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models |  | retrieval-augmented generation, large language models, evaluation |  |  | 2024.02 |
<!-- TABLE_END: RAG -->

# Agent
<!-- TABLE_START: Agent -->
| Source | Title (Link) | Authors | Tag | Subjects | Additional info | Date |
|---|---|---|---|---|---|---|
| arXiv(v1) 2026 | [InfiniteWeb: Scalable Web Environment Synthesis for GUI Agent Training](http://arxiv.org/abs/2601.04126v1) | Authors TBD, et al. | agent, web, GUI, training, environment | cs.CV, cs.AI | 600 tasks across websites | 2026.01 |
| arXiv(v1) 2026 | [LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities](http://arxiv.org/abs/2601.09822v1) | Authors TBD, et al. | code agent, software engineering, survey | cs.SE, cs.AI |  | 2026.01 |
| arXiv(v1) 2025 | [Beyond Task Completion: Assessment Framework for Agentic AI Systems](http://arxiv.org/abs/2512.12791v1) | Authors TBD, et al. | LLM agent, evaluation, framework, benchmark | cs.AI, cs.CL |  | 2025.12 |
| arXiv(v1) 2025 | [DeepCode: Open Agentic Coding](http://arxiv.org/abs/2512.07921v1) | Authors TBD, et al. | code agent, agentic coding, open source | cs.SE, cs.AI |  | 2025.12 |
| arXiv(v1) 2025 | [LongVideoAgent: Multi-Agent Reasoning with Long Videos](http://arxiv.org/abs/2512.20618v1) | Jingyi Zhang, et al. | multi-agent, video understanding, LLM, reasoning | cs.CV, cs.AI |  | 2025.12 |
| arXiv(v1) 2025 | [MAR: Multi-Agent Reflexion Improves Reasoning Abilities in LLMs](http://arxiv.org/abs/2512.20845v1) | Xinyuan Lu, et al. | multi-agent, LLM, reflexion, reasoning, debate | cs.CL, cs.AI |  | 2025.12 |
| arXiv(v1) 2025 | [SWE-RL: Training Superintelligent Software Agents through Self-Play](http://arxiv.org/abs/2512.18552v1) | Authors TBD, et al. | code agent, self-play, RL, software engineering | cs.SE, cs.LG |  | 2025.12 |
| arXiv(v1) 2025 | [Agent0: Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning](http://arxiv.org/abs/2511.16043v1) | Authors TBD, et al. | LLM agent, self-evolving, tool use, reasoning | cs.AI, cs.CL | 18% improvement on math, 24% on general | 2025.11 |
| arXiv(v1) 2025 | [Building Browser Agents: Architecture, Security, and Practical Solutions](http://arxiv.org/abs/2511.19477v1) | Authors TBD, et al. | agent, browser, security, architecture | cs.AI, cs.CL |  | 2025.11 |
| arXiv(v1) 2025 | [ReMA: Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation](http://arxiv.org/abs/2511.02303v1) | Zhiwei Zhang, et al. | multi-agent, LLM, reasoning, lazy agent, deliberation | cs.AI, cs.CL |  | 2025.11 |
| arXiv(v1) 2025 | [BrowserAgent: Web Agents with Human-Inspired Browsing Actions](http://arxiv.org/abs/2510.10666v1) | Authors TBD, et al. | agent, browser, web, automation | cs.AI, cs.CL |  | 2025.10 |
| arXiv(v1) 2025 | [Dark Patterns Impact on LLM-Based Web Agents](http://arxiv.org/abs/2510.18113v1) | Authors TBD, et al. | agent, web, dark patterns, decision making | cs.HC, cs.AI |  | 2025.10 |
| arXiv(v1) 2025 | [Architecting Resilient LLM Agents](http://arxiv.org/abs/2509.08646v1) | Authors TBD, et al. | LLM agent, resilience, architecture | cs.AI, cs.CL |  | 2025.09 |
| arXiv(v1) 2025 | [A Survey on Code Generation with LLM-based Agents](http://arxiv.org/abs/2508.00083v1) | Authors TBD, et al. | code agent, LLM, code generation, survey | cs.SE, cs.AI |  | 2025.08 |
| arXiv(v1) 2025 | [LLM-based Agentic Reasoning Frameworks: A Survey from Methods to Scenarios](http://arxiv.org/abs/2508.17692v1) | Bingxi Zhao, et al. | LLM, agent, reasoning, survey, framework | cs.AI, cs.CL |  | 2025.08 |
| arXiv(v1) 2025 | [MCP-Bench: Benchmarking Tool-Using LLM Agents](http://arxiv.org/abs/2508.20453v1) | Authors TBD, et al. | agent, benchmark, tool use, MCP | cs.AI, cs.CL |  | 2025.08 |
| arXiv(v4) 2025 | [Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction](http://arxiv.org/abs/2508.05294v4) | Harshitha Manoj, et al. | embodied AI, robot, LLM, VLM, autonomy, survey | cs.RO, cs.AI |  | 2025.08 |
| arXiv(v1) 2025 | [Understanding Tool-Integrated Reasoning](http://arxiv.org/abs/2508.19201v1) | Heng Lin, et al. | LLM, agent, tool use, reasoning, TIR | cs.LG, cs.AI, stat.ML |  | 2025.08 |
| arXiv(v2) 2025 | [Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools](http://arxiv.org/abs/2502.04644v2) | Junde Wu, et al. | LLM, agent, agentic reasoning, tool use, framework | cs.AI, cs.CL | ACL 2025 | 2025.07 |
| arXiv(v3) 2025 | [Embodied AI Agents: Modeling the World](http://arxiv.org/abs/2506.22355v3) | Pascale Fung, et al. | embodied AI, world model, VLM, robot, avatar | cs.AI | Meta AI | 2025.07 |
| arXiv(v1) 2025 | [Routine: A Structural Planning Framework for LLM Agent System in Enterprise](http://arxiv.org/abs/2507.14447v1) | Authors TBD, et al. | LLM agent, planning, enterprise, framework | cs.AI, cs.CL |  | 2025.07 |
| arXiv(v1) 2025 | [Toward a Theory of Agents as Tool-Use Decision-Makers](http://arxiv.org/abs/2506.00886v1) | Authors TBD, et al. | LLM agent, tool use, theory, decision making | cs.AI, cs.CL |  | 2025.06 |
| arXiv(v1) 2025 | [WebRL: Training LLM Web Agents via Self-Evolving Curriculum RL](http://arxiv.org/abs/2505.11451v1) | Authors TBD, et al. | agent, web, RL, curriculum, self-evolving | cs.LG, cs.AI |  | 2025.05 |
| arXiv(v1) 2025 | [AgentRewardBench: Benchmark for LLM Judges in Web Agent Evaluation](http://arxiv.org/abs/2504.12721v1) | Authors TBD, et al. | agent, benchmark, web, evaluation, reward | cs.AI, cs.CL | 1,302 trajectories | 2025.04 |
| arXiv(v1) 2025 | [From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review](http://arxiv.org/abs/2504.19678v1) | Mohamed Amine Ferrag, et al. | LLM, agent, survey, autonomous, comprehensive review | cs.AI, cs.LG |  | 2025.04 |
| arXiv(v1) 2024 | [Simultaneous identification of the parameters in the plasticity function for power hardening materials : A Bayesian approach](http://arxiv.org/abs/2412.05241v1) | Salih Tatar, et al. | LLM, agent, computer use, evaluation | math.NA, math.AP |  | 2024.12 |
| arXiv(v2) 2024 | [Feasibility Consistent Representation Learning for Safe Reinforcement Learning](http://arxiv.org/abs/2405.11718v2) | Zhepeng Cen, et al. | LLM, agent, UI, LAUI, interface | cs.LG | ICML 2024 | 2024.06 |
| arXiv(v1) 2024 | [DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows](https://arxiv.org/abs/2402.10379) | Ajay Patel, et al. | pipeline, liarbry, generation | cs.CL, cs.LG |  | 2024.02 |
| arXiv(v1) 2024 | [More Agents Is All You Need](https://arxiv.org/abs/2402.05120) | Junyou Li, et al. | multi agent, vote, task | cs.CL, cs.AI, cs.LG |  | 2024.02 |
| arXiv(v1) (NIPS23) | [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/abs/2303.17580) | Yongliang Shen, et al. | hugging face, API | cs.CL, cs.AI, cs.CV, cs.LG |  | 2023.12 |
| arXiv(v1) (NIPS23) | [CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society](https://arxiv.org/abs/2303.17760) | Guohao Li, et al. | role play, autonomous, user&assistant | cs.AI, cs.CL, cs.CY, cs.LG, cs.MA |  | 2023.11(v2) |
| arXiv(v2) 2023 | [MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models](https://arxiv.org/abs/2310.11954) | Dingyao Yu, et al. | pipeline | cs.CL, cs.MM, eess.AS |  | 2023.10 |
| arXiv(v2) 2023 | [VOYAGER: An Open-Ended Embodied Agent with Large Language Models](https://arxiv.org/abs/2305.16291) | Guanzhi Wang, et al. | multi, autonomous, microcraft, game | cs.AI, cs.LG |  | 2023.10 |
| arXiv(v3) 2023 | [The Rise and Potential of Large Language Model Based Agents: A Survey](https://arxiv.org/abs/2309.07864) | Zhiheng Xi, et al. | survey, [github paper list](https://github.com/WooooDyy/LLM-Agent-Paper-List) | cs.AI, cs.CL |  | 2023.09 |
| arXiv(v3) 2023 | [A Survey on Large Language Model based Autonomous Agents](https://arxiv.org/abs/2308.11432) | Lei Wang, et al. | survey, autonomous | cs.AI, cs.CL | Latest version is v4(2024.03), double columns. But v3(2023.09) single columns is easy to read. |  |
| arXiv(v1) (ICLR24) | [MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework](https://arxiv.org/abs/2308.00352) | Sirui Hong, et al. | autonomous system, SOP, multi-agent, framework | cs.AI, cs.MA |  |  |
<!-- TABLE_END: Agent -->

# Agentic-RL
<!-- TABLE_START: Agentic-RL -->
| Source | Title (Link) | Authors | Tag | Subjects | Additional info | Date |
|---|---|---|---|---|---|---|
| arXiv(v1) 2026 | [Agent Drift: Quantifying Behavioral Degradation in Multi-Agent LLM Systems Over Extended Interactions](http://arxiv.org/abs/2601.04170v1) | Abhishek Rath, et al. | multi-agent, behavioral degradation, LLM, agent | cs.AI |  | 2026.01 |
| arXiv(v5) 2026 | [AgentOrchestra: Orchestrating Multi-Agent Intelligence with the Tool-Environment-Agent(TEA) Protocol](http://arxiv.org/abs/2506.12508v5) | Wentao Zhang, et al. | hierarchical multi-agent, task solving, LLM, agent | cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity](http://arxiv.org/abs/2601.00268v1) | Doyoung Kim, et al. | evaluation, benchmark, API complexity, LLM, agent | cs.CL, cs.AI | 26 pages | 2026.01 |
| arXiv(v2) 2026 | [Cochain: Balancing Insufficient and Excessive Collaboration in LLM Agent Workflows](http://arxiv.org/abs/2505.10936v2) | Jiaxing Zhao, et al. | chain-of-collaboration, multi-agent, LLM, agent | cs.CL | 35 pages, 23 figures | 2026.01 |
| arXiv(v2) 2026 | [Collaborate, Deliberate, Evaluate: How LLM Alignment Affects Coordinated Multi-Agent Outcomes](http://arxiv.org/abs/2509.05882v2) | Abhijnan Nath, et al. | alignment, multi-agent coordination, LLM, agent | cs.CL, cs.AI, cs.LG | This submission is a new version of arXiv:2509.05882v1. with a substantially revised experimental pipeline and new metrics. In particular, collaborator agents are now instantiated independently via separate API calls, rather than generated autoregressively by a single agent. All experimental results are new. Accepted as an extended abstract at AAMAS 2026 | 2026.01 |
| arXiv(v1) 2026 | [DemMA: Dementia Multi-Turn Dialogue Agent with Expert-Guided Reasoning and Action Simulation](http://arxiv.org/abs/2601.06373v1) | Yutong Song, et al. | dementia dialogue, multi-turn, medical, LLM, agent | cs.MA |  | 2026.01 |
| arXiv(v1) 2026 | [EduSim-LLM: An Educational Platform Integrating Large Language Models and Robotic Simulation for Beginners](http://arxiv.org/abs/2601.01196v1) | Shenqi Lu, et al. | educational platform, robotics, simulation, LLM | cs.RO |  | 2026.01 |
| arXiv(v1) 2026 | [Game-Theoretic Lens on LLM-based Multi-Agent Systems](http://arxiv.org/abs/2601.15047v1) | Jianing Hao, et al. | game theory, multi-agent, LLM, agent | cs.MA, cs.GT | 9 pages, 5 figures | 2026.01 |
| arXiv(v2) 2026 (Spotlight paper of NeurIPS 2025) | [KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment](http://arxiv.org/abs/2502.06472v2) | Yuxing Lu, et al. | knowledge graph enrichment, multi-agent, LLM, agent | cs.CL, cs.AI, cs.CE, cs.DL | 24 pages, 3 figures, 2 tables | 2026.01 |
| arXiv(v1) 2026 | [LLM-in-Sandbox Elicits General Agentic Intelligence](http://arxiv.org/abs/2601.16206v1) | Daixuan Cheng, et al. | sandbox, agentic intelligence, LLM | cs.CL, cs.AI | Project Page: https://llm-in-sandbox.github.io | 2026.01 |
| arXiv(v2) 2026 | [Lifelong Learning of Large Language Model based Agents: A Roadmap](http://arxiv.org/abs/2501.07278v2) | Junhao Zheng, et al. | lifelong learning, continual learning, LLM, agent | cs.AI | Accepted to IEEE TPAMI | 2026.01 |
| arXiv(v1) 2025 | [PRL: Process Reward Learning Improves LLM Reasoning](http://arxiv.org/abs/2601.10201v1) | Authors TBD, et al. | agentic RL, PRM, process reward, reasoning | cs.LG, cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions](http://arxiv.org/abs/2601.06112v1) | Aayush Gupta, et al. | reliability evaluation, stress testing, LLM, agent | cs.AI | 18 pages, 5 figures, 8 tables. Evaluates ReAct vs Reflexion across four tool-using domains with perturbation (epsilon) and fault-injection (lambda) stress testing; 1,280 total episodes | 2026.01 |
| arXiv(v2) 2026 | [SimWorld: An Open-ended Realistic Simulator for Autonomous Agents in Physical and Social Worlds](http://arxiv.org/abs/2512.01078v2) | Jiawei Ren, et al. | simulation, autonomous agent, world model, LLM | cs.AI |  | 2026.01 |
| arXiv(v2) 2026 | [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](http://arxiv.org/abs/2601.00097v2) | Akash Kumar Panda, et al. | causal extraction, fuzzy cognitive maps, LLM, agent | cs.AI, cs.CL, cs.HC, cs.IR | 15 figures | 2026.01 |
| arXiv(v2) 2026 | [The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning](http://arxiv.org/abs/2601.06002v2) | Qiguang Chen, et al. | chain-of-thought, reasoning topology, LLM | cs.CL, cs.AI | Preprint | 2026.01 |
| arXiv(v1) 2026 | [The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs](http://arxiv.org/abs/2601.01580v1) | Zibo Zhao, et al. | self-reflection, reinforcement learning, LLM, agent | cs.LG, cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [When Numbers Start Talking: Implicit Numerical Coordination Among LLM-Based Agents](http://arxiv.org/abs/2601.03846v1) | Alessio Buscemi, et al. | numerical coordination, multi-agent, LLM, agent | cs.MA, cs.AI |  | 2026.01 |
| arXiv(v1) 2025 | [Enhancing Agentic RL with Progressive Reward Shaping and VSPO](http://arxiv.org/abs/2512.07478v1) | Authors TBD, et al. | agentic RL, reward shaping, GRPO, tool use | cs.LG, cs.AI |  | 2025.12 |
| arXiv(v1) 2025 | [From Word to World: Can Large Language Models be Implicit Text-based World Models?](http://arxiv.org/abs/2512.18832v1) | Yixia Li, et al. | world model, text-based, LLM, agent | cs.CL |  | 2025.12 |
| arXiv(v2) 2025 | [ToTRL: Unlock LLM Tree-of-Thoughts Reasoning Potential through Puzzles Solving](http://arxiv.org/abs/2505.12717v2) | Haoyuan Wu, et al. | tree-of-thought, reasoning, puzzle solving, LLM | cs.CL |  | 2025.12 |
| arXiv(v2) 2025 | [Understanding LLM Agent Behaviours via Game Theory: Strategy Recognition, Biases and Multi-Agent Dynamics](http://arxiv.org/abs/2512.07462v2) | Trung-Kiet Huynh, et al. | game theory, agent behavior, LLM, agent | cs.MA, cs.AI, cs.GT, cs.LG, math.DS |  | 2025.12 |
| arXiv(v2) 2025 | [Large Language Model-based Data Science Agent: A Survey](http://arxiv.org/abs/2508.02744v2) | Ke Chen, et al. | data science, agent, LLM | cs.AI |  | 2025.11 |
| arXiv(v1) 2025 | [MarsRL: Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism](http://arxiv.org/abs/2511.11373v1) | Shulin Liu, et al. | multi-agent, agentic RL, reasoning, LLM, pipeline parallelism | cs.AI | 10 pages | 2025.11 |
| arXiv(v1) 2025 | [AGENTRL: Scaling Agentic Reinforcement Learning](http://arxiv.org/abs/2510.04206v1) | Authors TBD, et al. | agentic RL, RLHF, LLM agent, scaling | cs.LG, cs.AI | Outperforms GPT-5 and Claude-Sonnet-4 | 2025.10 |
| arXiv(v2) 2025 | [BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks](http://arxiv.org/abs/2510.02418v2) | Sagnik Anupam, et al. | web navigation, evaluation, real-world, LLM, agent | cs.AI, cs.LG |  | 2025.10 |
| arXiv(v1) 2025 | [Consistently Simulating Human Personas with Multi-Turn Reinforcement Learning](http://arxiv.org/abs/2511.00222v1) | Marwa Abdulhai, et al. | persona simulation, multi-turn RL, LLM, agent | cs.CL, cs.AI |  | 2025.10 |
| arXiv(v3) 2025 | [DS-STAR: Data Science Agent via Iterative Planning and Verification](http://arxiv.org/abs/2509.21825v3) | Jaehyun Nam, et al. | data science, iterative planning, verification, LLM, agent | cs.AI |  | 2025.10 |
| arXiv(v1) 2025 | [Deliberate Lab: A Platform for Real-Time Human-AI Social Experiments](http://arxiv.org/abs/2510.13011v1) | Crystal Qian, et al. | social experiments, human-AI interaction, LLM, agent | cs.HC, cs.AI |  | 2025.10 |
| arXiv(v1) 2025 | [Demystifying Reinforcement Learning in Agentic Reasoning](http://arxiv.org/abs/2510.11701v1) | Zhaochen Yu, et al. | agentic RL, reasoning, LLM, agent | cs.CL | Code and models: https://github.com/Gen-Verse/Open-AgentRL | 2025.10 |
| arXiv(v3) 2025 | [DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning System for Multi-Turn Clinical Dialogue](http://arxiv.org/abs/2505.19630v3) | Yichun Feng, et al. | clinical dialogue, multi-agent RL, medical, LLM, agent | cs.CL |  | 2025.10 |
| arXiv(v1) 2025 | [GEM: A Gym for Agentic LLMs](http://arxiv.org/abs/2510.01051v1) | Zichen Liu, et al. | training environment, agentic LLM, gym, agent | cs.LG, cs.AI, cs.CL |  | 2025.10 |
| arXiv(v3) 2025 | [MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research](http://arxiv.org/abs/2505.19955v3) | Hui Chen, et al. | ML research, evaluation, benchmark, LLM, agent | cs.LG, cs.AI, cs.CL | 49 pages, 9 figures. Accepted by NeurIPS 2025 D&B Track | 2025.10 |
| arXiv(v1) 2025 | [Natural Language Tools: A Natural Language Approach to Tool Calling In Large Language Agents](http://arxiv.org/abs/2510.14453v1) | Reid T. Johnson, et al. | natural language tool calling, LLM, agent | cs.CL | 31 pages, 7 figures | 2025.10 |
| arXiv(v1) 2025 | [On Designing Effective RL Reward at Training Time for LLM Reasoning](http://arxiv.org/abs/2410.15115v1) | Authors TBD, et al. | agentic RL, reward design, reasoning, training | cs.LG, cs.AI |  | 2025.10 |
| arXiv(v1) 2025 | [RLSR: Reinforcement Learning with Supervised Reward](http://arxiv.org/abs/2510.14200v1) | Authors TBD, et al. | agentic RL, supervised reward, instruction following | cs.LG, cs.AI |  | 2025.10 |
| arXiv(v2) 2025 | [SimuRA: A World-Model-Driven Simulative Reasoning Architecture for General Goal-Oriented Agents](http://arxiv.org/abs/2507.23773v2) | Mingkai Deng, et al. | world model, simulative reasoning, goal-oriented, LLM, agent | cs.AI, cs.CL, cs.LG, cs.RO | This submission has been updated to adjust the scope and presentation of the work | 2025.10 |
| arXiv(v2) 2025 (Am. Statist. (2025) 1-14) | [A Survey on Large Language Model-based Agents for Statistics and Data Science](http://arxiv.org/abs/2412.14222v2) | Maojun Sun, et al. | data science, statistics, survey, LLM, agent | cs.AI, cs.CL, cs.LG, stat.OT |  | 2025.09 |
| arXiv(v1) 2025 | [OPPO: Accelerating PPO-based RLHF via Pipeline Overlap](http://arxiv.org/abs/2509.25762v1) | Authors TBD, et al. | agentic RL, PPO, RLHF, efficiency, overlap | cs.LG, cs.AI |  | 2025.09 |
| arXiv(v1) 2025 | [RL Foundations for Deep Research Systems: A Survey](http://arxiv.org/abs/2509.06733v1) | Authors TBD, et al. | agentic RL, deep research, survey, post-DeepSeek | cs.LG, cs.AI | Post Feb 2025 papers | 2025.09 |
| arXiv(v1) 2025 | [Reward Hacking Mitigation using Verifiable Composite Rewards](http://arxiv.org/abs/2509.15557v1) | Authors TBD, et al. | RLHF, reward hacking, RLVR, verification | cs.LG, cs.AI |  | 2025.09 |
| arXiv(v1) 2025 | [SAMULE: Self-Learning Agents Enhanced by Multi-level Reflection](http://arxiv.org/abs/2509.20562v1) | Yubin Ge, et al. | self-learning, multi-level reflection, LLM, agent | cs.AI | Accepted at EMNLP 2025 Main Conference | 2025.09 |
| arXiv(v1) 2025 | [Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning](http://arxiv.org/abs/2509.13351v1) | Pulkit Verma, et al. | logical chain-of-thought, symbolic planning, LLM | cs.AI, cs.CL |  | 2025.09 |
| arXiv(v1) 2025 | [The Landscape of Agentic Reinforcement Learning for LLMs: A Survey](http://arxiv.org/abs/2509.02547v1) | Authors TBD, et al. | agentic RL, survey, LLM, POMDP | cs.LG, cs.AI |  | 2025.09 |
| arXiv(v1) 2025 | [iStar: Agentic Reinforcement Learning with Implicit Step Rewards](http://arxiv.org/abs/2509.19199v1) | Authors TBD, et al. | agentic RL, credit assignment, implicit PRM | cs.LG, cs.AI |  | 2025.09 |
| arXiv(v3) 2025 | [MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement](http://arxiv.org/abs/2506.15692v3) | Jaehyun Nam, et al. | ML engineering, code generation, search, LLM, agent | cs.LG |  | 2025.08 |
| arXiv(v1) 2025 | [AgentMesh: A Cooperative Multi-Agent Generative AI Framework for Software Development Automation](http://arxiv.org/abs/2507.19902v1) | Sourena Khanzadeh, et al. | multi-agent, software development, code generation, LLM, agent | cs.SE, cs.AI |  | 2025.07 |
| arXiv(v1) 2025 | [Technical Survey of RL Techniques for Large Language Models](http://arxiv.org/abs/2507.04136v1) | Authors TBD, et al. | agentic RL, survey, PPO, DPO, GRPO | cs.LG, cs.AI |  | 2025.07 |
| arXiv(v2) 2025 | [ToolACE: Winning the Points of LLM Function Calling](http://arxiv.org/abs/2409.00920v2) | Weiwen Liu, et al. | function calling, tool use, LLM, agent | cs.LG, cs.AI, cs.CL | 21 pages, 22 figures | 2025.07 |
| arXiv(v1) 2025 | [A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy](http://arxiv.org/abs/2506.09420v1) | Henry Peng Zou, et al. | human-agent systems, collaboration, LLM, agent | cs.AI, cs.CL, cs.HC, cs.LG, cs.MA |  | 2025.06 |
| arXiv(v2) 2025 | [Beyond Self-Talk: A Communication-Centric Survey of LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2502.14321v2) | Bingyu Yan, et al. | multi-agent communication, survey, LLM, agent | cs.MA, cs.CL |  | 2025.06 |
| arXiv(v1) 2025 | [GENMANIP: LLM-driven Simulation for Generalizable Instruction-Following Manipulation](http://arxiv.org/abs/2506.10966v1) | Ning Gao, et al. | simulation, robotic manipulation, LLM, agent | cs.RO |  | 2025.06 |
| arXiv(v1) 2025 | [OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems](http://arxiv.org/abs/2506.10764v1) | Xiaozhe Li, et al. | optimization, benchmark, evaluation, LLM, agent | cs.AI, cs.LG |  | 2025.06 |
| arXiv(v1) 2025 | [RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments](http://arxiv.org/abs/2506.15253v1) | Yuchuan Fu, et al. | security evaluation, benchmark, LLM, agent | cs.CR, cs.AI | 12 pages, 8 figures | 2025.06 |
| arXiv(v1) 2025 | [Sailing by the Stars: Survey on Reward Models and Learning Strategies](http://arxiv.org/abs/2505.02686v2) | Authors TBD, et al. | agentic RL, reward model, survey, learning | cs.LG, cs.AI |  | 2025.06 |
| arXiv(v1) 2025 | [ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering](http://arxiv.org/abs/2505.23723v1) | Zexi Liu, et al. | agentic RL, ML engineering, LLM, agent | cs.CL, cs.AI, cs.LG |  | 2025.05 |
| arXiv(v1) 2025 | [Multi-Agent Systems for Robotic Autonomy with LLMs](http://arxiv.org/abs/2505.05762v1) | Junhong Chen, et al. | multi-agent, robotics, LLM, agent | cs.RO, cs.AI | 11 pages, 2 figures, 5 tables, submitted for publication | 2025.05 |
| arXiv(v1) 2025 | [Training LLM-Based Agents with Synthetic Self-Reflected Trajectories and Partial Masking](http://arxiv.org/abs/2505.20023v1) | Yihan Chen, et al. | synthetic trajectories, self-reflection, training, LLM, agent | cs.CL |  | 2025.05 |
| arXiv(v1) 2025 | [Agentic Reasoning and Tool Integration for LLMs via Reinforcement Learning](http://arxiv.org/abs/2505.01441v1) | Joykirat Singh, et al. | agentic RL, tool integration, reasoning, LLM | cs.AI |  | 2025.04 |
| arXiv(v1) 2025 | [Comprehensive Survey of Reward Models: Taxonomy and Applications](http://arxiv.org/abs/2504.12328v1) | Authors TBD, et al. | agentic RL, reward model, survey, taxonomy | cs.LG, cs.AI |  | 2025.04 |
| arXiv(v1) 2025 | [DPO Meets PPO: Reinforced Token Optimization for RLHF](http://arxiv.org/abs/2404.18922v1) | Han Zhong, et al. | agentic RL, DPO, PPO, RLHF, token-level | cs.LG, cs.AI | RTO framework | 2025.04 |
| arXiv(v1) 2025 | [Hierarchical Multi-Step Reward Models for Enhanced Reasoning](http://arxiv.org/abs/2503.13551v1) | Authors TBD, et al. | agentic RL, reward model, hierarchical, reasoning | cs.LG, cs.AI |  | 2025.03 |
| arXiv(v1) 2025 | [Look Before You Leap: Using Serialized State Machine for Language Conditioned Robotic Manipulation](http://arxiv.org/abs/2503.05114v1) | Tong Mu, et al. | finite state machine, robotic manipulation, LLM | cs.RO, cs.AI | 7 pages, 4 figures | 2025.03 |
| arXiv(v1) 2025 | [SafePlan: Leveraging Formal Logic and Chain-of-Thought Reasoning for Enhanced Safety in LLM-based Robotic Task Planning](http://arxiv.org/abs/2503.06892v1) | Ike Obi, et al. | formal logic, chain-of-thought, safety, robotic planning, LLM | cs.RO |  | 2025.03 |
| arXiv(v2) 2025 | [Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation](http://arxiv.org/abs/2410.13232v2) | Hyungjoo Chae, et al. | web navigation, environment dynamics, LLM, agent | cs.CL | ICLR 2025 | 2025.03 |
| arXiv(v1) 2025 | [Every Software as an Agent: Blueprint and Case Study](http://arxiv.org/abs/2502.04747v1) | Mengwei Xu, et al. | software agent, autonomous, LLM | cs.SE, cs.AI |  | 2025.02 |
| arXiv(v1) 2025 | [Process Reward Models for LLM Agents: Practical Framework](http://arxiv.org/abs/2502.10325v1) | Authors TBD, et al. | PRM, reward model, LLM agent, RLHF | cs.LG, cs.AI | InversePRM | 2025.02 |
| arXiv(v1) 2025 | [Provably Efficient Online RLHF with One-Pass Reward Modeling](http://arxiv.org/abs/2502.07193v1) | Authors TBD, et al. | online RLHF, reward modeling, efficiency | cs.LG, cs.AI |  | 2025.02 |
| arXiv(v1) 2025 (Proceedings of the 2024 IEEE International Japan-Africa Conference on Electronics communications and Computations (JAC ECC)) | [Guided Code Generation with LLMs: A Multi-Agent Framework for Complex Code Tasks](http://arxiv.org/abs/2501.06625v1) | Amr Almorsi, et al. | multi-agent, code generation, LLM, agent | cs.AI | 4 pages, 3 figures | 2025.01 |
| arXiv(v1) 2025 | [REINFORCE++: Critic-Free Policy Optimization with Global Advantage Normalization](http://arxiv.org/abs/2501.03262v1) | Authors TBD, et al. | agentic RL, REINFORCE, critic-free, GRPO | cs.LG, cs.AI | Outperforms PPO | 2025.01 |
| arXiv(v4) 2024 | [Planning with Multi-Constraints via Collaborative Language Agents](http://arxiv.org/abs/2405.16510v4) | Cong Zhang, et al. | meta-task planning, multi-agent, LLM, agent | cs.AI, cs.CL, cs.LG |  | 2024.12 |
| arXiv(v2) 2024 | [AutoWebGLM: A Large Language Model-based Web Navigating Agent](http://arxiv.org/abs/2404.03648v2) | Hanyu Lai, et al. | web navigation, browsing, LLM, agent | cs.CL | Accepted to KDD 2024 | 2024.10 |
<!-- TABLE_END: Agentic-RL -->

# MLLM
<!-- TABLE_START: MLLM -->
| Source | Title (Link) | Authors | Tag | Subjects | Additional info | Date |
|---|---|---|---|---|---|---|
| arXiv(v1) 2026 | [Ground What You See: Hallucination-Resistant MLLMs via Caption Feedback](http://arxiv.org/abs/2601.06224v1) | Authors TBD, et al. | MLLM, hallucination, caption feedback, grounding | cs.CV, cs.CL |  | 2026.01 |
| arXiv(v1) 2026 | [Innovator-VL: A Multimodal Large Language Model for Scientific Discovery](http://arxiv.org/abs/2601.19325v1) | Zichen Wen, et al. | scientific discovery, MLLM, vision-language | cs.CV, cs.AI | Innovator-VL tech report | 2026.01 |
| arXiv(v2) 2026 | [MGPC: Multimodal Network for Generalizable Point Cloud Completion With Modality Dropout and Progressive Decoding](http://arxiv.org/abs/2601.03660v2) | Jiangyuan Liu, et al. | point cloud completion, multimodal, MLLM | cs.CV | Code and dataset are available at https://github.com/L-J-Yuan/MGPC | 2026.01 |
| arXiv(v1) 2026 | [Multimodal In-context Learning for ASR of Low-resource Languages](http://arxiv.org/abs/2601.05707v1) | Zhaolin Li, et al. | multimodal in-context learning, ASR, low-resource, MLLM | cs.CL, cs.AI | Under review | 2026.01 |
| arXiv(v3) 2026 | [Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large Language Models](http://arxiv.org/abs/2511.07253v3) | Umberto Cappellazzo, et al. | unified speech recognition, multimodal, MLLM | eess.AS, cs.CV, cs.SD | Accepted to IEEE ICASSP 2026 (camera-ready version). Project website (code and model weights): https://umbertocappellazzo.github.io/Omni-AVSR/ | 2026.01 |
| arXiv(v1) 2026 | [The Paradigm Shift: A Comprehensive Survey on Large Vision Language Models for Multimodal Fake News Detection](http://arxiv.org/abs/2601.15316v1) | Wei Ai, et al. | fake news detection, vision-language, MLLM, survey | cs.AI, cs.CV |  | 2026.01 |
| arXiv(v3) 2026 | [UniVideo: Unified Understanding, Generation, and Editing for Videos](http://arxiv.org/abs/2510.08377v3) | Cong Wei, et al. | video understanding, generation, editing, unified, MLLM | cs.CV | Project Website https://congwei1230.github.io/UniVideo/ | 2026.01 |
| arXiv(v1) 2026 | [VLingNav: Embodied Navigation with Adaptive Reasoning and Visual-Assisted Linguistic Memory](http://arxiv.org/abs/2601.08665v1) | Shaoan Wang, et al. | embodied navigation, adaptive reasoning, MLLM, vision-language | cs.RO, cs.CV | Project page: https://wsakobe.github.io/VLingNav-web/ | 2026.01 |
| arXiv(v1) 2026 | [VideoLoom: A Video Large Language Model for Joint Spatial-Temporal Understanding](http://arxiv.org/abs/2601.07290v1) | Jiapeng Shi, et al. | video understanding, spatial-temporal, MLLM, vision-language | cs.CV |  | 2026.01 |
| arXiv(v1) 2025 | [A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning](http://arxiv.org/abs/2512.21583v1) | Zelin Zang, et al. | medical diagnosis, logic tree reasoning, vision-language, MLLM | cs.AI |  | 2025.12 |
| arXiv(v1) 2025 | [DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models](http://arxiv.org/abs/2512.24165v1) | Zefeng He, et al. | generative reasoning, diffusion model, MLLM | cs.CV | Project page: https://diffthinker-project.github.io | 2025.12 |
| arXiv(v1) 2025 | [From Indoor to Open World: Revealing the Spatial Reasoning Gap in MLLMs](http://arxiv.org/abs/2512.19683v1) | Authors TBD, et al. | MLLM, spatial reasoning, benchmark, open world | cs.CV, cs.CL |  | 2025.12 |
| arXiv(v1) 2025 | [Kling-Omni Technical Report](http://arxiv.org/abs/2512.16776v1) | Kling Team, et al. | video generation, multimodal synthesis, MLLM | cs.CV | Kling-Omni Technical Report | 2025.12 |
| arXiv(v1) 2025 | [Lemon: A Unified and Scalable 3D Multimodal Model for Universal Spatial Understanding](http://arxiv.org/abs/2512.12822v1) | Yongyuan Liang, et al. | 3D understanding, point cloud, spatial understanding, MLLM | cs.CV, cs.AI |  | 2025.12 |
| arXiv(v3) 2025 (Proc. 2025 IEEE 8th International Conference on Multimedia Information Processing and Retrieval (MIPR), pp. 456-462, 2025) | [MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models](http://arxiv.org/abs/2506.07400v3) | Philip R. Liu, et al. | multi-agent, medical diagnosis, MLLM | cs.MA, cs.AI, cs.CV, cs.LG |  | 2025.12 |
| arXiv(v2) 2025 | [TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning](http://arxiv.org/abs/2512.03963v2) | Tao Wu, et al. | temporal understanding, reinforcement learning, MLLM, video | cs.CV |  | 2025.12 |
| arXiv(v1) 2025 | [MVU-Eval: Multi-Video Understanding Evaluation for MLLMs](http://arxiv.org/abs/2511.07250v1) | Authors TBD, et al. | MLLM, multi-video, evaluation, benchmark | cs.CV, cs.CL |  | 2025.11 |
| arXiv(v1) 2025 (Proceedings of the Conference on Language Modeling (COLM 2025)) | [REM: Evaluating LLM Embodied Spatial Reasoning through Multi-Frame Trajectories](http://arxiv.org/abs/2512.00736v1) | Jacob Thompson, et al. | embodied spatial reasoning, trajectory, MLLM | cs.LG, cs.AI, cs.CV |  | 2025.11 |
| arXiv(v1) 2025 | [Seeing is Believing: Rich-Context Hallucination Detection via Backward Visual Grounding](http://arxiv.org/abs/2511.12140v1) | Authors TBD, et al. | MLLM, hallucination, detection, visual grounding | cs.CV, cs.CL | Outperforms GPT-4o | 2025.11 |
| arXiv(v1) 2025 | [SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards](http://arxiv.org/abs/2511.07403v1) | Authors TBD, et al. | MLLM, 3D reasoning, spatial, RL | cs.CV, cs.CL | Outperforms GPT-4o | 2025.11 |
| arXiv(v1) 2025 | [MT-Video-Bench: Video Understanding Benchmark for MLLMs in Multi-Turn Dialogues](http://arxiv.org/abs/2510.17722v1) | Authors TBD, et al. | MLLM, video understanding, benchmark, multi-turn | cs.CV, cs.CL |  | 2025.10 |
| arXiv(v1) 2025 | [MemVR: Memory-Space Visual Retracing for Hallucination Mitigation in MLLMs](http://arxiv.org/abs/2410.03577v1) | Authors TBD, et al. | MLLM, hallucination, mitigation, memory | cs.CV, cs.CL | Plug-and-play | 2025.10 |
| arXiv(v2) 2025 | [Revealing Multimodal Causality with Large Language Models](http://arxiv.org/abs/2509.17784v2) | Jin Li, et al. | causal discovery, MLLM, multimodal causality | cs.LG, cs.AI | Accepted at NeurIPS 2025 | 2025.10 |
| arXiv(v1) 2025 | [Video-STR: Reinforcing MLLMs in Video Spatio-Temporal Reasoning with Relation Graph](http://arxiv.org/abs/2510.10976v1) | Wentao Wang, et al. | spatio-temporal reasoning, relation graph, MLLM, video | cs.AI |  | 2025.10 |
| arXiv(v1) 2025 | [Two Causes, Not One: Rethinking Omission and Fabrication Hallucinations in MLLMs](http://arxiv.org/abs/2509.00371v1) | Authors TBD, et al. | MLLM, hallucination, omission, fabrication | cs.CV, cs.CL |  | 2025.09 |
| arXiv(v1) 2025 | [VIRAL: Visual Representation Alignment for MLLMs](http://arxiv.org/abs/2509.07979v1) | Authors TBD, et al. | MLLM, visual alignment, fine-grained understanding | cs.CV, cs.CL |  | 2025.09 |
| arXiv(v1) 2025 | [Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents](http://arxiv.org/abs/2508.05954v1) | Han Lin, et al. | diffusion model, patch-level CLIP, image generation, MLLM | cs.CV, cs.AI, cs.CL | Project Page: https://bifrost-1.github.io | 2025.08 |
| arXiv(v1) 2025 | [Grounding the Ungrounded: Spectral-Graph Framework for Quantifying Hallucinations in MLLMs](http://arxiv.org/abs/2508.19366v1) | Authors TBD, et al. | MLLM, hallucination, grounding, detection | cs.CV, cs.CL |  | 2025.08 |
| arXiv(v1) 2025 | [Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey](http://arxiv.org/abs/2508.13073v1) | Authors TBD, et al. | MLLM, VLA, robotics, manipulation, survey | cs.RO, cs.CV |  | 2025.08 |
| arXiv(v1) 2025 | [Multimodal Large Language Models for End-to-End Affective Computing: Benchmarking and Boosting with Generative Knowledge Prompting](http://arxiv.org/abs/2508.02429v1) | Miaosen Luo, et al. | affective computing, emotion recognition, MLLM | cs.AI, cs.LG |  | 2025.08 |
| arXiv(v1) 2025 | [RynnEC: Bringing MLLMs into Embodied World](http://arxiv.org/abs/2508.14160v1) | Authors TBD, et al. | MLLM, embodied, video, spatial reasoning | cs.CV, cs.RO |  | 2025.08 |
| arXiv(v3) 2025 | [SimVecVis: A Dataset for Enhancing MLLMs in Visualization Understanding](http://arxiv.org/abs/2506.21319v3) | Can Liu, et al. | visualization understanding, dataset, MLLM | cs.HC, cs.CV |  | 2025.07 |
| arXiv(v2) 2025 | [UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation](http://arxiv.org/abs/2506.20214v2) | Yanzhe Chen, et al. | codebook, multimodal generation, MLLM | cs.CV, cs.MM | 19 pages, 5 figures | 2025.07 |
| arXiv(v1) 2025 | [CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning](http://arxiv.org/abs/2506.17629v1) | Kailing Li, et al. | embodied visual reasoning, cognitive map, MLLM | cs.CV, cs.AI, cs.CL |  | 2025.06 |
| arXiv(v1) 2025 | [Insight-V: Exploring Long-Chain Visual Reasoning with MLLMs](https://openaccess.thecvf.com/CVPR2025) | Authors TBD, et al. | MLLM, visual reasoning, long-chain, CVPR | cs.CV | CVPR 2025 | 2025.06 |
| arXiv(v2) 2025 | [LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning](http://arxiv.org/abs/2505.16933v2) | Zebin You, et al. | diffusion model, visual instruction tuning, MLLM | cs.LG, cs.CL, cs.CV | Project page and codes: \url{https://ml-gsai.github.io/LLaDA-V-demo/} | 2025.06 |
| arXiv(v2) 2025 | [LLaVA-ST: A Multimodal Large Language Model for Fine-Grained Spatial-Temporal Understanding](http://arxiv.org/abs/2501.08282v2) | Hongyu Li, et al. | spatial-temporal understanding, MLLM, vision-language | cs.CV | Accepted by CVPR2025 | 2025.06 |
| arXiv(v1) 2025 (CVPR 2025) | [LLaVA-ST: Multimodal LLM for Fine-Grained Spatial-Temporal Understanding](https://openaccess.thecvf.com/CVPR2025) | Authors TBD, et al. | MLLM, spatial-temporal, video, CVPR | cs.CV | CVPR 2025 | 2025.06 |
| arXiv(v1) 2025 | [Manager: Aggregating Insights from Unimodal Experts in VLMs and MLLMs](http://arxiv.org/abs/2506.11515v1) | Authors TBD, et al. | MLLM, VLM, unimodal experts, fusion | cs.CV, cs.CL |  | 2025.06 |
| arXiv(v1) 2025 | [MedTVT-R1: A Multimodal LLM Empowering Medical Reasoning and Diagnosis](http://arxiv.org/abs/2506.18512v1) | Yuting Zhang, et al. | medical reasoning, diagnosis, MLLM | eess.IV, cs.CL, cs.CV, q-bio.QM |  | 2025.06 |
| arXiv(v1) 2025 | [Pts3D-LLM: Studying the Impact of Token Structure for 3D Scene Understanding With Large Language Models](http://arxiv.org/abs/2506.05689v1) | Hugues Thomas, et al. | 3D scene understanding, point cloud, token structure, MLLM | cs.CV | Main paper and appendix | 2025.06 |
| CVPR25 (CVPR 2025) | [Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Reweighting](https://openaccess.thecvf.com/CVPR2025) | Authors TBD, et al. | MLLM, hallucination, attention, CVPR | cs.CV | CVPR 2025 | 2025.06 |
| arXiv(v1) 2025 | [Structured Attention Matters to Multimodal LLMs in Document Understanding](http://arxiv.org/abs/2506.21600v1) | Chang Liu, et al. | document understanding, structured attention, MLLM | cs.CL, cs.AI, cs.IR |  | 2025.06 |
| arXiv(v2) 2025 | [Watch and Listen: Understanding Audio-Visual-Speech Moments with Multimodal LLM](http://arxiv.org/abs/2505.18110v2) | Zinuo Li, et al. | audio-visual-speech, multimodal, MLLM, video understanding | cs.CL |  | 2025.06 |
| arXiv(v3) 2025 | [Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning](http://arxiv.org/abs/2503.15558v3) | NVIDIA, et al. | physical common sense, embodied reasoning, MLLM | cs.AI, cs.CV, cs.LG, cs.RO |  | 2025.05 |
| arXiv(v1) 2025 | [HoloLLM: Multisensory Foundation Model for Language-Grounded Human Sensing and Reasoning](http://arxiv.org/abs/2505.17645v1) | Chuhao Zhou, et al. | multisensory, human sensing, reasoning, MLLM | cs.CV, cs.AI, cs.CL, cs.LG, cs.MM | 18 pages, 13 figures, 6 tables | 2025.05 |
| arXiv(v2) 2025 | [Kubrick: Multimodal Agent Collaborations for Synthetic Video Generation](http://arxiv.org/abs/2408.10453v2) | Liu He, et al. | video generation, multi-agent collaboration, MLLM | cs.CV, cs.GR, cs.MM | Accepted by CVPR 2025 AI4CC Workshop | 2025.05 |
| arXiv(v1) 2025 | [MedBridge: Bridging Foundation Vision-Language Models to Medical Image Diagnosis](http://arxiv.org/abs/2505.21698v1) | Authors TBD, et al. | MLLM, medical, VLM, diagnosis | cs.CV |  | 2025.05 |
| arXiv(v1) 2025 | [VideoLLM Benchmarks and Evaluation: A Survey](http://arxiv.org/abs/2505.03829v1) | Authors TBD, et al. | MLLM, video, benchmark, evaluation, survey | cs.CV, cs.CL |  | 2025.05 |
| arXiv(v2) 2025 | [Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark](http://arxiv.org/abs/2504.16427v2) | Hanlei Zhang, et al. | multimodal language analysis, MLLM, semantics | cs.CL, cs.AI, cs.MM | 23 pages, 5 figures | 2025.04 |
| arXiv(v2) 2025 | [Dual Diffusion for Unified Image Generation and Understanding](http://arxiv.org/abs/2501.00289v2) | Zijie Li, et al. | dual diffusion, unified generation, understanding, MLLM | cs.CV, cs.AI, cs.LG |  | 2025.04 |
| arXiv(v1) 2025 | [Multimodal LLMs for OCR, OCR Post-Correction, and Named Entity Recognition in Historical Documents](http://arxiv.org/abs/2504.00414v1) | Gavin Greif, et al. | OCR, historical documents, named entity recognition, MLLM | cs.CL, cs.AI, cs.DL |  | 2025.04 |
| arXiv(v1) 2025 | [Socratic Chart: Cooperating Multiple Agents for Robust SVG Chart Understanding](http://arxiv.org/abs/2504.09764v1) | Yuyang Ji, et al. | chart understanding, SVG, multi-agent, MLLM | cs.CV |  | 2025.04 |
| arXiv(v1) 2025 | [VLM-R1: A Stable and Generalizable R1-Style Large VLM](http://arxiv.org/abs/2504.07615v1) | Authors TBD, et al. | MLLM, VLM, reasoning, R1-style | cs.CV, cs.CL |  | 2025.04 |
| arXiv(v1) 2025 | [MLLM-For3D: Adapting Multimodal Large Language Model for 3D Reasoning Segmentation](http://arxiv.org/abs/2503.18135v1) | Authors TBD, et al. | MLLM, 3D, segmentation, reasoning | cs.CV |  | 2025.03 |
| arXiv(v1) 2025 | [MM-Spatial: Exploring 3D Spatial Understanding in Multimodal LLMs](http://arxiv.org/abs/2503.13111v1) | Erik Daxberger, et al. | MLLM, 3D, spatial, understanding, benchmark | cs.CV, cs.CL | ICCV 2025 | 2025.03 |
| arXiv(v1) 2025 | [Med3DVLM: An Efficient Vision-Language Model for 3D Medical Image Analysis](http://arxiv.org/abs/2503.20047v1) | Authors TBD, et al. | MLLM, medical, 3D, VLM, CT | cs.CV |  | 2025.03 |
| arXiv(v1) 2025 | [Mobile-VideoGPT: Fast and Accurate Video Understanding Language Model](http://arxiv.org/abs/2503.21782v1) | Authors TBD, et al. | MLLM, video, mobile, efficient | cs.CV, cs.CL |  | 2025.03 |
| arXiv(v1) 2025 | [R1-Zero's Aha Moment in Visual Reasoning on a 2B Non-SFT Model](http://arxiv.org/abs/2503.05132v1) | Authors TBD, et al. | MLLM, visual reasoning, R1-Zero, emergent | cs.CV, cs.CL |  | 2025.03 |
| arXiv(v1) 2025 | [SpaceVLLM: Endowing MLLM with Spatio-Temporal Video Grounding](http://arxiv.org/abs/2503.13983v1) | Authors TBD, et al. | MLLM, video, spatio-temporal, grounding | cs.CV, cs.CL |  | 2025.03 |
| arXiv(v1) 2025 | [Vision-R1: Incentivizing Reasoning Capability in MLLMs](http://arxiv.org/abs/2503.06749v1) | Authors TBD, et al. | MLLM, reasoning, visual reasoning | cs.CV, cs.CL |  | 2025.03 |
| arXiv(v4) 2025 | [LMFusion: Adapting Pretrained Language Models for Multimodal Generation](http://arxiv.org/abs/2412.15188v4) | Weijia Shi, et al. | multimodal generation, LLM adaptation, MLLM | cs.CL, cs.AI, cs.CV, cs.LG | Name change: LlamaFusion to LMFusion | 2025.02 |
| arXiv(v1) 2025 | [Multimodal Large Language Models for Text-rich Image Understanding: A Comprehensive Review](http://arxiv.org/abs/2502.16586v1) | Pei Fu, et al. | text-rich image understanding, MLLM, vision-language | cs.CV |  | 2025.02 |
| arXiv(v1) 2025 | [Visual Perception Token for Multimodal Large Language Models](http://arxiv.org/abs/2502.17425v1) | Authors TBD, et al. | MLLM, visual perception, token, autonomous control | cs.CV, cs.CL | 829k training samples | 2025.02 |
| arXiv(v1) 2025 | [Weak Supervision Dynamic KL-Weighted Diffusion Models Guided by Large Language Models](http://arxiv.org/abs/2502.00826v1) | Julian Perry, et al. | diffusion model, LLM guidance, weak supervision, image generation | cs.CL |  | 2025.02 |
| arXiv(v1) 2025 | [Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization](http://arxiv.org/abs/2501.11968v1) | Jie Zhao, et al. | graph-structured optimization, combinatorial, MLLM | cs.AI, cs.LG |  | 2025.01 |
| arXiv(v1) 2025 | [Exploring the Role of Explicit Temporal Modeling in Multimodal Large Language Models for Video Understanding](http://arxiv.org/abs/2501.16786v1) | Yun Li, et al. | temporal modeling, video understanding, MLLM | cs.CV, cs.CL |  | 2025.01 |
| arXiv(v5) 2025 | [Harnessing Multimodal Large Language Models for Multimodal Sequential Recommendation](http://arxiv.org/abs/2408.09698v5) | Yuyang Ye, et al. | sequential recommendation, MLLM, multimodal | cs.IR, cs.AI |  | 2025.01 |
<!-- TABLE_END: MLLM -->

# Memory
<!-- TABLE_START: Memory -->
| Source | Title (Link) | Authors | Tag | Subjects | Additional info | Date |
|---|---|---|---|---|---|---|
| arXiv(v1) 2026 | [A Dynamic Retrieval-Augmented Generation System with Selective Memory and Remembrance](http://arxiv.org/abs/2601.02428v1) | Okan Bursa, et al. | dynamic RAG, selective memory, retrieval, LLM | cs.IR, cs.AI | 6 Pages, 2 figures | 2026.01 |
| arXiv(v1) 2026 | [Active Context Compression: Autonomous Memory Management in LLM Agents](http://arxiv.org/abs/2601.07190v1) | Authors TBD, et al. | memory, compression, context, autonomous, Focus | cs.CL, cs.AI | 22.7% token savings | 2026.01 |
| arXiv(v1) 2025 | [Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management](http://arxiv.org/abs/2601.01885v1) | Authors TBD, et al. | memory, unified, long-term, short-term, management | cs.AI, cs.CL |  | 2026.01 |
| arXiv(v1) 2026 | [Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents](http://arxiv.org/abs/2601.07468v1) | Authors TBD, et al. | memory, temporal, semantic, personalized | cs.CL, cs.AI | Durative memory, Zep architecture | 2026.01 |
| arXiv(v1) 2026 | [Beyond Static Summarization: Proactive Memory Extraction for LLM Agents](http://arxiv.org/abs/2601.04463v1) | Chengyuan Yang, et al. | memory, extraction, summarization, agent | cs.CL, cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [Continuum Memory Architectures for Long-Horizon LLM Agents](http://arxiv.org/abs/2601.09913v1) | Authors TBD, et al. | memory, continuum, long-horizon, consolidation | cs.AI, cs.CL | Episodic-to-semantic conversion | 2026.01 |
| arXiv(v2) 2026 | [Cost and accuracy of long-term memory in Distributed Multi-Agent Systems based on Large Language Models](http://arxiv.org/abs/2601.07978v2) | Benedict Wolff, et al. | graph memory, distributed multi-agent, LLM | cs.IR | 23 pages, 4 figures, 7 tables | 2026.01 |
| arXiv(v1) 2026 | [Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration](http://arxiv.org/abs/2601.10744v1) | Sen Wang, et al. | memory, benchmark, multimodal, RL, MLLM | cs.AI, cs.CV | Our dataset and code will be released at our \href{https://wangsen99.github.io/papers/lmee/}{website} | 2026.01 |
| arXiv(v1) 2026 | [Fine-Mem: Fine-Grained Feedback Alignment for Long-Horizon Memory Management](http://arxiv.org/abs/2601.08435v1) | Weitao Ma, et al. | memory, management, feedback, alignment, agent | cs.CL | 18 pages, 5 figures | 2026.01 |
| arXiv(v3) 2026 | [HaluMem: Evaluating Hallucinations in Memory Systems of Agents](http://arxiv.org/abs/2511.03506v3) | Ding Chen, et al. | memory, hallucination, evaluation, agent | cs.CL |  | 2026.01 |
| arXiv(v1) 2026 | [HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants](http://arxiv.org/abs/2601.06152v1) | Hailong Li, et al. | memory, personalized assistant, hippocampus, long-term | cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [HiMem: Hierarchical Long-Term Memory for LLM Long-Horizon Agents](http://arxiv.org/abs/2601.06377v1) | Ningning Zhang, et al. | memory, long-term, hierarchical, agent, LLM | cs.AI |  | 2026.01 |
| arXiv(v2) 2026 | [Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory](http://arxiv.org/abs/2508.08997v2) | Sizhe Yuen, et al. | multi-agent, structured memory, LLM, agent | cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [LLMs Can't Play Hangman: On the Necessity of a Private Working Memory for Language Agents](http://arxiv.org/abs/2601.06973v1) | Davide Baldelli, et al. | working memory, evaluation, agent, LLM | cs.CL |  | 2026.01 |
| arXiv(v2) 2026 | [LiCoMemory: Lightweight and Cognitive Agentic Memory for Efficient Long-Term Reasoning](http://arxiv.org/abs/2511.01448v2) | Zhengjun Huang, et al. | cognitive memory, long-term reasoning, LLM, agent | cs.IR |  | 2026.01 |
| arXiv(v1) 2026 | [MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents](http://arxiv.org/abs/2601.03236v1) | Dongming Jiang, et al. | multi-graph, agentic memory, LLM, agent | cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [Mem-Gallery: Benchmarking Multimodal Long-Term Conversational Memory for MLLM Agents](http://arxiv.org/abs/2601.03515v1) | Yuanchen Bei, et al. | memory, multimodal, conversational, MLLM benchmark | cs.CL, cs.AI | 34 pages, 18 figures | 2026.01 |
| arXiv(v1) 2026 | [MemBuilder: Reinforcing LLMs for Long-Term Memory Construction via Attributed Dense Rewards](http://arxiv.org/abs/2601.05488v1) | Authors TBD, et al. | memory, long-term, construction, dense reward | cs.CL, cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction](http://arxiv.org/abs/2601.06966v1) | Haonan Bian, et al. | memory, benchmark, interaction, agent | cs.CL, cs.AI |  | 2026.01 |
| arXiv(v3) 2026 | [SimpleMem: Efficient Lifelong Memory for LLM Agents](http://arxiv.org/abs/2601.02553v3) | Jiaqi Liu, et al. | lifelong memory, efficient, LLM, agent | cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [SwiftMem: Fast Agentic Memory via Query-aware Indexing](http://arxiv.org/abs/2601.08160v1) | Anxin Tian, et al. | memory, retrieval, indexing, agent, LLM | cs.CL, cs.AI |  | 2026.01 |
| arXiv(v3) 2026 | [TeleMem: Building Long-Term and Multimodal Memory for Agentic AI](http://arxiv.org/abs/2601.06037v3) | Chunliang Chen, et al. | memory, multimodal, long-term, agent, LLM | cs.CL, cs.AI, cs.CV |  | 2026.01 |
| arXiv(v1) 2025 | [Tool-Memory Conflicts in Tool-Augmented LLMs](http://arxiv.org/abs/2601.09760v1) | Authors TBD, et al. | memory, tool use, conflict, LLM | cs.CL, cs.AI |  | 2026.01 |
| arXiv(v1) (NeurIPS25) | [A-MEM: Agentic Memory for LLM Agents (NeurIPS)](http://arxiv.org/abs/2502.12110v1) | Authors TBD, et al. | memory, agentic, Zettelkasten, NeurIPS | cs.AI, cs.CL | NeurIPS 2025 publication | 2025.12 |
| arXiv(v1) 2025 | [AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents](http://arxiv.org/abs/2512.23343v1) | Jiafeng Liang, et al. | memory, cognitive, survey, agent | cs.CL, cs.AI, cs.CV | 57 pages, 5 figures | 2025.12 |
| arXiv(v1) 2025 | [Audited Skill-Graph Self-Improvement for Agentic LLMs via Verifiable Rewards, Experience Synthesis, and Continual Memory](http://arxiv.org/abs/2512.23760v1) | Ken Huang, et al. | memory, continual, self-improvement, agent | cs.CR, cs.AI | 11 pages, 4 figures. Includes a complete runnable reference implementation and audit logging framework | 2025.12 |
| arXiv(v1) 2025 | [Beyond Heuristics: A Decision-Theoretic Framework for Agent Memory Management](http://arxiv.org/abs/2512.21567v1) | Changzhi Sun, et al. | memory, agent, decision-theoretic, management | cs.CL |  | 2025.12 |
| arXiv(v1) 2025 | [Cache What Lasts: Token Retention for Memory-Bounded KV Cache in LLMs](http://arxiv.org/abs/2512.03324v1) | Ngoc Bui, et al. | memory, KV cache, retention, long-context | cs.LG, cs.AI |  | 2025.12 |
| arXiv(v1) 2025 | [Context as a Tool: Context Management for Long-Horizon SWE-Agents](http://arxiv.org/abs/2512.22087v1) | Shukai Liu, et al. | memory, context management, long-horizon, SWE-agent | cs.CL |  | 2025.12 |
| arXiv(v2) 2025 | [Evaluating Long-Term Memory for Long-Context Question Answering](http://arxiv.org/abs/2510.23730v2) | Alessandra Terranova, et al. | memory, long-context, evaluation, QA | cs.CL | Accepted as a poster at Metacognition in Generative AI EurIPS workshop | 2025.12 |
| arXiv(v1) 2025 | [Hindsight is 20/20: Building Agent Memory that Retains, Recalls, and Reflects](http://arxiv.org/abs/2512.12818v1) | Authors TBD, et al. | memory, hindsight, reflection, retention | cs.AI, cs.CL | Retain-Recall-Reflect framework | 2025.12 |
| arXiv(v1) 2025 | [Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement](http://arxiv.org/abs/2512.18950v1) | Saman Forouzandeh, et al. | memory, procedural, hierarchical, agent | cs.LG, cs.AI | Accepted at The 25th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2026). 21 pages including references, with 7 figures and 8 tables. Code is publicly available at the authors GitHub repository: https://github.com/S-Forouzandeh/MACLA-LLM-Agents-AAMAS-Conference | 2025.12 |
| arXiv(v2) 2025 | [MMAG: Mixed Memory-Augmented Generation for Large Language Models Applications](http://arxiv.org/abs/2512.01710v2) | Stefano Zeppieri, et al. | memory, memory-augmented generation, RAG, LLM | cs.CL, cs.IR |  | 2025.12 |
| arXiv(v1) 2025 | [MemEvolve: Meta-Evolution of Agent Memory Systems](http://arxiv.org/abs/2512.18746v1) | Guibin Zhang, et al. | memory, evolution, meta-learning, agent | cs.CL, cs.MA |  | 2025.12 |
| arXiv(v1) 2025 | [MemR3: Memory Retrieval via Reflective Reasoning for LLM Agents](http://arxiv.org/abs/2512.20237v1) | Authors TBD, et al. | memory, retrieval, reflection, reasoning | cs.AI, cs.CL | Router + evidence-gap tracker | 2025.12 |
| arXiv(v2) 2025 | [Memento 2: Learning by Stateful Reflective Memory](http://arxiv.org/abs/2512.22716v2) | Jun Wang, et al. | memory, agent, reflection, stateful | cs.AI, cs.CV, cs.LG | 35 pages, four figures | 2025.12 |
| arXiv(v1) 2025 | [Memory in the Age of AI Agents](http://arxiv.org/abs/2512.13564v1) | Yuyang Hu, et al. | memory, survey, LLM, agent | cs.CL, cs.AI | Comprehensive survey on agent memory | 2025.12 |
| arXiv(v1) 2025 | [MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval](http://arxiv.org/abs/2512.16962v1) | Saksham Sahai Srivastava, et al. | memory, security, agent, attack | cs.CR, cs.AI, cs.LG | 14 pages, 1 figure, includes appendix | 2025.12 |
| arXiv(v3) 2025 | [O-Mem: Omni Memory System for Personalized, Long Horizon, Self-Evolving Agents](http://arxiv.org/abs/2511.13593v3) | Piaohong Wang, et al. | memory, long-horizon, self-evolving, agent | cs.CL |  | 2025.12 |
| arXiv(v1) 2025 | [R-Debater: Retrieval-Augmented Debate Generation through Argumentative Memory](http://arxiv.org/abs/2512.24684v1) | Maoyuan Li, et al. | memory, retrieval, debate, RAG | cs.CL, cs.AI | Accepteed by AAMAS 2026 full paper | 2025.12 |
| arXiv(v2) 2025 | [Significant Other AI: Identity, Memory, and Emotional Regulation as Long-Term Relational Intelligence](http://arxiv.org/abs/2512.00418v2) | Sung Park, et al. | memory, identity, relational, long-term | cs.HC, cs.AI |  | 2025.12 |
| arXiv(v1) 2025 | [Adaptive Focus Memory for Language Models](http://arxiv.org/abs/2511.12712v1) | Authors TBD, et al. | memory, adaptive, focus, compression, AFM | cs.CL, cs.AI | 2/3 token reduction | 2025.11 |
| arXiv(v1) 2025 | [BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing](http://arxiv.org/abs/2511.04919v1) | Authors TBD, et al. | memory, selective, budget, efficient | cs.CL, cs.AI | Learned gating + BM25 | 2025.11 |
| arXiv(v1) 2025 | [CoEdge-RAG: Optimizing Hierarchical Scheduling for Retrieval-Augmented LLMs in Collaborative Edge Computing](http://arxiv.org/abs/2511.05915v1) | Guihang Hong, et al. | RAG, edge computing, optimization, LLM | cs.DC | Accepted by RTSS 2025 (Real-Time Systems Symposium, 2025) | 2025.11 |
| arXiv(v1) 2025 | [EMem: Event-Centric Memory for Long-Term Conversational Agents](http://arxiv.org/abs/2511.17208v1) | Authors TBD, et al. | memory, event-centric, conversation, neo-Davidsonian | cs.CL, cs.AI | Event-like propositions | 2025.11 |
| arXiv(v1) 2025 | [Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory](http://arxiv.org/abs/2511.20857v1) | Tianxin Wei, et al. | memory, benchmark, test-time learning, agent | cs.CL, cs.AI |  | 2025.11 |
| arXiv(v1) 2025 | [G-KV: Decoding-Time KV Cache Eviction with Global Attention](http://arxiv.org/abs/2512.00504v1) | Mengqi Liao, et al. | memory, KV cache, eviction, efficiency | cs.CL, cs.AI |  | 2025.11 |
| arXiv(v1) 2025 | [GCAgent: Long-Video Understanding via Schematic and Narrative Episodic Memory](http://arxiv.org/abs/2511.12027v1) | Jeong Hun Yeo, et al. | memory, episodic, video, MLLM | cs.CV, cs.AI |  | 2025.11 |
| arXiv(v1) 2025 | [Goal-Directed Search Outperforms Goal-Agnostic Memory Compression in Long-Context Memory Tasks](http://arxiv.org/abs/2511.21726v1) | Yicong Zheng, et al. | memory, compression, long-context, search | cs.CL, cs.AI, cs.LG |  | 2025.11 |
| arXiv(v1) 2025 | [KVzip: Memory Compression for LLM Chatbots via KV Cache Optimization](http://arxiv.org/abs/2511.18243v1) | Authors TBD, et al. | memory, compression, KV cache, chatbot | cs.CL, cs.AI | 3-4x compression, 170K tokens | 2025.11 |
| MobiCom25 | [Poster: MemAura: Persistent Personalized Context Memory for LLM Services in Smart Environments](https://doi.org/10.1145/3680207.3765697) | Siyuan Liu, et al. | LLM, memory, personalization, smart environment, context |  |  | 2025.11 |
| arXiv(v1) 2025 | [Trainable Graph Memory for LLM Agents: From Experience to Strategy](http://arxiv.org/abs/2511.07800v1) | Authors TBD, et al. | memory, graph, trainable, strategy | cs.AI, cs.CL | Utility assessment mechanism | 2025.11 |
| arXiv(v1) 2025 | [WebCoach: Self-Evolving Web Agents with Cross-Session Memory Guidance](http://arxiv.org/abs/2511.12997v1) | Genglin Liu, et al. | memory, web agent, cross-session, self-evolving | cs.AI, cs.CL | 18 pages; work in progress | 2025.11 |
| arXiv(v1) 2025 | [A Memory-Efficient Retrieval Architecture for RAG-Enabled Wearable Medical LLMs-Agents](http://arxiv.org/abs/2510.27107v1) | Zhipeng Liao, et al. | memory-efficient, RAG, wearable, medical, LLM, agent | cs.AR | Accepted by BioCAS2025 | 2025.10 |
| arXiv(v1) 2025 | [Acon: Optimizing Context Compression for Long-horizon LLM Agents](http://arxiv.org/abs/2510.00615v1) | Authors TBD, et al. | memory, compression, context, optimization | cs.CL, cs.AI | 26-54% memory reduction | 2025.10 |
| arXiv(v1) 2025 | [Beyond a Million Tokens: Benchmarking and Enhancing Long-Term Memory in LLMs](http://arxiv.org/abs/2510.27246v1) | Mohammad Tavakoli, et al. | memory, long-context, benchmark, long-term | cs.CL, cs.AI, cs.IR |  | 2025.10 |
| arXiv(v1) 2025 | [CAM: Contextual Augmentation Memory for LLM Agents](http://arxiv.org/abs/2510.15321v1) | Authors TBD, et al. | memory, contextual, augmentation, agent | cs.AI, cs.CL |  | 2025.10 |
| arXiv(v1) 2025 | [Dynamic Affective Memory Management for Personalized LLM Agents](http://arxiv.org/abs/2510.27418v1) | Junfeng Lu, et al. | memory, affective, personalization, agent | cs.CL | 12 pasges, 8 figures | 2025.10 |
| arXiv(v1) 2025 | [Enabling Personalized Long-term Interactions in LLM-based Agents through Persistent Memory](http://arxiv.org/abs/2510.07925v1) | Authors TBD, et al. | memory, personalized, long-term, user profile | cs.CL, cs.AI |  | 2025.10 |
| arXiv(v1) 2025 | [LightMem: Lightweight Memory for Efficient LLM Agents](http://arxiv.org/abs/2510.18765v1) | Authors TBD, et al. | memory, lightweight, efficient, agent | cs.AI, cs.CL |  | 2025.10 |
| arXiv(v1) 2025 | [MEMTRACK: Evaluating Long-Term Memory and State Tracking in Multi-Platform Dynamic Agent Environments](http://arxiv.org/abs/2510.01353v1) | Darshan Deshpande, et al. | memory, benchmark, state tracking, agent | cs.AI, cs.CL | Accepted to NeurIPS 2025 SEA Workshop | 2025.10 |
| arXiv(v1) 2025 | [Memory-Augmented State Machine Prompting: A Novel LLM Agent Framework for Real-Time Strategy Games](http://arxiv.org/abs/2510.18395v1) | Runnan Qi, et al. | memory, prompting, state machine, agent | cs.AI | 10 pages, 4 figures, 1 table, 1 algorithm. Submitted to conference | 2025.10 |
| arXiv(v1) 2025 | [Pre-Storage Reasoning for Episodic Memory in LLM Agents](http://arxiv.org/abs/2510.14567v1) | Authors TBD, et al. | memory, episodic, pre-storage, reasoning | cs.AI, cs.CL |  | 2025.10 |
| arXiv(v2) 2025 | [Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions](http://arxiv.org/abs/2507.05257v2) | Yuanzhe Hu, et al. | memory evaluation, multi-turn, LLM, agent | cs.CL, cs.AI | Y. Hu and Y. Wang contribute equally | 2025.09 |
| arXiv(v1) 2025 | [HopRAG: Multi-Hop Reasoning with Graph Memory for LLM Agents](http://arxiv.org/abs/2509.15678v1) | Authors TBD, et al. | memory, multi-hop, graph, reasoning, RAG | cs.AI, cs.CL |  | 2025.09 |
| arXiv(v1) 2025 | [Mem-α: Learning Memory Construction via Reinforcement Learning](http://arxiv.org/abs/2509.25911v1) | Yu Wang, et al. | memory, RL, construction, agent | cs.CL |  | 2025.09 |
| arXiv(v1) 2025 | [Mem-α: Memory with Adaptive Forgetting for LLM Agents](http://arxiv.org/abs/2509.21456v1) | Authors TBD, et al. | memory, forgetting, adaptive, agent | cs.AI, cs.CL |  | 2025.09 |
| arXiv(v1) 2025 | [Memory in LLM-based Multi-agent Systems: Mechanisms, Challenges, and Collective](http://arxiv.org/abs/2509.15234v1) | Authors TBD, et al. | memory, multi-agent, collective, survey | cs.AI, cs.MA |  | 2025.09 |
| arXiv(v1) 2025 | [Multiple Memory Systems for Enhancing Long-term Memory of LLM Agents](http://arxiv.org/abs/2509.16789v1) | Authors TBD, et al. | memory, multiple systems, long-term, enhancement | cs.AI, cs.CL |  | 2025.09 |
| arXiv(v1) 2025 | [Nemori: Neural Memory Organization for LLM Agents](http://arxiv.org/abs/2509.17654v1) | Authors TBD, et al. | memory, neural, organization, agent | cs.AI, cs.CL |  | 2025.09 |
| arXiv(v1) 2025 | [SGMem: Sentence Graph Memory for Long-Term Conversational Agents](http://arxiv.org/abs/2509.21212v1) | Yaxiong Wu, et al. | memory, graph, conversation, retrieval | cs.CL, cs.IR | 19 pages, 6 figures, 1 table | 2025.09 |
| arXiv(v1) 2025 | [SGMem: Structured Graph Memory for LLM Agents](http://arxiv.org/abs/2509.19872v1) | Authors TBD, et al. | memory, graph, structured, agent | cs.AI, cs.CL |  | 2025.09 |
| IJCAI25 (IJCAI 2025) | [AriGraph: Learning Knowledge Graph World Models with Episodic Memory](https://www.ijcai.org/proceedings/2025/0002) | Authors TBD, et al. | memory, knowledge graph, episodic, world model | cs.AI | IJCAI 2025 | 2025.08 |
| arXiv(v1) 2025 | [Cognitive Workspace: Active Memory Management for LLMs - Functional Infinite Context](http://arxiv.org/abs/2508.13171v1) | Authors TBD, et al. | memory, cognitive, workspace, active management | cs.CL, cs.AI | Metacognitive control | 2025.08 |
| arXiv(v1) 2025 | [Learn to Memorize: Optimizing LLM-based Agents with Adaptive Memory Framework](http://arxiv.org/abs/2508.16629v1) | Zeyu Zhang, et al. | adaptive memory, optimization, LLM, agent | cs.LG, cs.AI, cs.CL, cs.IR | 17 pages, 4 figures, 5 tables | 2025.08 |
| arXiv(v1) 2025 | [Memory-Augmented Transformers: A Systematic Review](http://arxiv.org/abs/2508.10824v1) | Authors TBD, et al. | memory, transformer, survey, augmented | cs.CL, cs.AI | Systematic review | 2025.08 |
| arXiv(v1) 2025 | [Memory-R1: Enhancing LLM Agents to Manage and Utilize Memories via RL](http://arxiv.org/abs/2508.19828v1) | Authors TBD, et al. | memory, RL, memory manager, ADD/UPDATE/DELETE | cs.AI, cs.LG | Memory Manager + Answer Agent | 2025.08 |
| arXiv(v1) 2025 | [Recursive Summarization for Long-Term Dialogue Memory in LLMs](http://arxiv.org/abs/2308.15022v3) | Authors TBD, et al. | memory, summarization, dialogue, recursive | cs.CL, cs.AI | Updated 2025 | 2025.08 |
| arXiv(v2) 2025 | [In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents](http://arxiv.org/abs/2503.08026v2) | Zhen Tan, et al. | reflective memory, dialogue agent, personalization, LLM | cs.CL, cs.AI | Accepted to ACL 2025 | 2025.07 |
| ACL25 (ACL 2025) | [Pretraining Context Compressor for LLMs with Embedding-Based Memory](https://aclanthology.org/2025.acl-long.1394) | Authors TBD, et al. | memory, compression, embedding, context | cs.CL | PCC framework | 2025.07 |
| arXiv(v1) 2025 | [Cross-Attention Networks for Memory Retrieval in Generative Agents](http://arxiv.org/abs/2504.12345v1) | Authors TBD, et al. | memory, retrieval, cross-attention, generative | cs.AI, cs.CL | Frontiers in Psychology | 2025.04 |
| arXiv(v1) 2025 | [From Human Memory to AI Memory: A Survey on Memory Mechanisms in the Era of LLMs](http://arxiv.org/abs/2504.15965v1) | Authors TBD, et al. | memory, survey, episodic, semantic, working memory | cs.CL, cs.AI | Personal/system, parametric/non-parametric | 2025.04 |
| arXiv(v3) 2025 | [LIFT: Improving Long Context Understanding of Large Language Models through Long Input Fine-Tuning](http://arxiv.org/abs/2502.14644v3) | Yansheng Mao, et al. | long context, fine-tuning, LLM | cs.CL |  | 2025.04 |
| arXiv(v1) 2025 | [Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory](http://arxiv.org/abs/2504.19413v1) | Authors TBD, et al. | memory, long-term, scalable, production | cs.AI, cs.CL | 26% improvement over OpenAI | 2025.04 |
| arXiv(v1) 2025 | [In Prospect and Retrospect: Reflective Memory Management for Long-term Dialogue Agents](http://arxiv.org/abs/2503.15269v1) | Authors TBD, et al. | memory, reflective, dialogue, long-term | cs.CL, cs.AI |  | 2025.03 |
| arXiv(v1) 2025 | [Tuning LLMs by RAG Principles: Towards LLM-native Memory](http://arxiv.org/abs/2503.16071v1) | Jiale Wei, et al. | RAG, fine-tuning, optimization, LLM | cs.CL, cs.AI, cs.IR |  | 2025.03 |
| arXiv(v1) 2025 | [A-MEM: Agentic Memory for LLM Agents](http://arxiv.org/abs/2502.12110v1) | Authors TBD, et al. | memory, agentic, self-organizing, Zettelkasten | cs.AI, cs.CL | Dynamic memory organization | 2025.02 |
| arXiv(v1) 2025 | [Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents](http://arxiv.org/abs/2502.06975v1) | Authors TBD, et al. | memory, episodic, long-term, position paper | cs.AI, cs.CL | Encoding and retrieval | 2025.02 |
| arXiv(v1) 2025 | [Zep: Temporal Knowledge Graph Architecture for Agent Memory](http://arxiv.org/abs/2502.17089v1) | Authors TBD, et al. | memory, temporal, knowledge graph, agent | cs.AI, cs.CL | Episodic + semantic + community | 2025.02 |
| arXiv(v1) 2024 | [Memory-Augmented Agent Training for Business Document Understanding](http://arxiv.org/abs/2412.15274v1) | Jiale Liu, et al. | memory, agent, training, document | cs.CL, cs.AI | 11 pages, 8 figures | 2024.12 |
| arXiv(v1) 2024 | [On the Structural Memory of LLM Agents](http://arxiv.org/abs/2412.15266v1) | Ruihong Zeng, et al. | memory, agent, analysis, structural | cs.CL, cs.AI |  | 2024.12 |
| arXiv(v1) 2024 | [XKV: Personalized KV Cache Memory Reduction for Long-Context LLM Inference](http://arxiv.org/abs/2412.05896v1) | Weizhuo Li, et al. | memory, KV cache, long-context, personalization | cs.LG, cs.CL |  | 2024.12 |
| arXiv(v1) 2024 | [MELODI: Exploring Memory Compression for Long Contexts](http://arxiv.org/abs/2410.03156v1) | Yinpeng Chen, et al. | memory compression, long context, LLM | cs.LG, cs.AI |  | 2024.10 |
| arXiv(v1) 2024 | [A Survey on the Memory Mechanism of Large Language Model based Agents](http://arxiv.org/abs/2404.13501v1) | Zeyu Zhang, et al. | memory, survey, LLM, agent | cs.AI | ACM TOIS, 39 pages | 2024.04 |
<!-- TABLE_END: Memory -->

# Personalization
<!-- TABLE_START: Personalization -->
| Source | Title (Link) | Authors | Tag | Subjects | Additional info | Date |
|---|---|---|---|---|---|---|
| arXiv(v2) 2026 | [Linear Personality Probing and Steering in LLMs: A Big Five Study](http://arxiv.org/abs/2512.17639v2) | Michel Frising, et al. | personalization, personality, probing, steering | cs.CL | 29 pages, 6 figures | 2026.01 |
| arXiv(v1) 2026 | [One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment](http://arxiv.org/abs/2601.18731v1) | Hongru Cai, et al. | meta reward modeling, alignment, personalization, LLM | cs.CL, cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [PRISP: Privacy-Safe Few-Shot Personalization via Lightweight Adaptation](http://arxiv.org/abs/2601.06471v1) | Junho Park, et al. | few-shot, privacy-safe, lightweight adaptation, personalization, LLM | cs.CL, cs.AI, cs.LG | 16 pages, 9 figures | 2026.01 |
| arXiv(v1) 2026 | [PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning](http://arxiv.org/abs/2601.08679v1) | Xiaoyou Liu, et al. | personalization, persona, reasoning, LLM | cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation](http://arxiv.org/abs/2601.09974v1) | Seoyeon Kim, et al. | personalization, continual, retrieval, parametric adaptation, LLM | cs.AI, cs.CL | under review, 23 pages | 2026.01 |
| arXiv(v1) 2026 | [Structured Personality Control and Adaptation for LLM Agents](http://arxiv.org/abs/2601.10025v1) | Jinpeng Wang, et al. | personalization, personality, control, agent, LLM | cs.AI |  | 2026.01 |
| arXiv(v1) 2026 | [The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models](http://arxiv.org/abs/2601.10387v1) | Christina Lu, et al. | persona, default persona, alignment, LLM | cs.CL |  | 2026.01 |
| arXiv(v2) 2026 | [The Reward Model Selection Crisis in Personalized Alignment](http://arxiv.org/abs/2512.23067v2) | Fady Rezk, et al. | personalization, alignment, reward model, RLHF | cs.AI, cs.LG |  | 2026.01 |
| arXiv(v1) 2026 | [When Personalization Misleads: Understanding and Mitigating Hallucinations in Personalized LLMs](http://arxiv.org/abs/2601.11000v1) | Zhongxiang Sun, et al. | personalization, hallucination, safety, evaluation | cs.CL, cs.AI | 20 pages, 15 figures | 2026.01 |
| arXiv(v1) 2025 | [Agentic Multi-Persona Framework for Evidence-Aware Fake News Detection](http://arxiv.org/abs/2512.21039v1) | Roopa Bukke, et al. | persona, multi-agent, fake news, LLM | cs.IR, cs.LG | 12 pages, 8 tables, 2 figures | 2025.12 |
| arXiv(v1) 2025 | [Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs](http://arxiv.org/abs/2512.19937v1) | Eric Yeh, et al. | personalization, personality, decoding, control | cs.AI | 20 pages, 5 figures | 2025.12 |
| arXiv(v1) 2025 | [LLM Personas as a Substitute for Field Experiments in Method Benchmarking](http://arxiv.org/abs/2512.21080v1) | Enoch Hyunwook Kang, et al. | persona, evaluation, methodology, LLM | cs.AI, cs.LG, econ.EM |  | 2025.12 |
| arXiv(v1) 2025 | [Memoria: A Scalable Agentic Memory Framework for Personalized Conversational AI](http://arxiv.org/abs/2512.12686v1) | Samarth Sarin, et al. | personalization, memory, conversational AI, agent | cs.AI, cs.CL | Paper accepted at 5th International Conference of AIML Systems 2025, Bangalore, India | 2025.12 |
| arXiv(v1) 2025 | [PILAR: Personalizing Augmented Reality Interactions with LLM-based Human-Centric and Trustworthy Explanations for Daily Use Cases](http://arxiv.org/abs/2512.17172v1) | Ripan Kumar Kundu, et al. | personalization, AR, explanations, LLM | cs.HC, cs.AI | Published in the 2025 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct) | 2025.12 |
| arXiv(v1) 2025 | [PRISM: A Personality-Driven Multi-Agent Framework for Social Media Simulation](http://arxiv.org/abs/2512.19933v1) | Zhixiang Lu, et al. | personality, multi-agent, social simulation, LLM | cs.CL |  | 2025.12 |
| arXiv(v1) 2025 | [PersonaMem-v2: Towards Personalized Intelligence via Learning Implicit User Personas](http://arxiv.org/abs/2512.06688v1) | Authors TBD, et al. | personalization, persona, implicit, user modeling | cs.CL, cs.AI | 1000 personas, 20k preferences, 128k context | 2025.12 |
| arXiv(v1) 2025 | [Personalized Multimodal Large Language Models: A Survey](http://arxiv.org/abs/2412.02142v1) | Authors TBD, et al. | personalization, MLLM, survey, multimodal | cs.CV, cs.CL | Comprehensive MLLM personalization survey | 2025.12 |
| arXiv(v1) 2025 | [PrefGen: Multimodal Preference Learning for Image Generation](http://arxiv.org/abs/2512.06020v1) | Authors TBD, et al. | personalization, MLLM, image generation, preference | cs.CV, cs.CL | User-specific conditioning | 2025.12 |
| arXiv(v1) 2025 | [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](http://arxiv.org/abs/2512.24008v1) | Gaurab Chhetri, et al. | personalization, search, agent, retrieval | cs.AI | Accepted to WEB&GRAPH 2026 (WSDM 2026 workshop) | 2025.12 |
| arXiv(v1) 2025 | [TAME: Long-Context MLLM Personalization with Double Memories](http://arxiv.org/abs/2512.21616v1) | Authors TBD, et al. | personalization, MLLM, memory, training-free | cs.CV, cs.CL | RA2G recipe | 2025.12 |
| arXiv(v1) 2025 | [The Mental World of Large Language Models in Recommendation: A Benchmark on Association, Personalization, and Knowledgeability](http://arxiv.org/abs/2512.17389v1) | Guangneng Hu, et al. | personalization, recommendation, benchmark, LLM | cs.IR | 21 pages, 13 figures, 27 tables, submission to KDD 2025 | 2025.12 |
| arXiv(v1) 2025 | [Towards Proactive Personalization through Profile Customization for Individual Users in Dialogues](http://arxiv.org/abs/2512.15302v1) | Xiaotian Zhang, et al. | proactive personalization, profile customization, dialogue, LLM | cs.CL |  | 2025.12 |
| TiiS25 | [User Perceptions of Personalized and Generic Explanations in LLM-Driven Recommender Systems](https://doi.org/10.1145/3779059) | Ítallo De Sousa Silva, et al. | LLM, recommender system, personalization, explanations, user study |  |  | 2025.12 |
| arXiv(v1) 2025 | [Fixed-Persona SLMs with Modular Memory: Scalable NPC Dialogue on Consumer Hardware](http://arxiv.org/abs/2511.10277v1) | Martin Braas, et al. | personalization, persona, modular memory, NPC | cs.AI, cs.IR |  | 2025.11 |
| arXiv(v2) 2025 | [Mem-PAL: Towards Memory-based Personalized Dialogue Assistants for Long-term User-Agent Interaction](http://arxiv.org/abs/2511.13410v2) | Zhaopei Huang, et al. | personalization, dialogue, memory, long-term | cs.CL | Accepted by AAAI 2026 (Oral) | 2025.11 |
| arXiv(v1) 2025 | [PLUM: Learning to Remember User Conversations for Personalization](http://arxiv.org/abs/2411.13405v1) | Authors TBD, et al. | personalization, memory, conversation, LoRA | cs.CL, cs.AI | Parameter-efficient | 2025.11 |
| arXiv(v1) 2025 | [PersonaAgent with GraphRAG: Community-Aware KG for Personalized LLM](http://arxiv.org/abs/2511.17467v1) | Authors TBD, et al. | personalization, GraphRAG, knowledge graph, agent | cs.CL, cs.AI | 11.1% F1 improvement on LaMP | 2025.11 |
| arXiv(v1) 2025 | [PersonalizedRouter: Personalized LLM Routing via Graph-based User Preference Modeling](http://arxiv.org/abs/2511.16883v1) | Authors TBD, et al. | personalization, routing, GNN, user preference | cs.CL, cs.AI |  | 2025.11 |
| arXiv(v1) 2025 | [Profile-LLM: Dynamic Profile Optimization for Realistic Personality Expression](http://arxiv.org/abs/2511.19852v1) | Authors TBD, et al. | personalization, profile, personality, dynamic | cs.CL, cs.AI | Education, therapy, entertainment | 2025.11 |
| arXiv(v1) 2025 | [LLMDiRec: LLM-Enhanced Intent Diffusion for Sequential Recommendation](http://arxiv.org/abs/2601.03259v1) | Bo-Chian Chen, et al. | intent diffusion, sequential recommendation, LLM | cs.IR | Under review | 2025.10 |
| arXiv(v1) 2025 | [MemWeaver: A Hierarchical Memory from Textual Interactive Behaviors for Personalized Generation](http://arxiv.org/abs/2510.07713v1) | Shuo Yu, et al. | personalization, memory, user behavior, generation | cs.CL | 12 pages, 8 figures | 2025.10 |
| arXiv(v1) 2025 | [P2P: Instant Personalized LLM Adaptation via Hypernetwork](http://arxiv.org/abs/2510.16282v1) | Authors TBD, et al. | personalization, hypernetwork, instant adaptation | cs.CL, cs.AI | Single-pass generation | 2025.10 |
| arXiv(v1) 2025 | [Preference-Aware Memory Update for Long-Term LLM Agents](http://arxiv.org/abs/2510.09720v1) | Haoran Sun, et al. | personalization, preference, memory update, long-term | cs.CL, cs.AI |  | 2025.10 |
| arXiv(v1) 2025 | [RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile](http://arxiv.org/abs/2510.16392v1) | Ao Tian, et al. | personalization, user profile, memory, agent | cs.AI | 11 pages,3 figures | 2025.10 |
| arXiv(v1) 2025 | [Real-Time Personalization for LLM-based Recommendation with Customized ICL](http://arxiv.org/abs/2410.23136v1) | Authors TBD, et al. | personalization, recommendation, ICL, real-time, online | cs.IR, cs.AI | No model update needed | 2025.10 |
| arXiv(v2) 2025 | [CoPL: Collaborative Preference Learning for Personalizing LLMs](http://arxiv.org/abs/2503.01658v2) | Youngbin Choi, et al. | collaborative preference learning, personalization, LLM | cs.LG, cs.AI, cs.IR | 19pages, 13 figures, 11 tables | 2025.09 |
| arXiv(v1) 2025 | [DP-FedLoRA: Privacy-Enhanced Federated Fine-Tuning for On-Device Large Language Models](http://arxiv.org/abs/2509.09097v1) | Honghui Xu, et al. | federated learning, privacy-enhanced, on-device LLM, fine-tuning | cs.CR, cs.AI |  | 2025.09 |
| arXiv(v1) 2025 | [HumAIne-Chatbot: Real-Time Personalized Conversational AI via RL](http://arxiv.org/abs/2509.04303v1) | Authors TBD, et al. | personalization, chatbot, RL, real-time, industry | cs.CL, cs.AI | Production deployment | 2025.09 |
| arXiv(v1) 2025 | [MMPB: Multi-Modal Personalization Benchmark for VLMs](http://arxiv.org/abs/2509.22820v1) | Authors TBD, et al. | personalization, MLLM, benchmark, VLM | cs.CV, cs.CL | First MLLM personalization benchmark | 2025.09 |
| arXiv(v1) 2025 | [Personalized Reasoning: Just-In-Time Personalization and Why LLMs Fail At It](http://arxiv.org/abs/2510.00177v1) | Shuyue Stella Li, et al. | just-in-time personalization, LLM, user preference | cs.CL, cs.AI | 57 pages, 6 figures | 2025.09 |
| RecSys25 | [Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation](https://doi.org/10.1145/3705328.3748159) | Genki Kusano, et al. | LLM, recommendation, personalization, prompt engineering |  |  | 2025.09 |
| arXiv(v1) 2025 | [T-POP: Test-Time Personalization with Online Preference Feedback](http://arxiv.org/abs/2509.24696v1) | Zikun Qu, et al. | test-time personalization, online preference, LLM | cs.LG, cs.AI | Preprint | 2025.09 |
| arXiv(v1) 2025 | [DGDPO: Diagnostic-Guided Dynamic Profile Optimization for User Simulators](http://arxiv.org/abs/2508.12645v1) | Authors TBD, et al. | personalization, user simulation, profile, dynamic | cs.IR, cs.AI | Bidirectional evolution | 2025.08 |
| arXiv(v1) 2025 | [End-to-End Personalization: Unifying Recommender Systems with Large Language Models](http://arxiv.org/abs/2508.01514v1) | Danial Ebrat, et al. | recommendation system, unifying, LLM | cs.IR, cs.LG | Second Workshop on Generative AI for Recommender Systems and Personalization at the ACM Conference on Knowledge Discovery and Data Mining (GenAIRecP@KDD 2025) | 2025.08 |
| arXiv(v1) 2025 | [MLLMRec: MLLMs in Recommender Systems](http://arxiv.org/abs/2508.15304v1) | Authors TBD, et al. | personalization, MLLM, recommendation, visual | cs.CV, cs.IR | Visual attribute extraction | 2025.08 |
| arXiv(v1) 2025 | [MM-R1: Unified MLLMs for Personalized Image Generation](http://arxiv.org/abs/2508.11433v1) | Authors TBD, et al. | personalization, MLLM, image generation, GRPO | cs.CV, cs.CL | X-CoT reasoning | 2025.08 |
| arXiv(v1) 2025 | [MSPA: Multimodal Self-Corrective Preference Alignment for Recommendation](http://arxiv.org/abs/2508.14912v1) | Authors TBD, et al. | personalization, MLLM, recommendation, self-corrective | cs.CV, cs.IR | 4D multimodal signals | 2025.08 |
| arXiv(v2) 2025 | [Personalized LLM for Generating Customized Responses to the Same Query from Different Users](http://arxiv.org/abs/2412.11736v2) | Hang Zeng, et al. | personalization, response generation, user-specific, LLM | cs.CL | Accepted by CIKM'25 | 2025.08 |
| arXiv(v1) 2025 | [RLHF Fine-Tuning of LLMs for Alignment with Implicit User Feedback in Conversational Recommenders](http://arxiv.org/abs/2508.05289v1) | Authors TBD, et al. | personalization, RLHF, implicit feedback, recommender | cs.IR, cs.AI | Dwell time, sentiment signals | 2025.08 |
| arXiv(v1) (SIGIR25) | [CoT-Rec: Enhancing LLM-Based Recommendations Through Personalized Reasoning](http://arxiv.org/abs/2502.13845v1) | Authors TBD, et al. | personalization, recommendation, CoT, reasoning | cs.IR, cs.AI | SIGIR 2025 | 2025.07 |
| arXiv(v1) 2025 | [Comprehensive Review on LLMs for Recommender Systems](http://arxiv.org/abs/2507.21117v1) | Authors TBD, et al. | personalization, recommendation, survey, LLM | cs.IR, cs.AI | Hybrid RAG approaches | 2025.07 |
| arXiv(v1) 2025 | [DEP: Latent Inter-User Difference Modeling for LLM Personalization](http://arxiv.org/abs/2507.20849v1) | Authors TBD, et al. | personalization, latent, embedding, difference-aware | cs.CL, cs.AI | Sparse autoencoder | 2025.07 |
| arXiv(v1) 2025 | [PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training](http://arxiv.org/abs/2507.20067v1) | Authors TBD, et al. | personalization, inference-time, alignment, preference | cs.CL, cs.AI | No reward model needed | 2025.07 |
| arXiv(v1) 2025 | [PLUS: Learning to Summarize User Information for Personalized RLHF](http://arxiv.org/abs/2507.13579v1) | Authors TBD, et al. | personalization, RLHF, user summary, preference | cs.LG, cs.AI | 11-77% reward model improvement | 2025.07 |
| arXiv(v1) 2025 | [PRIME: LLM Personalization with Cognitive Memory and Thought Processes](http://arxiv.org/abs/2507.04607v1) | Authors TBD, et al. | personalization, memory, episodic, semantic, cognitive | cs.CL, cs.AI | Dual-memory model | 2025.07 |
| arXiv(v1) 2025 | [PURE: LLM-based User Profile Management for Recommender System](http://arxiv.org/abs/2502.14541v1) | Authors TBD, et al. | personalization, user profile, recommendation, management | cs.IR, cs.AI | Profile extraction and updating | 2025.07 |
| arXiv(v1) 2025 | [Personalization of Large Language Models: A Survey](http://arxiv.org/abs/2411.00027v1) | Zhehao Zhang, et al. | personalization, survey, LLM, user profile | cs.CL, cs.AI | Comprehensive taxonomy | 2025.07 |
| arXiv(v2) 2025 | [Comparison-based Active Preference Learning for Multi-dimensional Personalization](http://arxiv.org/abs/2411.00524v2) | Minhyeon Oh, et al. | active preference learning, multi-dimensional, personalization, LLM | cs.LG |  | 2025.06 |
| arXiv(v1) 2025 | [PersonalAI: KG Storage and Retrieval for Personalized LLM Agents](http://arxiv.org/abs/2506.17001v1) | Authors TBD, et al. | personalization, knowledge graph, memory, agent | cs.AI, cs.CL | Hybrid graph with hyperedges | 2025.06 |
| UMAP25 | [Personalizing LLM Responses to Combat Political Misinformation](https://doi.org/10.1145/3699682.3728349) | Adiba Proma, et al. | LLM, personalization, misinformation, user modeling |  |  | 2025.06 |
| arXiv(v1) 2025 | [ProfiLLM: LLM-Based Framework for Implicit User Profiling](http://arxiv.org/abs/2506.13980v1) | Authors TBD, et al. | personalization, profiling, implicit, chatbot | cs.CL, cs.AI | IT/cybersecurity domain | 2025.06 |
| arXiv(v1) 2025 | [SEAL: Self-Adapting Language Models](http://arxiv.org/abs/2506.10943v1) | Authors TBD, et al. | personalization, self-adaptation, online learning | cs.CL, cs.AI | Self-generated finetuning data | 2025.06 |
| arXiv(v3) 2025 | [Drift: Decoding-time Personalized Alignments with Implicit User Preferences](http://arxiv.org/abs/2502.14289v3) | Minbeom Kim, et al. | decoding-time alignment, implicit preferences, personalization, LLM | cs.CL | 19 pages, 6 figures | 2025.05 |
| arXiv(v2) 2025 | [HyPerAlign: Interpretable Personalized LLM Alignment via Hypothesis Generation](http://arxiv.org/abs/2505.00038v2) | Cristina Garbacea, et al. | alignment, hypothesis generation, personalization, LLM | cs.CL |  | 2025.05 |
| arXiv(v1) 2025 | [MAP: Memory Assisted LLM for Personalized Recommendation System](http://arxiv.org/abs/2505.03824v1) | Authors TBD, et al. | personalization, recommendation, memory, history | cs.IR, cs.AI |  | 2025.05 |
| arXiv(v1) 2025 | [PROSE: Aligning LLMs by Predicting Preferences from User Writing Samples](http://arxiv.org/abs/2505.23815v1) | Authors TBD, et al. | personalization, preference prediction, writing samples | cs.CL, cs.AI | Iterative refinement | 2025.05 |
| arXiv(v1) 2025 | [Privacy-preserving Prompt Personalization in Federated Learning for Multimodal Large Language Models](http://arxiv.org/abs/2505.22447v1) | Sizai Hou, et al. | federated learning, privacy-preserving, prompt personalization, MLLM | cs.CR | Under Review | 2025.05 |
| arXiv(v1) 2025 | [RLPA: Teaching LLMs to Evolve with Users via Dynamic Profile Modeling](http://arxiv.org/abs/2505.15456v1) | Authors TBD, et al. | personalization, RLHF, dynamic profile, user evolution | cs.CL, cs.AI | Outperforms Claude-3.5, DeepSeek-V3 | 2025.05 |
| arXiv(v1) 2025 | [Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering](http://arxiv.org/abs/2505.04260v1) | Authors TBD, et al. | personalization, chatbot, activation steering, inference | cs.CL, cs.AI | Training-free | 2025.05 |
| arXiv(v1) 2025 | [Towards Explainable Temporal User Profiling with LLMs](http://arxiv.org/abs/2505.00886v1) | Milad Sabouri, et al. | temporal user profiling, explainable, LLM | cs.IR, cs.AI |  | 2025.05 |
| arXiv(v1) 2025 | [Towards a unified user modeling language for engineering human centered AI systems](http://arxiv.org/abs/2505.24697v1) | Aaron Conrardy, et al. | user modeling, LLM, personalization | cs.SE | Accepted at the Third Workshop on Engineering Interactive Systems Embedding AI Technologies (EISEAIT workshop at EICS 2025) | 2025.05 |
| arXiv(v1) 2025 | [A Survey on Personalized and Pluralistic Preference Alignment in Large Language Models](http://arxiv.org/abs/2504.07070v1) | Authors TBD, et al. | personalization, preference alignment, survey, pluralistic | cs.CL, cs.AI | Training and inference-time methods | 2025.04 |
| arXiv(v2) 2025 | [Differential Privacy Personalized Federated Learning Based on Dynamically Sparsified Client Updates](http://arxiv.org/abs/2503.09192v2) | Chuanyin Wang, et al. | differential privacy, federated learning, personalization, LLM | cs.LG, cs.CR | 10 pages,2 figures | 2025.04 |
| arXiv(v1) 2025 | [Know Me, Respond to Me: Benchmarking LLMs for Dynamic User Profiling](http://arxiv.org/abs/2504.14225v1) | Authors TBD, et al. | personalization, benchmark, user profiling, dynamic | cs.CL, cs.AI |  | 2025.04 |
| arXiv(v1) 2025 | [LoRe: Personalizing LLMs via Low-Rank Reward Modeling](http://arxiv.org/abs/2504.14439v1) | Avinandan Bose, et al. | low-rank reward modeling, personalization, LLM, RLHF | cs.LG, cs.AI, cs.CL |  | 2025.04 |
| arXiv(v1) 2025 | [PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval](http://arxiv.org/abs/2504.20624v1) | Authors TBD, et al. | personalization, chatbot, retrieval, real-time | cs.CL, cs.AI | 21.77% dialogue improvement, production deployed | 2025.04 |
| arXiv(v1) 2025 | [User Feedback Alignment for LLM-powered Exploration in Large-scale Recommendation](http://arxiv.org/abs/2504.05522v1) | Authors TBD, et al. | personalization, recommendation, feedback, exploration | cs.IR, cs.AI | Click and dwell time signals | 2025.04 |
| arXiv(v1) 2025 | [A Shared Low-Rank Adaptation Approach to Personalized RLHF](http://arxiv.org/abs/2503.19201v1) | Renpu Liu, et al. | RLHF, low-rank adaptation, personalization, LLM | cs.LG, cs.AI | Published as a conference paper at AISTATS 2025 | 2025.03 |
| arXiv(v1) 2025 | [Agentic Recommender Systems in the Era of Multimodal LLMs: Survey](http://arxiv.org/abs/2503.16734v1) | Authors TBD, et al. | personalization, recommendation, agent, MLLM, survey | cs.IR, cs.AI | User agent simulation | 2025.03 |
| arXiv(v1) 2025 | [BAHE: LLM-Enhanced CTR Prediction in Long Textual User Behaviors](http://arxiv.org/abs/2403.19347v1) | Authors TBD, et al. | personalization, CTR, user behavior, industry | cs.IR, cs.AI | Deployed on 50M daily data | 2025.03 |
| arXiv(v1) 2025 | [Can LLM Agents Simulate Multi-Turn Human Behavior? Evidence from Online Shopping](http://arxiv.org/abs/2503.20749v1) | Authors TBD, et al. | personalization, agent, user simulation, behavior | cs.AI, cs.HC | 31,865 shopping sessions | 2025.03 |
| arXiv(v1) 2025 | [Language Model Personalization via Reward Factorization](http://arxiv.org/abs/2503.06358v1) | Idan Shenfeld, et al. | reward factorization, RLHF, personalization, LLM | cs.LG |  | 2025.03 |
| arXiv(v1) 2025 | [Measuring What Makes You Unique: Difference-Aware User Modeling for LLM Personalization](http://arxiv.org/abs/2503.02450v1) | Authors TBD, et al. | personalization, user modeling, difference-aware | cs.CL, cs.AI |  | 2025.03 |
| arXiv(v7) 2025 | [PAD: Personalized Alignment of LLMs at Decoding-Time](http://arxiv.org/abs/2410.04070v7) | Ruizhe Chen, et al. | decoding-time alignment, personalization, LLM | cs.CL, cs.AI | ICLR 2025 | 2025.03 |
| arXiv(v1) 2025 | [PersonaX: A Recommendation Agent Oriented User Modeling Framework](http://arxiv.org/abs/2503.02398v1) | Authors TBD, et al. | personalization, recommendation, user modeling, agent | cs.IR, cs.AI | 3-11% improvement on AgentCF | 2025.03 |
| arXiv(v1) 2025 | [A Survey of Personalized Large Language Models: Progress and Future Directions](http://arxiv.org/abs/2502.11528v1) | Authors TBD, et al. | personalization, survey, LLM, prompting, finetuning | cs.CL, cs.AI | Input/model/objective level | 2025.02 |
| arXiv(v1) 2025 | [FSPO: Few-Shot Preference Optimization of Synthetic Preference Data in LLMs Elicits Effective Personalization to Real Users](http://arxiv.org/abs/2502.19312v1) | Anikait Singh, et al. | few-shot, preference optimization, personalization, LLM | cs.LG, cs.AI, cs.CL, cs.HC, stat.ML | Website: https://fewshot-preference-optimization.github.io/ | 2025.02 |
| arXiv(v1) 2025 | [LoCoMo: Evaluating Very Long-Term Conversational Memory of LLM Agents](http://arxiv.org/abs/2402.17753v1) | Authors TBD, et al. | personalization, memory, conversation, benchmark | cs.CL, cs.AI | 300 turns, 9K tokens, 35 sessions | 2025.02 |
| arXiv(v1) 2025 | [PrefEval: Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following](http://arxiv.org/abs/2502.09597v1) | Authors TBD, et al. | personalization, benchmark, preference, evaluation | cs.CL | 3000 preference-query pairs, 20 topics | 2025.02 |
| arXiv(v3) 2025 | [Privacy-Preserving Personalized Federated Prompt Learning for Multimodal Large Language Models](http://arxiv.org/abs/2501.13904v3) | Linh Tran, et al. | federated learning, privacy-preserving, personalized prompt, MLLM | cs.LG |  | 2025.02 |
| arXiv(v1) 2025 | [RLTHF: Targeted Human Feedback for LLM Alignment](http://arxiv.org/abs/2502.13417v1) | Authors TBD, et al. | personalization, RLHF, targeted feedback, efficient | cs.CL, cs.AI | 6-7% human annotation effort | 2025.02 |
| arXiv(v3) 2025 | [SmartAgent: Chain-of-User-Thought for Embodied Personalized Agent in Cyber World](http://arxiv.org/abs/2412.07472v3) | Jiaqi Zhang, et al. | personalization, agent, user modeling, embodied | cs.AI |  | 2025.02 |
| arXiv(v1) 2025 | [User Profile Construction and Updating with LLMs: Benchmark](http://arxiv.org/abs/2502.10660v1) | Authors TBD, et al. | personalization, user profile, construction, updating | cs.CL, cs.AI | Static and dynamic profiling | 2025.02 |
| arXiv(v1) 2025 | [When Personalization Meets Reality: Multi-Faceted Analysis of Personalized Preference Learning](http://arxiv.org/abs/2502.19158v1) | Authors TBD, et al. | personalization, preference learning, fairness, evaluation | cs.CL, cs.AI |  | 2025.02 |
| arXiv(v1) 2025 | [Advancing Personalized Federated Learning: Integrative Approaches with AI for Enhanced Privacy and Customization](http://arxiv.org/abs/2501.18174v1) | Kevin Cooper, et al. | federated learning, privacy, personalization, LLM | cs.LG, eess.SP | arXiv admin note: substantial text overlap with arXiv:2501.16758 | 2025.01 |
| arXiv(v2) 2025 | [Identifying and Manipulating Personality Traits in LLMs Through Activation Engineering](http://arxiv.org/abs/2412.10427v2) | Rumi Allbert, et al. | personalization, personality, activation engineering, steering | cs.CL, cs.AI |  | 2025.01 |
| arXiv(v1) 2025 | [PerRecBench: Can LLMs Understand Preferences in Personalized Recommendation?](http://arxiv.org/abs/2501.13391v1) | Authors TBD, et al. | personalization, benchmark, recommendation, preference | cs.IR, cs.CL | 19 LLMs evaluated | 2025.01 |
| arXiv(v2) 2025 | [PsychAdapter: Adapting LLM Transformers to Reflect Traits, Personality and Mental Health](http://arxiv.org/abs/2412.16882v2) | Huy Vu, et al. | personalization, personality, traits, mental health | cs.AI, cs.CL |  | 2025.01 |
| arXiv(v1) 2024 | [AI PERSONA: Towards Life-long Personalization of LLMs](http://arxiv.org/abs/2412.13103v1) | Tiannan Wang, et al. | personalization, persona, lifelong, LLM | cs.CL, cs.AI | Work in progress | 2024.12 |
| arXiv(v1) 2024 | [Beyond Discrete Personas: Personality Modeling Through Journal Intensive Conversations](http://arxiv.org/abs/2412.11250v1) | Sayantan Pal, et al. | personalization, persona, personality modeling, long-term | cs.CL, cs.AI | Accepted in COLING 2025 | 2024.12 |
| arXiv(v1) 2024 | [Can Large Language Models Understand You Better? An MBTI Personality Detection Dataset Aligned with Population Traits](http://arxiv.org/abs/2412.12510v1) | Bohan Li, et al. | personalization, personality, dataset, MBTI | cs.CL, cs.CY | Accepted by COLING 2025. 28 papges, 20 figures, 10 tables | 2024.12 |
| arXiv(v1) 2024 | [Disentangling Preference Representation and Text Generation for Efficient Individual Preference Alignment](http://arxiv.org/abs/2412.20834v1) | Jianfei Zhang, et al. | personalization, preference alignment, efficiency, LLM | cs.CL, cs.AI | Coling 2025 | 2024.12 |
| arXiv(v2) 2024 | [Molar: Multimodal LLMs with Collaborative Filtering Alignment for Enhanced Sequential Recommendation](http://arxiv.org/abs/2412.18176v2) | Yucong Luo, et al. | collaborative filtering, sequential recommendation, MLLM | cs.IR, cs.AI |  | 2024.12 |
| arXiv(v1) 2024 | [Semantic Convergence: Harmonizing Recommender Systems via Two-Stage Alignment and Behavioral Semantic Tokenization](http://arxiv.org/abs/2412.13771v1) | Guanghan Li, et al. | recommendation system, alignment, behavioral semantic, LLM | cs.IR, cs.AI, cs.CL | 7 pages, 3 figures, AAAI 2025 | 2024.12 |
| arXiv(v1) 2024 | [ULMRec: User-centric Large Language Model for Sequential Recommendation](http://arxiv.org/abs/2412.05543v1) | Minglai Shao, et al. | personalization, recommendation, sequential, LLM | cs.IR |  | 2024.12 |
| arXiv(v1) 2024 | [Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning](http://arxiv.org/abs/2408.10075v1) | Sriyash Poddar, et al. | RLHF, variational preference learning, personalization, LLM | cs.LG, cs.AI, cs.CL, cs.RO | weirdlabuw.github.io/vpl | 2024.08 |
| arXiv(v2) 2024 | [RLHF from Heterogeneous Feedback via Personalization and Preference Aggregation](http://arxiv.org/abs/2405.00254v2) | Chanwoo Park, et al. | RLHF, heterogeneous feedback, preference aggregation, personalization, LLM | cs.AI, cs.LG | Added experiments | 2024.05 |
<!-- TABLE_END: Personalization -->
