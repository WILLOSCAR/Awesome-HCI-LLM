"Source","Title","Authors","DOI","Journal_Ref","Link","Tag","Subjects","Additional_Info","Date","Topic"
"CHI 2023","HOOV: Hand Out-Of-View Tracking for Proprioceptive Interaction using Inertial Sensing","Paul Streli, Rayan Armani, Yi Fei Cheng, et al.","10.1145/3544548.3581468","","https://arxiv.org/abs/2303.07016","IMU, VR, transformer","cs.HC, cs.CV, I.2; I.5; H.5","","","HCI"
"Ubicomp 2023","From 2D to 3D: Facilitating Single-Finger Mid-Air Typing on QWERTY Keyboards with Probabilistic Touch Modeling","","","","https://dl.acm.org/doi/10.1145/3580829","mid air, text entry, VR","","","","HCI"
"Ubicomp 2023","PrintShear: Shear Input Based on Fingerprint Deformation","","","","https://dl.acm.org/doi/10.1145/3596257","touch, finger input","","","","HCI"
"CHI 2023","IMUPoser: Full-Body Pose Estimation using IMUs in Phones, Watches, and Earbuds","Vimal Mollyn, Riku Arakawa, Mayank Goel, et al.","10.1145/3544548.3581392","","https://arxiv.org/abs/2304.12518","IMU, pose estimation, BiLSTM","cs.HC, cs.CV","","","HCI"
"arXiv(v1) 2024","IMUSIC: IMU-based Facial Expression Capture","Youjia Wang, Yiwen Wu, Hengan Zhou, et al.","","","https://arxiv.org/abs/2402.03944","IMU, generation, simulate, transformer diffusion","cs.CV","code coming soon ([link](https://sites.google.com/view/projectpage-imusic))","2024.02","HCI"
"Ubicomp 2023","I Know Your Intent: Graph-enhanced Intent-aware User Device Interaction Prediction via Contrastive Learning","","","","https://dl.acm.org/doi/10.1145/3610906","user device interaction, graph, attention, contrastive learning","","","","HCI"
"Ubicomp 2023","Synthetic Smartwatch IMU Data Generation from In-the-wild ASL Videos","","","","https://dl.acm.org/doi/abs/10.1145/3596261","IMU, synthetic, ASL recognition","","","","HCI"
"Ubicomp 2023","ThumbAir: In-Air Typing for Head Mounted Displays","","","","https://dl.acm.org/doi/10.1145/3569474","mid air, text entry, VR, HMD, user study","","","","HCI"
"Ubicomp 2023","TwinkleTwinkle: Interacting with Your Smart Devices by Eye Blink","","","","https://dl.acm.org/doi/abs/10.1145/3596238","acoustic sensing, eye blink, signal process","","","","HCI"
"Ubicomp 2023","Voicify Your UI: Towards Android App Control with Voice Commands","","","","https://dl.acm.org/doi/10.1145/3581998","design, smartphones, sound-based input, dl parser, UI","","","","HCI"
"Ubicomp 2023","LapTouch: Using the Lap for Seated Touch Interaction with HMDs","","","","https://dl.acm.org/doi/10.1145/3610878","VR, seated, touch, on-body","","","","HCI"
"Ubicomp 2023","GLOBEM: Cross-Dataset Generalization of Longitudinal Human Behavior Modeling","","","","https://dl.acm.org/doi/10.1145/3569485","generalizability, behavior modeling, passive sensing","","","","HCI"
"Ubicomp 2023","StructureSense: Inferring Constructive Assembly Structures from User Behaviors","","","","https://dl.acm.org/doi/10.1145/3570343","tangible user interfaces, TUI, RFID, user modeling, bayesian inference","","","","HCI"
"Ubicomp 2023","Naturalistic E-Scooter Maneuver Recognition with Federated Contrastive Rider Interaction Learning","","","","https://dl.acm.org/doi/10.1145/3570345","IMU, DCT, contrastive learning, asynchronous federated learning, ehavior analysis","","","","HCI"
"Ubicomp 2023","TAO: Context Detection from Daily Activity Patterns Using Temporal Analysis and Ontology","","","","https://dl.acm.org/doi/abs/10.1145/3610896","behavioral context recognition, activity recognition, ontology, deep learning","","","","HCI"
"Ubicomp 2023","HyWay: Enabling Mingling in the Hybrid World∗","","","","https://dl.acm.org/doi/abs/10.1145/3596235","hybrid mingling, unstructured and semi-structured conversations, awareness, agency, porosity, reciprocity","","","","HCI"
"Ubicomp 2023","Exploring the Opportunities of AR for Enriching Storytelling with Family Photos between Grandparents and Grandchildren","","","","https://dl.acm.org/doi/abs/10.1145/3610903","AR, storytelling, intergenerational communication","","","","HCI"
"Ubicomp 2023","Contact Tracing for Healthcare Workers in an Intensive Care Unit","","","","https://dl.acm.org/doi/10.1145/3610924","contact Tracing, Internet of things (IoT), bluetooth low energy, Covid-19","","","","HCI"
"Ubicomp 2023","A Data-Driven Context-Aware Health Inference System for Children during School Closures","","","","https://dl.acm.org/doi/10.1145/3580800","data analysis, school closures, health inference, risk factor analysis","","","","HCI"
"Ubicomp 2023","Privacy-Enhancing Technology and Everyday Augmented Reality: Understanding Bystanders’ Varying Needs for Awareness and Consent","","","","https://dl.acm.org/doi/10.1145/3569501","AR, privacy, bystanders, altered reality, extended perception, biometrics","","","","HCI"
"Ubicomp 2023","MoCaPose: Motion Capturing with Textile-integrated Capacitive Sensors in Loose-fitting Smart Garments","","","","https://dl.acm.org/doi/abs/10.1145/3580883","motion capture, wearable sensing, capacitive sensing, deep learning, motion tracking, smart textile","","","","HCI"
"Ubicomp 2023","PoseSonic: 3D Upper Body Pose Estimation Through Egocentric Acoustic Sensing on Smartglasses","","","","https://dl.acm.org/doi/abs/10.1145/3610895?af=R","human pose estimation, acoustic sensing, smart/AR glasses, deep learning, cross-modal supervision","","","","HCI"
"Ubicomp 2023","MI-Poser: Human Body Pose Tracking Using Magnetic and Inertial Sensor Fusion with Metal Interference Mitigation","","","","https://dl.acm.org/doi/10.1145/3610891","EMF, body pose tracking, inverse kinematics, sensor fusion","","","","HCI"
"Ubicomp 2023","Headar: Sensing Head Gestures for Confirmation Dialogs on Smartwatches with Wearable Millimeter-Wave Radar","","","","https://dl.acm.org/doi/abs/10.1145/3610900","wearable interaction, gestural input, millimeter-wave radar, head gestures, smartwatch","","","","HCI"
"Ubicomp 2023","DRG-Keyboard: Enabling Subtle Gesture Typing on the Fingertip with Dual IMU Rings","","","","https://dl.acm.org/doi/10.1145/3569463","text entry, gesture keyboard, fingertip interaction, smart ring","","","","HCI"
"Ubicomp 2023","Abacus Gestures: A Large Set of Math-Based Usable Finger-Counting Gestures for Mid-Air Interactions","","","","https://dl.acm.org/doi/10.1145/3610898","vision, mid-air, gesture interaction, math, finger counting, abacus","","","","HCI"
"Ubicomp 2023","sUrban: Stable Prediction for Unseen Urban Data from Location-based Sensors","","","","https://dl.acm.org/doi/abs/10.1145/3610877","urban computing, location-based data, spatial-temporal prediction, out-of-distribution data","","","","HCI"
"Ubicomp 2023","Spectral-Loc: Indoor Localization Using Light Spectral Information","","","","https://dl.acm.org/doi/10.1145/3580878","indoor localization, spectral information, ambient light","","","","HCI"
"arXiv(v2) 2024","IMUOptimize: A Data-Driven Approach to Optimal IMU Placement for Human Pose Estimation with Transformer Architecture","Varun Ramani, Hossein Khayami, Yang Bai, et al.","","","https://arxiv.org/abs/2402.08923","IMU, transformer, interpretability, data driven, time series","cs.LG","","2024.02","HCI"
"CVPR 2024","Dynamic Inertial Poser (DynaIP): Part-Based Motion Dynamics Learning for Enhanced Human Pose Estimation with Sparse Inertial Sensors","Yu Zhang, Songpengcheng Xia, Lei Chu, et al.","","","https://arxiv.org/abs/2312.02196","IMU, sparse inertial sensors","cs.CV","","2024.03","HCI"
"Ubicomp 2023","N-euro Predictor: A Neural Network Approach for Smoothing and Predicting Motion Trajectory","","","","https://dl.acm.org/doi/10.1145/3610884","vision-based interactions, motion-to-photon latency, motion prediction, neural network, perceived jitter and lag","","","","HCI"
"Ubicomp 2023","GC-Loc: A Graph Attention Based Framework for Collaborative Indoor Localization Using Infrastructure-free Signals","","","","https://dl.acm.org/doi/10.1145/3569495","collaborative indoor localization, graph neural network, geomagnetism","","","","HCI"
"arXiv(v5) 2024","Evaluating Human-Language Model Interaction","Mina Lee, Megha Srivastava, Amelia Hardy, et al.","","","https://arxiv.org/abs/2212.09746","LM, human-centered, evaluation","cs.CL","","","HCI"
"Ubicomp 2023","WristAcoustic: Through-Wrist Acoustic Response Based Authentication for Smartwatches","","","","https://dl.acm.org/doi/10.1145/3569473","smartwatch authentication, bone conduction, acoustic response","","","","HCI"
"Ubicomp 2023","VibPath: Two-Factor Authentication with Your Hand's Vibration Response to Unlock Your Phone","","","","https://dl.acm.org/doi/10.1145/3610894","user authentication, vibration, IMU, smartphone, wearables, smartwatch","","","","HCI"
"Ubicomp 2024","CAvatar: Real-time Human Activity Mesh Reconstruction via Tactile Carpets","","","","https://dl.acm.org/doi/pdf/10.1145/3631424","human activity reconstruction, 3D human mesh, pressure and vibrations, tactile sensor","","","","HCI"
"Ubicomp 2023","NF-Heart: A Near-field Non-contact Continuous User Authentication System via Ballistocardiogram","","","","https://dl.acm.org/doi/10.1145/3580851","continuous authentication, ballistocardiogram (BCG), biometrics, non-contact sensing, smart chair","","","","HCI"
"Ubicomp 2023","Fingerprinting IoT Devices Using Latent Physical Side-Channels","","","","https://dl.acm.org/doi/abs/10.1145/3596247","physical side-channels, fingerprinting, internet-of-things","","","","HCI"
"Ubicomp 2023","ViSig: Automatic Interpretation of Visual Body Signals Using On-Body Sensors","","","","https://dl.acm.org/doi/10.1145/3580797","visual signalling, on-body sensors, UWB, IMU, body signals, fallback communication, sports automation, postures, gestures","","","","HCI"
"Ubicomp 2024","Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data","","","","","","","","","HCI"
"Ubicomp 2023","SkinLink: On-body Construction and Prototyping of Reconfigurable Epidermal Interfaces","","","","","","","","","HCI"
"Ubicomp 2023","Radio2Text: Streaming Speech Recognition Using mmWave Radio Signals","","","","","","","","","HCI"
"Ubicomp 2023","HIPPO: Pervasive Hand-Grip Estimation from Everyday Interactions","","","","","","","","","HCI"
"Ubicomp 2023","LT-Fall: The Design and Implementation of a Life-threatening Fall Detection and Alarming System","","","","","","","","","HCI"
"Ubicomp 2022","IF-ConvTransformer: A Framework for Human Activity Recognition Using IMU Fusion and ConvTransformer","","","","https://dl.acm.org/doi/10.1145/3534584","IMU, fusion, multimodal, transformer, attention","","","","HCI"
"ISWC 2023","On the Utility of Virtual On-body Acceleration Data for Fine-grained Human Activity Recognition","","","","https://dl.acm.org/doi/10.1145/3594738.3611364","HAR, virtual, IMU","","","","HCI"
"ISWC 2023","C-Auth: Exploring the Feasibility of Using Egocentric View of Face Contour for User Authentication on Glasses","","","","https://dl.acm.org/doi/10.1145/3594738.3611355","smart glasses, authentication, ecocentric view","","","","HCI"
"ISWC 2023","Towards a Haptic Taxonomy of Emotions: Exploring Vibrotactile Stimulation in the Dorsal Region","","","","","","","","","HCI"
"Todo","","","","","","","","","","HCI"
"arXiv(v1) 2023","Multimodal Foundation Models: From Specialists to General-Purpose Assistants","Chunyuan Li, Zhe Gan, Zhengyuan Yang, et al.","","","https://arxiv.org/abs/2309.10020","survey","cs.CV, cs.CL","","2023.09","LLM"
"NIPS 2023","Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias","Yue Yu, Yuchen Zhuang, Jieyu Zhang, et al.","","NeurIPS 2023","https://arxiv.org/abs/2306.15895","synthetic data generation","cs.CL, cs.AI, cs.LG","","arXiv(v2) 2023.10","LLM"
"arXiv(v1) 2024","Design2Code: How Far Are We From Automating Front-End Engineering?","Chenglei Si, Yanzhe Zhang, Ryan Li, et al.","","","https://arxiv.org/abs/2403.03163","llm, auto, google","cs.CL, cs.CV, cs.CY","","2024.03","LLM"
"arXiv(v2) 2023","The Good, The Bad, and Why: Unveiling Emotions in Generative AI","Cheng Li, Jindong Wang, Yixuan Zhang, et al.","","","https://arxiv.org/abs/2312.11111","emotion, prompt, attack, decode","cs.AI, cs.CL, cs.HC","extension of Large language models understand and can be enhanced by emotional stimuli","2023.12","LLM"
"arXiv(v1) 2024","Are You Being Tracked? Discover the Power of Zero-Shot Trajectory Tracing with LLMs!","Huanqi Yang, Sijie Ji, Rucheng Wu, et al.","","","https://arxiv.org/abs/2403.06201","iot, imu, cot, prompt","cs.CL, cs.AI, cs.HC, cs.LG","","2024.03","LLM"
"arXiv(v1) 2024","Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs","Keen You, Haotian Zhang, Eldon Schoop, et al.","","","https://arxiv.org/abs/2404.05719","ui, mllm, benchmark, any-resolution","cs.CV, cs.CL, cs.HC","","2024.04","LLM"
"arXiv(v6) 2024","Health-LLM: Personalized Retrieval-Augmented Disease Prediction System","Qinkai Yu, Mingyu Jin, Dong Shu, et al.","","","https://arxiv.org/abs/2402.00746","RAG, XGBoost, AutoML","cs.CL","","2024.03","RAG"
"arXiv(v1) 2024","CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models","","","","","retrieval-augmented generation, large language models, evaluation","","","2024.02","RAG"
"arXiv(v1) 2024","LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language Models and Doc-Level Embedding","","","","","relevant query, doc-Level embedding, embedding-based retrieval, dense retrieval","","","2024.04","RAG"
"ICLR 2024","MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework","Sirui Hong, Mingchen Zhuge, Jiaqi Chen, et al.","","","https://arxiv.org/abs/2308.00352","autonomous system, SOP, multi-agent, framework","cs.AI, cs.MA","","","Agent"
"arXiv(v1) 2024","DataDreamer: A Tool for Synthetic Data Generation and Reproducible LLM Workflows","Ajay Patel, Colin Raffel, Chris Callison-Burch","","","https://arxiv.org/abs/2402.10379","pipeline, liarbry, generation","cs.CL, cs.LG","","2024.02","Agent"
"arXiv(v2) 2023","MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models","Dingyao Yu, Kaitao Song, Peiling Lu, et al.","","","https://arxiv.org/abs/2310.11954","pipeline","cs.CL, cs.MM, eess.AS","","2023.10","Agent"
"arXiv(v3) 2023","The Rise and Potential of Large Language Model Based Agents: A Survey","Zhiheng Xi, Wenxiang Chen, Xin Guo, et al.","","","https://arxiv.org/abs/2309.07864","survey, [github paper list](https://github.com/WooooDyy/LLM-Agent-Paper-List)","cs.AI, cs.CL","","2023.09","Agent"
"NIPS 2023","CAMEL: Communicative Agents for ""Mind"" Exploration of Large Language Model Society","Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, et al.","","","https://arxiv.org/abs/2303.17760","role play, autonomous, user&assistant","cs.AI, cs.CL, cs.CY, cs.LG, cs.MA","","2023.11(v2)","Agent"
"NIPS 2023","HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face","Yongliang Shen, Kaitao Song, Xu Tan, et al.","","","https://arxiv.org/abs/2303.17580","hugging face, API","cs.CL, cs.AI, cs.CV, cs.LG","","2023.12","Agent"
"arXiv(v2) 2023","VOYAGER: An Open-Ended Embodied Agent with Large Language Models","Guanzhi Wang, Yuqi Xie, Yunfan Jiang, et al.","","","https://arxiv.org/abs/2305.16291","multi, autonomous, microcraft, game","cs.AI, cs.LG","","2023.10","Agent"
"arXiv(v1) 2024","More Agents Is All You Need","Junyou Li, Qin Zhang, Yangbin Yu, et al.","","","https://arxiv.org/abs/2402.05120","multi agent, vote, task","cs.CL, cs.AI, cs.LG","","2024.02","Agent"
"arXiv(v3) 2023","A Survey on Large Language Model based Autonomous Agents","Lei Wang, Chen Ma, Xueyang Feng, et al.","10.1007/s11704-024-40231-1","","https://arxiv.org/abs/2308.11432","survey, autonomous","cs.AI, cs.CL","Latest version is v4(2024.03), double columns. But v3(2023.09) single columns is easy to read.","","Agent"
"arXiv(v7) 2023","Attention Is All You Need","Ashish Vaswani, Noam Shazeer, Niki Parmar, et al.","","","http://arxiv.org/abs/1706.03762v7","arxiv","cs.CL, cs.LG","15 pages, 5 figures","2023.08","LLM"
"arXiv(v3) 2025","Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs","Kang Zhao, Tao Yuan, Han Bao, et al.","","","http://arxiv.org/abs/2410.16135v3","LLM, GUI agent, interface","cs.LG, cs.AI","","2025.06","LLM"
"arXiv(v2) 2024","Finding Candidate TeV Halos among Very-High Energy Sources","Dong Zheng, Zhongxiang Wang","","","http://arxiv.org/abs/2403.16074v2","VR, AR, egocentric, pose estimation","astro-ph.HE","15 pages, 7 figures, 4 tables, referee's comments incorporated, accepted for publication in ApJ","2024.05","HCI"
"arXiv(v1) 2024","Exploring Text-to-Motion Generation with Human Preference","Jenny Sheng, Matthieu Lin, Andrew Zhao, et al.","","","http://arxiv.org/abs/2404.09445v1","IMU, human object interaction, dataset","cs.LG, cs.AI, cs.CV","Accepted to CVPR 2024 HuMoGen Workshop","2024.04","HCI"
"arXiv(v1) 2024","LLMs in HCI Data Work: Bridging the Gap Between Information Retrieval and Responsible Research Practices","Neda Taghizadeh Serajeh, Iman Mohammadi, Vittorio Fuccella, et al.","","","http://arxiv.org/abs/2403.18173v1","VR, AR, avatar control, pose estimation","cs.HC, cs.IR","5 pages, CHI2024 Workshop on LLMs as Research Tools: Applications and Evaluations in HCI Data Work","2024.03","HCI"
"arXiv(v1) 2024","Modeling stock price dynamics on the Ghana Stock Exchange: A Geometric Brownian Motion approach","Dennis Lartey Quayesam, Anani Lotsi, Felix Okoe Mettle","","","http://arxiv.org/abs/2403.13192v1","VR, AR, motion capture, egocentric","math.OC, q-fin.ST","","2024.03","HCI"
"arXiv(v3) 2025","Lai Loss: A Novel Loss for Gradient Control","YuFei Lai","","","http://arxiv.org/abs/2405.07884v3","LLM, agent, interface, UI","cs.LG","The experiment in this article is not very rigorous and may require further testing for its effectiveness","2025.05","LLM"
"arXiv(v2) 2024","Massively parallel CMA-ES with increasing population","David Redon, Pierre Fortin, Bilel Derbel, et al.","","","http://arxiv.org/abs/2409.11765v2","LLM, agent, HCI, user interface","cs.DC","","2024.10","LLM"
"arXiv(v1) 2024","In-Band Full-Duplex MIMO Systems for Simultaneous Communications and Sensing: Challenges, Methods, and Future Perspectives","Besma Smida, George C. Alexandropoulos, Taneli Riihonen, et al.","","","http://arxiv.org/abs/2410.06512v1","LLM, GUI agent, computer use","cs.IT, cs.ET, eess.SP","12 pages, 5 figures, White Paper to appear at IEEE SPM","2024.10","LLM"
"Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2023","CAvatar","Wenqiang Chen, Yexin Hu, Wei Song, et al.","10.1145/3631424","","https://doi.org/10.1145/3631424","human activity, 3D mesh, tactile, pressure","","","2023.12","HCI"
"arXiv(v1) 2024","OrientedFormer: An End-to-End Transformer-Based Oriented Object Detector in Remote Sensing Images","Jiaqi Zhao, Zeyu Ding, Yong Zhou, et al.","","","http://arxiv.org/abs/2409.19648v1","LLM, agent, GUI, interface","cs.CV","The paper is accepted by IEEE Transactions on Geoscience and Remote Sensing (TGRS)","2024.09","LLM"
"Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2024","ViObject","Wenqiang Chen, Shupei Lin, Zhencan Peng, et al.","10.1145/3643547","","https://doi.org/10.1145/3643547","mental health, LLM, text data","","","2024.03","HCI"
"Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2024","HyperHAR","Nafees Ahmad, Ho-fung Leung","10.1145/3643511","","https://doi.org/10.1145/3643511","LLM, passive sensing, sensemaking","","","2024.03","HCI"
"arXiv(v1) 2024","WheelPoser: Sparse-IMU Based Body Pose Estimation for Wheelchair Users","Yunzhi Li, Vimal Mollyn, Kuang Yuan, et al.","10.1145/3663548.3675638","","http://arxiv.org/abs/2409.08494v1","IMU, pose estimation, wheelchair, accessibility","cs.GR, cs.CV, cs.HC","Accepted by ASSETS 2024","2024.09","HCI"
"arXiv(v1) 2024","Modeling and optimization for arrays of water turbine OWC devices","M. Gambarini, G. Agate, G. Ciaramella, et al.","","","http://arxiv.org/abs/2403.14509v1","VR, AR, motion capture, egocentric, stereo camera","math.OC, physics.flu-dyn","","2024.03","HCI"
"arXiv(v2) 2025","Device-Independent Quantum Key Distribution Based on Routed Bell Tests","Tristan Le Roy-Deloison, Edwin Peter Lobo, Jef Pauwels, et al.","10.1103/PRXQuantum.6.020311","PRX Quantum 6, 020311 (April 2025)","http://arxiv.org/abs/2404.01202v2","IMU, RGB, human object interaction, dataset, 3D tracking","quant-ph","Version2: Slight improvements in the text. Close to published version","2025.05","HCI"
"arXiv(v1) 2024","On depth prediction for autonomous driving using self-supervised learning","Houssem Boulahbal","","","http://arxiv.org/abs/2403.06194v1","VR, AR, avatar, pose estimation, headset","cs.CV","PhD thesis","2024.03","HCI"
"arXiv(v3) 2025","SignLLM: Sign Language Production Large Language Models","Sen Fang, Chen Chen, Lei Wang, et al.","","","http://arxiv.org/abs/2405.10718v3","LLM, agent, user interface, HCI, interaction","cs.CV, cs.CL","website at https://signllm.github.io/","2025.04","LLM"
"arXiv(v6) 2025","LLaVA-CoT: Let Vision Language Models Reason Step-by-Step","Guowei Xu, Peng Jin, Ziang Wu, et al.","","","http://arxiv.org/abs/2411.10440v6","LLM, GUI agent, survey, computer use","cs.CV","17 pages, ICCV 2025","2025.07","LLM"
"arXiv(v1) 2024","A Scalable Communication Protocol for Networks of Large Language Models","Samuele Marro, Emanuele La Malfa, Jesse Wright, et al.","","","http://arxiv.org/abs/2410.11905v1","LLM, agent, GUI, computer use, interface","cs.AI, cs.LG","","2024.10","LLM"
"arXiv(v1) 2024","ShowUI: One Vision-Language-Action Model for GUI Visual Agent","Kevin Qinghong Lin, Linjie Li, Difei Gao, et al.","","","http://arxiv.org/abs/2411.17465v1","LLM, UI, vision-language, GUI","cs.CV, cs.AI, cs.CL, cs.HC","Technical Report. Github: https://github.com/showlab/ShowUI","2024.11","LLM"
"arXiv(v1) 2024","OS-ATLAS: A Foundation Action Model for Generalist GUI Agents","Zhiyong Wu, Zhenyu Wu, Fangzhi Xu, et al.","","","http://arxiv.org/abs/2410.23218v1","LLM, agent, computer use, GUI, foundation model","cs.CL, cs.CV, cs.HC","","2024.10","LLM"
"arXiv(v1) 2024","Evaluating Text Classification Robustness to Part-of-Speech Adversarial Examples","Anahita Samadi, Allison Sullivan","","","http://arxiv.org/abs/2408.08374v1","IMU, transformer, pose estimation, calibration","cs.CL, cs.LG","","2024.08","HCI"
"arXiv(v2) 2025","Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions","Michael J. Q. Zhang, W. Bradley Knox, Eunsol Choi","","","http://arxiv.org/abs/2410.13788v2","IMU, diffusion, pose estimation, loose sensor","cs.CL","Presented at ICLR 2025","2025.03","HCI"
"arXiv(v1) 2025","Broadband shot-to-shot transient absorption anisotropy","Maximilian Binzer, František Šanda, Lars Mewes, et al.","","","http://arxiv.org/abs/2503.14144v1","VR, AR, egocentric, motion capture, FRAME","physics.optics","The following article has been submitted to The Journal of Physical Chemistry. After it is published, it will be found at https://pubs.aip.org/aip/jcp","2025.03","HCI"
"arXiv(v2) 2024","PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models","Shashi Kant Gupta, Aditya Basu, Mauro Nievas, et al.","","","http://arxiv.org/abs/2404.15549v2","IMU, RGB, HOI, dataset, tracking","cs.CL, cs.AI","30 Pages, 8 Figures, Supplementary Work Attached","2024.04","HCI"
"arXiv(v1) 2024","Bayesian Learned Models Can Detect Adversarial Malware For Free","Bao Gia Doan, Dang Quang Nguyen, Paul Montague, et al.","","","http://arxiv.org/abs/2403.18309v1","VR, AR, simulated avatar, headset","cs.CR","Accepted to the 29th European Symposium on Research in Computer Security (ESORICS) 2024 Conference","2024.03","HCI"
"arXiv(v2) 2024","Feasibility Consistent Representation Learning for Safe Reinforcement Learning","Zhepeng Cen, Yihang Yao, Zuxin Liu, et al.","","","http://arxiv.org/abs/2405.11718v2","LLM, agent, UI, LAUI, interface","cs.LG","ICML 2024","2024.06","Agent"
"arXiv(v1) 2024","Unlocking the Power of Environment Assumptions for Unit Proofs","Siddharth Priya, Temesghen Kahsai, Arie Gurfinkel","","","http://arxiv.org/abs/2409.12269v1","LLM, GUI, agent, survey","cs.SE, cs.PL","SEFM 2024","2024.09","LLM"
"arXiv(v1) 2024","Simultaneous identification of the parameters in the plasticity function for power hardening materials : A Bayesian approach","Salih Tatar, Mohamed BenSalah","","","http://arxiv.org/abs/2412.05241v1","LLM, agent, computer use, evaluation","math.NA, math.AP","","2024.12","Agent"
"Proceedings of the CHI Conference on Human Factors in Computing Systems 2024","Towards Robotic Companions: Understanding Handler-Guide Dog Interactions for Informed Guide Dog Robot Design","Hochul Hwang, Hee-Tae Jung, Nicholas A Giudice, et al.","10.1145/3613904.3642181","","https://doi.org/10.1145/3613904.3642181","LLM, HCI, CHI, interaction","","","2024.05","HCI"
